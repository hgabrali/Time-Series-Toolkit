


# PART 1: ğŸš‚ Loading the Train Data: Step-by-Step Process
*(EÄŸitim Verisini YÃ¼kleme: AdÄ±m AdÄ±m SÃ¼reÃ§)*

Ã–nceki aÅŸamada Ã§oÄŸu dosya baÅŸarÄ±yla yÃ¼klenmiÅŸti, ancak maÄŸaza satÄ±ÅŸlarÄ±nÄ±n zaman serisi verilerini (*time-series data*) iÃ§eren `train.csv` dosyasÄ± hariÃ§. Bu dosya oldukÃ§a bÃ¼yÃ¼ktÃ¼r ve standart yÃ¶ntemlerle okunmasÄ± zordur.

Bu bÃ¶lÃ¼mde, bÃ¼yÃ¼k veri dosyalarÄ±nÄ± yÃ¶netmek iÃ§in **"Chunking"** (ParÃ§alara AyÄ±rma) ve **"Sampling"** (Ã–rnekleme) stratejilerini uyguladÄ±k. Ä°ÅŸte adÄ±m adÄ±m uygulanan iÅŸlemler:

---

### 1. Install the `gdown` Library
*(gdown KÃ¼tÃ¼phanesinin Kurulumu)*
* **Ä°ÅŸlem (Action):** `gdown` kÃ¼tÃ¼phanesini ortamÄ±mÄ±za kurduk.
* **Neden? (Why?):** BÃ¼yÃ¼k dosyamÄ±z Google Drive Ã¼zerinde barÄ±nmaktadÄ±r. Standart `requests` kÃ¼tÃ¼phanesi yerine, bÃ¼yÃ¼k dosyalarÄ± indirme (*large file download*) konusunda daha yetenekli ve stabil olan `gdown` aracÄ±nÄ± tercih ettik.

### 2. Download the `train.csv` File
*(train.csv DosyasÄ±nÄ±n Ä°ndirilmesi)*
* **Ä°ÅŸlem (Action):** DosyayÄ± indirdik ve Ã§alÄ±ÅŸma ortamÄ±mÄ±za `train.csv` adÄ±yla kaydettik.
* **Neden? (Why?):** Veriyi iÅŸleyebilmek iÃ§in yerel ortama (*local environment*) veya Colab diskine alÄ±nmasÄ± gerekiyordu.

### 3. Select Stores from the "Pichincha" Region
*(Pichincha BÃ¶lgesinden MaÄŸazalarÄ±n SeÃ§imi)*
* **Ä°ÅŸlem (Action):** Analiz kapsamÄ±mÄ±zÄ± daraltmak iÃ§in maÄŸaza listesini filtreledik ve sadece "Pichincha" bÃ¶lgesindeki maÄŸazalarÄ± seÃ§tik.
* **Neden? (Why?):** TÃ¼m veri yerine belirli bir bÃ¶lgeye odaklanarak analizi daha yÃ¶netilebilir hale getirdik (*region filtering*).

### 4. Read the Data in Chunks and Filter by Store
*(Veriyi ParÃ§alar Halinde Okuma ve MaÄŸazaya GÃ¶re Filtreleme)*
* **Ä°ÅŸlem (Action):** `train.csv` dosyasÄ± Ã§ok bÃ¼yÃ¼k olduÄŸu iÃ§in tek seferde okumak yerine, 1 milyon satÄ±rlÄ±k **parÃ§alar halinde** (*chunks*) okuduk. Her parÃ§a okunduÄŸunda, sadece yukarÄ±da seÃ§tiÄŸimiz "Pichincha" maÄŸazalarÄ±na ait satÄ±rlarÄ± tuttuk.
* **Neden? (Why?):** Bellek yÃ¶netimi (*memory management*) iÃ§in kritiktir. TÃ¼m dosyayÄ± RAM'e yÃ¼klemek yerine, parÃ§a parÃ§a iÅŸleyip gereksiz veriyi anÄ±nda elemek (*on-the-fly filtering*) sistemin Ã§Ã¶kmesini engeller.

### 5. Combine the Chunks
*(ParÃ§alarÄ±n BirleÅŸtirilmesi)*
* **Ä°ÅŸlem (Action):** FiltrelenmiÅŸ parÃ§alarÄ± (*filtered chunks*) tek bir DataFrame Ã§atÄ±sÄ± altÄ±nda birleÅŸtirdik (*concatenation*).
* **Neden? (Why?):** Analiz ve modelleme aÅŸamasÄ±nda bÃ¼tÃ¼ncÃ¼l bir veri seti Ã¼zerinde Ã§alÄ±ÅŸabilmek iÃ§in parÃ§alarÄ± tekrar bir araya getirmemiz gerekiyordu.

### 6. Sample 2 Million Rows
*(2 Milyon SatÄ±rÄ±n Ã–rneklenmesi)*
* **Ä°ÅŸlem (Action):** FiltrelenmiÅŸ veriden rastgele 2 milyon satÄ±r seÃ§tik (*random sampling*).
* **Neden? (Why?):** EÄŸitim amaÃ§lÄ± (*educational sake*) hesaplamalarÄ± hÄ±zlandÄ±rmak iÃ§in. GerÃ§ek dÃ¼nyada tÃ¼m veri kullanÄ±labilir ancak Ã¶ÄŸrenme sÃ¼recinde iÅŸlem sÃ¼resini kÄ±saltmak (*computation speed*) iÃ§in veri boyutu optimize edildi.

### 7. Clean Up
*(Temizlik)*
* **Ä°ÅŸlem (Action):** Bellekte yer kaplayan geÃ§ici parÃ§a listelerini sildik.
* **Neden? (Why?):** Python'Ä±n bellek yÃ¶netimini rahatlatmak (*garbage collection*) ve RAM'i verimli kullanmak iÃ§in gereksiz deÄŸiÅŸkenler temizlendi.

### 8. Verification
*(DoÄŸrulama)*
* **Ä°ÅŸlem (Action):** OluÅŸturulan DataFrame'lerin ilk satÄ±larÄ±nÄ± (`head`) yazdÄ±rarak kontrol ettik.
* **Neden? (Why?):** Verinin dÃ¼zgÃ¼n yÃ¼klenip yÃ¼klenmediÄŸini ve formatÄ±n beklediÄŸimiz gibi olup olmadÄ±ÄŸÄ±nÄ± teyit etmek (*sanity check*).

---

# PART 2: Veri Setini Anlamak (Understanding the Dataset)

Ä°ndirdiÄŸimiz **CorporaciÃ³n Favorita Grocery Sales Forecasting** veri setine yakÄ±ndan bakalÄ±m.

### ğŸ“‚ Girdi Verileri (Input Data)

Ã‡alÄ±ÅŸacaÄŸÄ±mÄ±z birden fazla `csv` dosyasÄ± bulunmaktadÄ±r. Bunlar ÅŸunlarÄ± iÃ§erir:

#### 1. `train.csv`
* Hedef deÄŸiÅŸken (*target*) olan `unit_sales` (birim satÄ±ÅŸlar) verisini `date` (tarih) bazÄ±nda iÃ§erir. AyrÄ±ca `store_nbr` (maÄŸaza no), `item_nbr` (Ã¼rÃ¼n no) ve satÄ±rlarÄ± etiketlemek iÃ§in benzersiz bir `id` sÃ¼tunu bulunur.
* Hedef `unit_sales`, tamsayÄ± (*integer*) (Ã¶rn: bir paket cips) veya ondalÄ±klÄ± sayÄ± (*float*) (Ã¶rn: 1.5 kg peynir) olabilir.
* `unit_sales` deÄŸerinin negatif olmasÄ±, o Ã¼rÃ¼nÃ¼n iade edildiÄŸini (*returns*) gÃ¶sterir.
* `onpromotion` sÃ¼tunu, o `item_nbr`'Ä±n belirtilen `date` ve `store_nbr` iÃ§in promosyonda olup olmadÄ±ÄŸÄ±nÄ± belirtir.
* Bu dosyadaki `onpromotion` deÄŸerlerinin yaklaÅŸÄ±k %16'sÄ± `NaN` (eksik veri)'dÄ±r.

> â˜ğŸ¼ **NOT (NOTE):** EÄŸitim verileri (*training data*), bir maÄŸaza/tarih kombinasyonu iÃ§in sÄ±fÄ±r `unit_sales` olan Ã¼rÃ¼nlere ait satÄ±rlarÄ± iÃ§ermez. ÃœrÃ¼nÃ¼n o tarihte maÄŸazada stokta olup olmadÄ±ÄŸÄ±na (*in stock*) dair bir bilgi yoktur ve ekiplerin bu durumu ele almanÄ±n en iyi yoluna karar vermesi gerekecektir. AyrÄ±ca, eÄŸitim verilerinde gÃ¶rÃ¼len ancak test verilerinde (*test data*) gÃ¶rÃ¼lmeyen az sayÄ±da Ã¼rÃ¼n vardÄ±r.

#### 2. `stores.csv`
* MaÄŸaza Ã¼st verilerini (*metadata*) iÃ§erir: `city` (ÅŸehir), `state` (eyalet), `type` (tÃ¼r) ve `cluster` (kÃ¼me).
* `cluster`, benzer maÄŸazalarÄ±n bir gruplandÄ±rmasÄ±dÄ±r.

#### 3. `items.csv`
* ÃœrÃ¼n Ã¼st verilerini (*metadata*) iÃ§erir: `family` (aile/kategori), `class` (sÄ±nÄ±f) ve `perishable` (bozulabilir).

> â˜ğŸ¼ **NOT (NOTE):** `perishable` (bozulabilir) olarak iÅŸaretlenen Ã¼rÃ¼nlerin skor aÄŸÄ±rlÄ±ÄŸÄ± (*score weight*) **1.25**'tir; diÄŸerlerinin aÄŸÄ±rlÄ±ÄŸÄ± ise **1.0**'dÄ±r.

#### 4. `transactions.csv`
* Her bir `date` ve `store_nbr` kombinasyonu iÃ§in satÄ±ÅŸ iÅŸlemlerinin (*sales transactions*) sayÄ±sÄ±nÄ± iÃ§erir. Sadece eÄŸitim verisi zaman aralÄ±ÄŸÄ± (*training data timeframe*) iÃ§in dahildir.

#### 5. `oil.csv`
* GÃ¼nlÃ¼k petrol fiyatÄ± (*Daily oil price*). Hem eÄŸitim (*train*) hem de test (*test*) verisi zaman aralÄ±ÄŸÄ±ndaki deÄŸerleri iÃ§erir. Ekvador petrol baÄŸÄ±mlÄ± (*oil-dependent*) bir Ã¼lkedir ve ekonomik saÄŸlÄ±ÄŸÄ± petrol fiyatlarÄ±ndaki ÅŸoklara karÅŸÄ± oldukÃ§a kÄ±rÄ±lgandÄ±r (*highly vulnerable*).

#### 6. `holidays_events.csv`
* Tatiller ve Etkinlikler ile bunlara ait Ã¼st veriler.
* `Additional` (Ek) tatiller, normal bir takvim tatiline eklenen gÃ¼nlerdir; Ã¶rneÄŸin Noel civarÄ±nda tipik olarak gerÃ§ekleÅŸen durumlar gibi (Noel Arifesini tatil yapmak).

> â˜ğŸ¼ **NOT (NOTE):** `transferred` (aktarÄ±lan) sÃ¼tununa Ã¶zellikle dikkat edin. `transferred` olan bir tatil resmi olarak o takvim gÃ¼nÃ¼ne denk gelir, ancak hÃ¼kÃ¼met tarafÄ±ndan baÅŸka bir tarihe taÅŸÄ±nmÄ±ÅŸtÄ±r. Bir `transferred` gÃ¼n, tatilden ziyade normal bir gÃ¼n gibidir. AslÄ±nda kutlandÄ±ÄŸÄ± gÃ¼nÃ¼ bulmak iÃ§in, `type` sÃ¼tununun `Transfer` olduÄŸu ilgili satÄ±ra bakÄ±n.
>
> *Ã–rneÄŸin:* `Independencia de Guayaquil` tatili 2012-10-09'dan 2012-10-12'ye aktarÄ±lmÄ±ÅŸtÄ±r (*transferred*), yani 2012-10-12'de kutlanmÄ±ÅŸtÄ±r.
>
> `type` deÄŸeri `Bridge` (KÃ¶prÃ¼) olan gÃ¼nler, bir tatile eklenen ekstra gÃ¼nlerdir (Ã¶rn: tatili uzun bir hafta sonuna uzatmak iÃ§in). Bunlar genellikle, `Bridge` gÃ¼nÃ¼nÃ¼ telafi etmek (*payback*) amacÄ±yla normalde Ã§alÄ±ÅŸma gÃ¼nÃ¼ olmayan (Ã¶rn: Cumartesi) bir gÃ¼nÃ¼n Ã§alÄ±ÅŸÄ±ldÄ±ÄŸÄ± `Work Day` (Ã‡alÄ±ÅŸma GÃ¼nÃ¼) tipi ile telafi edilir.

---

### ğŸ“ Ek Notlar (Additional Notes)

1.  **MaaÅŸlar (Wages):** Kamu sektÃ¶rÃ¼ndeki maaÅŸlar iki haftada bir, ayÄ±n **15'inde** ve **son gÃ¼nÃ¼nde** Ã¶denir. SÃ¼permarket satÄ±ÅŸlarÄ± bundan etkilenebilir.
2.  **Deprem (Earthquake):** 16 Nisan 2016'da Ekvador'da 7.8 bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde bir deprem meydana gelmiÅŸtir. Ä°nsanlar su ve diÄŸer temel ihtiyaÃ§ Ã¼rÃ¼nlerini baÄŸÄ±ÅŸlayarak yardÄ±m Ã§alÄ±ÅŸmalarÄ±nda (*relief efforts*) bir araya gelmiÅŸ, bu durum depremden sonraki birkaÃ§ hafta boyunca sÃ¼permarket satÄ±ÅŸlarÄ±nÄ± bÃ¼yÃ¼k Ã¶lÃ§Ã¼de etkilemiÅŸtir.

---

# PART 3:ğŸ” EDA for Time-Series Data
*(Zaman Serisi Verileri iÃ§in KeÅŸifÃ§i Veri Analizi)*

**EDA (Exploratory Data Analysis)** is a crucial step before applying machine learning models, especially in **time-series forecasting**. We will focus on:
*(EDA, Ã¶zellikle zaman serisi tahmininde makine Ã¶ÄŸrenimi modellerini uygulamadan Ã¶nce Ã§ok Ã¶nemli bir adÄ±mdÄ±r. Åunlara odaklanacaÄŸÄ±z:)*

* ğŸ—ï¸ **Understanding the Structure:** Understanding the structure of the dataset.
    *(Veri setinin yapÄ±sÄ±nÄ± anlamak.)*
* ğŸ§© **Handling Missing Data:** Handling missing data effectively.
    *(Eksik verileri etkili bir ÅŸekilde ele almak.)*
* ğŸ“ˆ **Visualizing Trends:** Visualizing sales trends.
    *(SatÄ±ÅŸ trendlerini gÃ¶rselleÅŸtirmek.)*
* ğŸ”— **Investigating Relationships:** Investigating relationships among the various features.
    *(Ã‡eÅŸitli Ã¶zellikler arasÄ±ndaki iliÅŸkileri araÅŸtÄ±rmak.)*

---


## ğŸ›¤ï¸ Workflow Steps


These are the steps we will follow:

### **Step 1: Checking for Missing Data**
*(AdÄ±m 1: Eksik Veri KontrolÃ¼)*
Identify gaps in the data (e.g., missing sales records, null values in promotion columns).
*(Verideki boÅŸluklarÄ± belirleme [Ã¶rn. eksik satÄ±ÅŸ kayÄ±tlarÄ±, promosyon sÃ¼tunlarÄ±ndaki boÅŸ deÄŸerler].)*

### **Step 2: Handling Outliers**
*(AdÄ±m 2: AykÄ±rÄ± DeÄŸerlerin Ele AlÄ±nmasÄ±)*
Detect and manage extreme values (e.g., negative sales indicating returns, or massive spikes due to earthquakes) that could skew the model.
*(Modeli saptÄ±rabilecek aÅŸÄ±rÄ± deÄŸerleri [Ã¶rn. iadeleri gÃ¶steren negatif satÄ±ÅŸlar veya depremlerden kaynaklanan bÃ¼yÃ¼k sÄ±Ã§ramalar] tespit etme ve yÃ¶netme.)*

### **Step 3: Fill Missing Dates with Zero Sales**
*(AdÄ±m 3: Eksik Tarihleri SÄ±fÄ±r SatÄ±ÅŸla Doldurma)*
Time-series models require a continuous timeline. Missing rows usually imply no sales occurred, so we impute them with 0.
*(Zaman serisi modelleri sÃ¼rekli bir zaman Ã§izelgesi gerektirir. Eksik satÄ±rlar genellikle satÄ±ÅŸ olmadÄ±ÄŸÄ±nÄ± ima eder, bu yÃ¼zden bunlarÄ± 0 ile doldururuz.)*

### **Step 4: Feature Engineering: Turning a Date into Useful Signals**
*(AdÄ±m 4: Ã–zellik MÃ¼hendisliÄŸi: Bir Tarihi FaydalÄ± Sinyallere DÃ¶nÃ¼ÅŸtÃ¼rme)*
Extract components like "Day of Week", "Month", "Year", and "Is Weekend" from the raw date object to help the model learn cyclical patterns.
*(Modelin dÃ¶ngÃ¼sel kalÄ±plarÄ± Ã¶ÄŸrenmesine yardÄ±mcÄ± olmak iÃ§in ham tarih nesnesinden "HaftanÄ±n GÃ¼nÃ¼", "Ay", "YÄ±l" ve "Hafta Sonu mu" gibi bileÅŸenleri Ã§Ä±karma.)*

### **Step 5: Visualizing Time-Series Data**
*(AdÄ±m 5: Zaman Serisi Verilerini GÃ¶rselleÅŸtirme)*
Plot sales over time to spot trends, seasonality, and potential structural breaks.
*(Trendleri, mevsimselliÄŸi ve potansiyel yapÄ±sal kÄ±rÄ±lmalarÄ± tespit etmek iÃ§in zaman iÃ§indeki satÄ±ÅŸlarÄ± grafiÄŸe dÃ¶kme.)*

### **Step 6: Examining the Impact of Holidays**
*(AdÄ±m 6: Tatillerin Etkisini Ä°nceleme)*
Analyze how specific events (National holidays, transferred days, bridges) correlate with sales spikes or drops.
*(Belirli olaylarÄ±n [Ulusal tatiller, aktarÄ±lan gÃ¼nler, kÃ¶prÃ¼ler] satÄ±ÅŸ artÄ±ÅŸlarÄ± veya dÃ¼ÅŸÃ¼ÅŸleriyle nasÄ±l iliÅŸkili olduÄŸunu analiz etme.)*

### **Step 7: Analyzing Perishable Items**
*(AdÄ±m 7: Bozulabilir ÃœrÃ¼nleri Analiz Etme)*
Investigate if perishable goods (weighted higher in scoring) show different sales patterns compared to non-perishables.
*(Bozulabilir mallarÄ±n [puanlamada aÄŸÄ±rlÄ±ÄŸÄ± daha yÃ¼ksek olan], bozulmayanlara kÄ±yasla farklÄ± satÄ±ÅŸ modelleri gÃ¶sterip gÃ¶stermediÄŸini araÅŸtÄ±rma.)*


---

# PART 4:

# ğŸ¯ Preparing Data & Introduction to Darts
*(Veri HazÄ±rlama ve Darts'a GiriÅŸ)*

Modelleme aÅŸamasÄ±na geÃ§meden Ã¶nce, Ã¼zerinde Ã§alÄ±ÅŸmaya hazÄ±r, temiz bir veri setine ihtiyacÄ±mÄ±z vardÄ±r. Bu bÃ¶lÃ¼mde, klasik **ARIMA/SARIMA** modellerini uygulamak iÃ§in Python'un gÃ¼Ã§lÃ¼ zaman serisi kÃ¼tÃ¼phanesi **Darts**'Ä± kullanacaÄŸÄ±z. Veri seti olarak yine "CorporaciÃ³n Favorita Grocery Sales Forecasting" verilerini kullanÄ±yoruz.

---

## ğŸ§ What is DARTS? Why use it?
*(DARTS Nedir? Neden KullanÄ±lÄ±r?)*

**DARTS**, zaman serisi tahmini (*time-series forecasting*) iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸ, kullanÄ±mÄ± kolay ve Ã¼st dÃ¼zey (*high-level*) bir Python kÃ¼tÃ¼phanesidir.

> **ğŸ’¡ The Core Philosophy (Temel Felsefe):**
> DARTS, `scikit-learn` kÃ¼tÃ¼phanesinin kullanÄ±cÄ± dostu yapÄ±sÄ±nÄ± (fit/predict mantÄ±ÄŸÄ±) zaman serilerine uyarlar. KarmaÅŸÄ±k modelleri (ARIMA'dan Derin Ã–ÄŸrenme Transformer'larÄ±na kadar) tek bir satÄ±r kodla deÄŸiÅŸtirmenize ve test etmenize olanak tanÄ±r.

### Key Features (Temel Ã–zellikler)
1.  **Unified API (BirleÅŸik ArayÃ¼z):** Klasik istatistiksel modellerden (*ARIMA, Exponential Smoothing*) modern makine Ã¶ÄŸrenimi (*XGBoost, LightGBM*) ve derin Ã¶ÄŸrenme modellerine (*N-BEATS, LSTM, Transformers*) kadar her ÅŸeyi aynÄ± arayÃ¼zle kullanabilirsiniz.
2.  **Multivariate Support (Ã‡ok DeÄŸiÅŸkenli Destek):** Sadece hedef deÄŸiÅŸkeni deÄŸil, dÄ±ÅŸsal faktÃ¶rleri (*past/future covariates*) de modele kolayca dahil edebilirsiniz (Ã¶rn. Tatiller, Petrol FiyatlarÄ±).
3.  **Backtesting & Evaluation (Geriye DÃ¶nÃ¼k Test ve DeÄŸerlendirme):** Modelin geÃ§miÅŸ performansÄ±nÄ± simÃ¼le etmek iÃ§in gÃ¼Ã§lÃ¼ araÃ§lar sunar.
4.  **Probabilistic Forecasting (OlasÄ±lÄ±ksal Tahmin):** Sadece tek bir deÄŸer deÄŸil, gÃ¼ven aralÄ±klarÄ± (*confidence intervals*) ve olasÄ±lÄ±k daÄŸÄ±lÄ±mlarÄ± Ã¼retebilir.

---

## ğŸ› ï¸ Step-by-Step Workflow
*(AdÄ±m AdÄ±m Ä°ÅŸ AkÄ±ÅŸÄ±)*

### Step 0: Installing Darts
*(AdÄ±m 0: Darts Kurulumu)*

We will illustrate how to use classical time-series methods like ARIMA for forecasting using the DARTS library. First, ensure the library is installed in your environment.
*(DARTS kÃ¼tÃ¼phanesini kullanarak tahminleme iÃ§in ARIMA gibi klasik yÃ¶ntemlerin nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± gÃ¶stereceÄŸiz. Ã–ncelikle kÃ¼tÃ¼phanenin ortamÄ±nÄ±zda kurulu olduÄŸundan emin olun.)*

### Step 1: Loading a Single Storeâ€“Item Series
*(AdÄ±m 1: Tek Bir MaÄŸaza-ÃœrÃ¼n Serisini YÃ¼kleme)*

Rather than juggling millions of rows, weâ€™ll extract **one product in one store** and truncate everything after March 31, 2014.
*(Milyonlarca satÄ±rla boÄŸuÅŸmak yerine, tek bir maÄŸazadaki tek bir Ã¼rÃ¼nÃ¼ Ã§Ä±karacaÄŸÄ±z ve 31 Mart 2014'ten sonraki verileri keseceÄŸiz.)*

* **Goal (Hedef):** Create a manageable dataset to learn the mechanics of the model.
* **Action (Eylem):** Filter by `store_nbr`, `item_nbr`, and apply `date < '2014-04-01'`.
* **Result (SonuÃ§):** A tidy DataFrame with just daily sales for our chosen series. (*SeÃ§ilen serimiz iÃ§in sadece gÃ¼nlÃ¼k satÄ±ÅŸlarÄ± iÃ§eren dÃ¼zenli bir DataFrame.*)

### Step 2: Prepare & Convert to `TimeSeries`
*(AdÄ±m 2: HazÄ±rlÄ±k ve `TimeSeries` Nesnesine DÃ¶nÃ¼ÅŸtÃ¼rme)*

This is the most critical step specific to Darts. Darts works with its own object type called `TimeSeries`, not standard Pandas DataFrames.
*(Bu, Darts'a Ã¶zgÃ¼ en kritik adÄ±mdÄ±r. Darts, standart Pandas DataFrame'leri ile deÄŸil, `TimeSeries` adÄ± verilen kendi nesne tÃ¼rÃ¼yle Ã§alÄ±ÅŸÄ±r.)*

**The Process (SÃ¼reÃ§):**
1.  **Datetime Conversion:** Convert the `date` column to datetime objects and set it as the index.
    *(Tarih sÃ¼tununu datetime nesnelerine Ã§evirin ve indeks olarak ayarlayÄ±n.)*
2.  **Aggregation:** Aggregate by date (summing all `unit_sales` for that day).
    *(Tarihe gÃ¶re toplulaÅŸtÄ±rma yapÄ±n [o gÃ¼nkÃ¼ tÃ¼m birim satÄ±ÅŸlarÄ± toplayarak].)*
3.  **Gap Filling (Reindexing):** Reindex to a complete daily calendar, filling any missing dates with **zero**.
    *(Eksik tarihleri sÄ±fÄ±r ile doldurarak tam bir gÃ¼nlÃ¼k takvime gÃ¶re yeniden indeksleyin.)*
4.  **Darts Conversion:** Finally, wrap it in Dartsâ€™ `TimeSeries` object using `TimeSeries.from_dataframe()`.
    *(Son olarak, `TimeSeries.from_dataframe()` kullanarak veriyi Darts TimeSeries nesnesine sarÄ±n.)*

> **âœ… Why?** This ensures all the libraryâ€™s modeling and backtesting tools work **out of the box** (*kurulum gerektirmeden/hazÄ±r olarak*).

---

### ğŸ“Š Visual Analysis & Interpretation




#### ğŸ’¡ Think First!


Before reading our interpretation, take a moment to reflect on the chart yourself:
*(Yorumumuzu okumadan Ã¶nce, grafik Ã¼zerinde dÃ¼ÅŸÃ¼nmek iÃ§in bir dakikanÄ±zÄ± ayÄ±rÄ±n:)*
* What do you notice about the **sales volume**? Is it consistent, volatile, or trending?
* Do the **spikes** (*sÄ±Ã§ramalar*) follow any visible pattern?
* What kinds of **features** might help the model capture this behavior?

#### ğŸ“‰ Our Analysis


**1. Key Observations (Temel GÃ¶zlemler)**
* **Consistently High Sales:** The product sells every day, typically between 300 and 800 units. It is a **high-volume item**.
* **No Missing/Zero Values:** We see activity on every day. This is ideal for training a model that learns from historical behavior without needing complex imputation (*eksik veri doldurma*).
* **Frequent, Sharp Fluctuations:** The series is **noisy** (*gÃ¼rÃ¼ltÃ¼lÃ¼*) â€” it goes up and down regularly â€” but mostly within a predictable range.
* **Occasional Large Peaks:** Some spikes rise sharply (>1000) above the usual range. These likely correspond to **promotions**, **holidays**, or **special events**.

**2. What This Suggests for Forecasting (Tahminleme Ä°Ã§in Ne Anlama Geliyor?)**
* **Lag Features:** The model will benefit from lags (e.g., `sales_lag_1`, `rolling_mean_7`) to learn local dynamics.
* **Calendar Features:** Including `day_of_week`, `is_weekend`, or `month` will help capture recurring patterns (*tekrarlayan kalÄ±plar*).
* **Volatility Handling:** Applying a **rolling average** or using a **log transformation** might improve model stability against noise.
* **External Signals:** To predict the huge spikes, adding **promotions** data (as *covariates*) would be valuable.

---

### Step 3: Splitting the Data into Training and Testing Sets
*(AdÄ±m 3: Veriyi EÄŸitim ve Test Setlerine AyÄ±rma)*

In time-series forecasting, we cannot use random splitting (like `train_test_split` in sklearn) because the **order of data matters**. We must split chronologically.
*(Zaman serisi tahmininde, rastgele bÃ¶lme kullanamayÄ±z Ã§Ã¼nkÃ¼ verinin sÄ±rasÄ± Ã¶nemlidir. Kronolojik olarak bÃ¶lmemiz gerekir.)*

* **Training Set (EÄŸitim Seti):** The past data used to teach the model patterns (e.g., usually the first 80-90% of the timeline).
    *(Model kalÄ±plarÄ±nÄ± Ã¶ÄŸretmek iÃ§in kullanÄ±lan geÃ§miÅŸ veriler.)*
* **Validation/Test Set (DoÄŸrulama/Test Seti):** The recent data used to evaluate how well the model predicts the future (the remaining 10-20%).
    *(Modelin geleceÄŸi ne kadar iyi tahmin ettiÄŸini deÄŸerlendirmek iÃ§in kullanÄ±lan son veriler.)*

**Darts Method:**
We use specific Darts methods (like `.split_before()`) to ensure no **data leakage** (*veri sÄ±zÄ±ntÄ±sÄ±*) occursâ€”meaning the model never sees the "future" it is trying to predict during training.


---

# PART 5:




---
---

# ğŸ•°ï¸ Comprehensive Guide to Time-Series Modelling
*(Zaman Serisi Modelleme KapsamlÄ± Rehberi)*

Bu dokÃ¼man, Zaman Serisi Tahmini (*Time-Series Forecasting*) projelerinde dikkate alÄ±nmasÄ± gereken temel bileÅŸenleri, analiz yÃ¶ntemlerini ve modelleme stratejilerini karÅŸÄ±laÅŸtÄ±rmalÄ± bir ÅŸekilde sunar.

---

## 1. ğŸ—ï¸ Preprocessing & Structural Analysis
*(Ã–n Ä°ÅŸleme ve YapÄ±sal Analiz)*

Modellemeye geÃ§meden Ã¶nce zaman serisinin karakteristiÄŸini anlamak ve veriyi matematiksel olarak modele hazÄ±rlamak zorunludur.

| BileÅŸen (Component) | AÃ§Ä±klama (Description) | Teknikler & Testler (Techniques & Tests) |
| :--- | :--- | :--- |
| **Stationarity**<br>*(Durgunluk)* | Serinin istatistiksel Ã¶zelliklerinin (ortalama, varyans) zamanla deÄŸiÅŸmemesi durumudur. Ã‡oÄŸu klasik model (ARIMA vb.) durgunluk gerektirir. | â€¢ **ADF Test (Augmented Dickey-Fuller):** Birim kÃ¶k (*unit root*) varlÄ±ÄŸÄ±nÄ± test eder.<br>â€¢ **KPSS Test:** Serinin trend duraÄŸan olup olmadÄ±ÄŸÄ±nÄ± test eder.<br>â€¢ **Differencing (Fark Alma):** DurgunlaÅŸtÄ±rmak iÃ§in $y_t - y_{t-1}$ iÅŸlemi. |
| **Seasonality & Trend**<br>*(Mevsimsellik ve Trend)* | Verideki uzun vadeli artÄ±ÅŸ/azalÄ±ÅŸ (Trend) ve belirli periyotlarla tekrar eden kalÄ±plar (Mevsimsellik). | â€¢ **Decomposition (AyrÄ±ÅŸtÄ±rma):** Additive (Toplamsal) veya Multiplicative (Ã‡arpÄ±msal) ayrÄ±ÅŸtÄ±rma.<br>â€¢ **STL Decomposition:** Mevsimsellik ve Trendi Loess kullanarak ayÄ±rma. |
| **Autocorrelation**<br>*(Otokorelasyon)* | Bir gÃ¶zlemin geÃ§miÅŸ gÃ¶zlemlerle olan iliÅŸkisi. | â€¢ **ACF (Autocorrelation Function):** DoÄŸrudan ve dolaylÄ± geÃ§miÅŸ iliÅŸkiler.<br>â€¢ **PACF (Partial Autocorrelation Function):** Ara gecikmelerin etkisini kaldÄ±rarak saf iliÅŸki. |
| **Missing Values**<br>*(Eksik DeÄŸerler)* | Zaman serisinde boÅŸluklar kabul edilemez. | â€¢ **Forward/Backward Fill:** Ã–nceki/sonraki deÄŸerle doldurma.<br>â€¢ **Interpolation:** Lineer veya zamana baÄŸlÄ± enterpolasyon.<br>â€¢ **Imputation:** Ortalama veya 0 ile doldurma (satÄ±ÅŸ yoksa). |

---

## 2. ğŸ› ï¸ Feature Engineering Strategies
*(Ã–zellik MÃ¼hendisliÄŸi Stratejileri)*

Zaman serisi verisini Makine Ã–ÄŸrenmesi (*Machine Learning*) modellerine (Ã¶rn. XGBoost, Random Forest) sokabilmek iÃ§in "zamanÄ±" Ã¶zelliklere dÃ¶nÃ¼ÅŸtÃ¼rmek gerekir.

| Ã–zellik TÃ¼rÃ¼ (Feature Type) | YÃ¶ntem (Method) | Neden KullanÄ±lÄ±r? (Why Use It?) |
| :--- | :--- | :--- |
| **Lag Features**<br>*(Gecikmeli Ã–zellikler)* | $t-1, t-7, t-30$ gibi geÃ§miÅŸ deÄŸerleri yeni sÃ¼tun olarak eklemek. | Modelin otokorelasyonu (*autocorrelation*) Ã¶ÄŸrenmesini saÄŸlar. "BugÃ¼nÃ¼n satÄ±ÅŸÄ± dÃ¼nkÃ¼ satÄ±ÅŸa benzer" mantÄ±ÄŸÄ±. |
| **Rolling Window Statistics**<br>*(Hareketli Pencere Ä°statistikleri)* | Son 7 gÃ¼nÃ¼n ortalamasÄ±, standart sapmasÄ±, min/max deÄŸerleri. | GÃ¼rÃ¼ltÃ¼yÃ¼ azaltÄ±r (*smoothing*) ve trend/momentum bilgisini yakalar. |
| **Date-Time Components**<br>*(Tarih-Zaman BileÅŸenleri)* | Ay, YÄ±l, HaftanÄ±n GÃ¼nÃ¼, YÄ±lÄ±n GÃ¼nÃ¼, Hafta Sonu mu? | Modelin dÃ¶ngÃ¼sel (*cyclical*) ve takvimsel etkileri Ã¶ÄŸrenmesini saÄŸlar. |
| **Cyclical Encoding**<br>*(DÃ¶ngÃ¼sel Kodlama)* | Ay ve gÃ¼n bilgisini SinÃ¼s/KosinÃ¼s fonksiyonlarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek. | AralÄ±k (12) ile Ocak (1) ayÄ±nÄ±n birbirine yakÄ±n olduÄŸunu modele matematiksel olarak anlatÄ±r. |
| **Exogenous Variables**<br>*(DÄ±ÅŸsal DeÄŸiÅŸkenler)* | Tatiller, Petrol FiyatlarÄ±, Hava Durumu, Promosyonlar. | Tahmin gÃ¼cÃ¼nÃ¼ artÄ±ran dÄ±ÅŸ faktÃ¶rleri dahil eder. |

---

## 3. ğŸ¤– Modelling Approaches: Comparative Table
*(Modelleme YaklaÅŸÄ±mlarÄ±: KarÅŸÄ±laÅŸtÄ±rmalÄ± Tablo)*

Hangi modelin seÃ§ileceÄŸi veri boyutuna, karmaÅŸÄ±klÄ±ÄŸÄ±na ve iÅŸ ihtiyacÄ±na baÄŸlÄ±dÄ±r.

| YaklaÅŸÄ±m (Approach) | Modeller (Models) | Avantajlar (Pros) | Dezavantajlar (Cons) | En Ä°yi KullanÄ±m (Best Use Case) |
| :--- | :--- | :--- | :--- | :--- |
| **Statistical (Classical)**<br>*(Ä°statistiksel/Klasik)* | â€¢ ARIMA / SARIMA<br>â€¢ ETS (Exponential Smoothing)<br>â€¢ Holt-Winters | â€¢ Az veriyle iyi Ã§alÄ±ÅŸÄ±r.<br>â€¢ YorumlanabilirliÄŸi (*interpretability*) yÃ¼ksektir.<br>â€¢ Ä°statistiksel Ã¶zellikleri (trend, mevsimsellik) doÄŸrudan modeller. | â€¢ Ã‡oklu dÄ±ÅŸsal deÄŸiÅŸkenleri (*multivariate*) yÃ¶netmek zordur.<br>â€¢ DoÄŸrusal olmayan (*non-linear*) iliÅŸkileri yakalayamaz.<br>â€¢ BÃ¼yÃ¼k veride yavaÅŸtÄ±r. | Tek deÄŸiÅŸkenli, kÄ±sa vadeli, net trendi olan veriler. |
| **Machine Learning (Tree-Based)**<br>*(Makine Ã–ÄŸrenmesi / AÄŸaÃ§ TabanlÄ±)* | â€¢ XGBoost<br>â€¢ LightGBM<br>â€¢ Random Forest<br>â€¢ CatBoost | â€¢ DoÄŸrusal olmayan karmaÅŸÄ±k iliÅŸkileri yakalar.<br>â€¢ DÄ±ÅŸsal deÄŸiÅŸkenleri (promosyon, tatil) mÃ¼kemmel yÃ¶netir.<br>â€¢ BÃ¼yÃ¼k veride Ã¶lÃ§eklenebilir (*scalable*). | â€¢ Trendi "extrapolate" edemez (gÃ¶rmediÄŸi yÃ¼ksek deÄŸerleri tahmin edemez).<br>â€¢ Ã‡ok fazla Ã–zellik MÃ¼hendisliÄŸi (*Feature Engineering*) gerektirir. | KarmaÅŸÄ±k perakende satÄ±ÅŸlarÄ±, Ã§oklu deÄŸiÅŸkenler, bÃ¼yÃ¼k veri setleri. (Bizim projemiz iÃ§in ideal). |
| **Deep Learning**<br>*(Derin Ã–ÄŸrenme)* | â€¢ LSTM / GRU (RNNs)<br>â€¢ CNN (1D)<br>â€¢ Transformers (TFT, Temporal Fusion) | â€¢ SÄ±ralÄ± baÄŸÄ±mlÄ±lÄ±klarÄ± (*sequential dependencies*) ve uzun vadeli hafÄ±zayÄ± yÃ¶netir.<br>â€¢ Ham veriden Ã¶zellik Ã§Ä±karabilir.<br>â€¢ Ã‡ok karmaÅŸÄ±k Ã¶rÃ¼ntÃ¼leri Ã§Ã¶zer. | â€¢ Ã‡ok bÃ¼yÃ¼k veri ve iÅŸlem gÃ¼cÃ¼ (*GPU*) gerektirir.<br>â€¢ "Black Box" (Kara Kutu) doÄŸasÄ± vardÄ±r, yorumlamasÄ± zordur.<br>â€¢ EÄŸitim sÃ¼resi uzundur. | Devasa veri setleri, web trafiÄŸi, finansal yÃ¼ksek frekanslÄ± iÅŸlemler. |
| **Modern Hybrid / Automated**<br>*(Modern Hibrit / Otomatik)* | â€¢ Prophet (Meta)<br>â€¢ NeuralProphet<br>â€¢ Auto-ARIMA | â€¢ KullanÄ±mÄ± kolaydÄ±r (*Out-of-the-box*).<br>â€¢ Tatilleri ve deÄŸiÅŸim noktalarÄ±nÄ± (*changepoints*) otomatik yÃ¶netir. | â€¢ Her zaman en yÃ¼ksek doÄŸruluÄŸu vermeyebilir.<br>â€¢ Ã–zelleÅŸtirme (*customization*) imkanlarÄ± bazen sÄ±nÄ±rlÄ±dÄ±r. | HÄ±zlÄ± prototipleme, iÅŸ zekasÄ± raporlamasÄ±, orta Ã¶lÃ§ekli veriler. |

---

## 4. ğŸ“‰ Validation & Evaluation Metrics
*(DoÄŸrulama ve DeÄŸerlendirme Metrikleri)*

Zaman serilerinde rastgele bÃ¶lme (*random split*) yapÄ±lamaz; "GeleceÄŸi kullanarak geÃ§miÅŸi tahmin etmek" (*Data Leakage*) hatasÄ±na dÃ¼ÅŸmemek gerekir.

### A. Validation Strategy (DoÄŸrulama Stratejisi)

* **Time Series Split:** Veriyi zamana gÃ¶re sÄ±ralÄ± tutarak eÄŸitim seti sÃ¼rekli bÃ¼yÃ¼rken test seti ileri kayar.
* **Sliding Window (Walk-Forward):** Sabit boyutlu bir pencere zaman iÃ§inde kaydÄ±rÄ±lÄ±r.
* **Strict Cut-off:** Ã–rn. 2016 sonuna kadar Train, 2017 baÅŸÄ± Validation, 2017 sonu Test.

### B. Key Metrics (Temel Metrikler)

| Metrik (Metric) | FormÃ¼l MantÄ±ÄŸÄ± (Logic) | ArtÄ±lar/Eksiler (Pros/Cons) |
| :--- | :--- | :--- |
| **MAE**<br>*(Mean Absolute Error)* | HatalarÄ±n mutlak deÄŸerlerinin ortalamasÄ±. | â€¢ YorumlamasÄ± kolaydÄ±r (SatÄ±ÅŸ adedi cinsinden hata).<br>â€¢ AykÄ±rÄ± deÄŸerlere (*outliers*) karÅŸÄ± daha direnÃ§lidir. |
| **RMSE**<br>*(Root Mean Squared Error)* | HatalarÄ±n karesinin ortalamasÄ±nÄ±n karekÃ¶kÃ¼. | â€¢ BÃ¼yÃ¼k hatalarÄ± daha Ã§ok cezalandÄ±rÄ±r (*penalizes large errors*).<br>â€¢ AykÄ±rÄ± deÄŸerlere karÅŸÄ± hassastÄ±r. |
| **MAPE**<br>*(Mean Absolute Percentage Error)* | HatanÄ±n gerÃ§ek deÄŸere oranÄ±nÄ±n yÃ¼zdesi. | â€¢ Ã–lÃ§ekten baÄŸÄ±msÄ±zdÄ±r (*scale-independent*), % olarak ifade edilir.<br>â€¢ GerÃ§ek deÄŸer 0 ise tanÄ±msÄ±z olur (Sonsuz hata). |
| **WMAPE**<br>*(Weighted MAPE)* | AÄŸÄ±rlÄ±klÄ± ortalama yÃ¼zde hatasÄ±. | â€¢ Hacme gÃ¶re aÄŸÄ±rlÄ±klandÄ±rÄ±r.<br>â€¢ DÃ¼ÅŸÃ¼k satÄ±ÅŸlÄ± Ã¼rÃ¼nlerdeki yÃ¼ksek yÃ¼zdesel hatalarÄ±n genel skoru bozmasÄ±nÄ± engeller. |
| **RMSLE**<br>*(Root Mean Squared Logarithmic Error)* | Logaritmik Ã¶lÃ§ekte RMSE. | â€¢ Tahmin edilen deÄŸerin gerÃ§ek deÄŸere "oranÄ±" ile ilgilenir.<br>â€¢ DÃ¼ÅŸÃ¼k tahmin etmeyi (*under-prediction*) yÃ¼ksek tahmin etmeye gÃ¶re daha az cezalandÄ±rÄ±r (veya tam tersi duruma gÃ¶re ayarlanabilir). |

---

## ğŸš€ Summary Checklist for a Successful Project
*(BaÅŸarÄ±lÄ± Bir Proje Ä°Ã§in Ã–zet Kontrol Listesi)*

1.  [ ] **EDA:** Veriyi gÃ¶rselleÅŸtir, mevsimselliÄŸi ve trendi anla.
2.  [ ] **Preprocessing:** Eksik verileri ve anomaliyi yÃ¶net.
3.  [ ] **Feature Engineering:** Lag, Rolling, Date Ã¶zelliklerini Ã¼ret.
4.  [ ] **Baseline Model:** Basit bir model (Ã¶rn. Naive Forecast veya ortalama) kurarak referans noktasÄ± belirle.
5.  [ ] **Model Selection:** Veriye uygun algoritmayÄ± (Ã¶rn. XGBoost) seÃ§.
6.  [ ] **Validation:** Zamana duyarlÄ± (*time-aware*) bir doÄŸrulama seti kullan.
7.  [ ] **Evaluation:** Ä°ÅŸ hedefine uygun metriÄŸi (Ã¶rn. Stok yÃ¶netimi iÃ§in RMSE) seÃ§ ve yorumla.
