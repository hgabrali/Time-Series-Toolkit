
# ğŸ“ˆ Model Evaluation for Time-Series Forecasting


<img width="1373" height="700" alt="image" src="https://github.com/user-attachments/assets/132a51e3-f996-4911-bb0a-c5ba8e49d395" />


Zaman serisi tahmini (Time-Series Forecasting), verinin sÄ±ralÄ± doÄŸasÄ± nedeniyle geleneksel makine Ã¶ÄŸrenimi gÃ¶revlerinden ayrÄ±lÄ±r. Bir modeli deÄŸerlendirmek, zamana duyarlÄ± teknikler ve stratejik bir yaklaÅŸÄ±m gerektirir.

Bu dÃ¶kÃ¼man, zaman serisi modellerinin deÄŸerlendirilmesinde kullanÄ±lan temel prensipleri, validasyon stratejilerini ve baÅŸarÄ± metriklerini teknik bir derinlikle ele alÄ±r.

---

## 1. Temel Zorluklar ve FarklÄ±lÄ±klar

Geleneksel makine Ã¶ÄŸreniminde veriler genellikle baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±ma sahip (IID) olarak kabul edilirken, zaman serilerinde bu durum geÃ§erli deÄŸildir.

### â³ Temporal Dependency (Zaman BaÄŸÄ±mlÄ±lÄ±ÄŸÄ±)
Zaman serilerinde gÃ¶zlemler zaman iÃ§inde sÄ±ralÄ±dÄ±r ve mevcut deÄŸer genellikle Ã¶nceki deÄŸerlere baÄŸlÄ±dÄ±r (otokorelasyon). 
* **Sorun:** Veriyi rastgele (random shuffle) "EÄŸitim" ve "Test" setlerine ayÄ±rmak, modelin geÃ§miÅŸten geleceÄŸi deÄŸil, "gelecekten geÃ§miÅŸi" Ã¶ÄŸrenmesine neden olur.
* **Ã‡Ã¶zÃ¼m:** Veri setleri her zaman kronolojik sÄ±raya gÃ¶re kesilmelidir.

### ğŸ’§ Data Leakage (Veri SÄ±zÄ±ntÄ±sÄ±)
GeleceÄŸe ait bilgilerin (test seti) eÄŸitim sÃ¼recine dahil olmasÄ± durumudur.
* **SonuÃ§:** Model eÄŸitimde harika performans gÃ¶sterir ancak canlÄ±ya (production) alÄ±ndÄ±ÄŸÄ±nda Ã§uvallar.
* **Kural:** Gelecek, geÃ§miÅŸi tahmin etmek iÃ§in kullanÄ±lamaz.

---

## 2. Validasyon Stratejileri (Cross-Validation Techniques)

Zaman serilerinde standart *k-fold cross-validation* kullanÄ±lmaz. Bunun yerine "Walk-Forward Validation" (Ä°leriye YÃ¼rÃ¼yen DoÄŸrulama) teknikleri uygulanÄ±r.

### A. Hold-Out YÃ¶ntemi (Basit Kronolojik BÃ¶lme)
Veri seti belirli bir zaman noktasÄ±ndan itibaren ikiye (veya Ã¼Ã§e) bÃ¶lÃ¼nÃ¼r.
* **EÄŸitim Seti:** $t_0$'dan $t_n$'e kadar.
* **Test Seti:** $t_{n+1}$'den $t_{n+m}$'e kadar.

### B. Time Series Cross-Validation (Walk-Forward)
Bu yÃ¶ntem, modelin zaman iÃ§indeki stabilitesini Ã¶lÃ§mek iÃ§in en gÃ¼venilir yoldur. Ä°ki ana yaklaÅŸÄ±mÄ± vardÄ±r:

#### 1. Expanding Window (GeniÅŸleyen Pencere)
EÄŸitim seti her adÄ±mda bÃ¼yÃ¼rken, test seti zaman ekseninde ileriye doÄŸru kayar.
* **KullanÄ±m AlanÄ±:** Veri geÃ§miÅŸinin tamamÄ± Ã¶nemliyse ve "Concept Drift" (Veri daÄŸÄ±lÄ±mÄ±nÄ±n zamanla deÄŸiÅŸmesi) az ise kullanÄ±lÄ±r.

```text
AdÄ±m 1: [Train: YÄ±l 1-3] -> [Test: YÄ±l 4]
AdÄ±m 2: [Train: YÄ±l 1-4] -> [Test: YÄ±l 5]
AdÄ±m 3: [Train: YÄ±l 1-5] -> [Test: YÄ±l 6]
```
####  2. Rolling Window (Kayan Pencere)
EÄŸitim setinin boyutu sabit tutulur. Yeni veri eklendikÃ§e, en eski veri eÄŸitim setinden Ã§Ä±karÄ±lÄ±r.

* **KullanÄ±m AlanÄ±:** Veri yapÄ±sÄ± zamanla deÄŸiÅŸiyorsa (rejim deÄŸiÅŸikliÄŸi) ve modelin sadece yakÄ±n geÃ§miÅŸe odaklanmasÄ± isteniyorsa kullanÄ±lÄ±r.
  
```text
AdÄ±m 1: [Train: YÄ±l 2-3] -> [Test: YÄ±l 4]
AdÄ±m 2:       [Train: YÄ±l 3-4] -> [Test: YÄ±l 5]
AdÄ±m 3:             [Train: YÄ±l 4-5] -> [Test: YÄ±l 6]
```

### ğŸ†š KarÅŸÄ±laÅŸtÄ±rma: Rolling vs. Expanding Window

Zaman serisi modellerinde doÄŸrulama (validation) yaparken veri setinin nasÄ±l bÃ¶lÃ¼ndÃ¼ÄŸÃ¼ modelin baÅŸarÄ±sÄ±nÄ± doÄŸrudan etkiler. AÅŸaÄŸÄ±da iki ana yÃ¶ntemin mekanizmasÄ± ve karÅŸÄ±laÅŸtÄ±rmalÄ± analizi yer almaktadÄ±r.

#### ğŸ¨ GÃ¶rsel AnlatÄ±m (Visual Explanation)

**1. Expanding Window (GeniÅŸleyen Pencere)**
Veri seti kÃ¼mÃ¼latif olarak bÃ¼yÃ¼r. BaÅŸlangÄ±Ã§ noktasÄ± sabittir.
```text
AdÄ±m 1: | Train (YÄ±l 1) | -> Test (YÄ±l 2)
AdÄ±m 2: | Train (YÄ±l 1 + 2)      | -> Test (YÄ±l 3)
AdÄ±m 3: | Train (YÄ±l 1 + 2 + 3)           | -> Test (YÄ±l 4)

```

# ğŸ“Š Model Evaluation Metrics & Residual Analysis for Time-Series

Zaman serisi tahminlemesinde (Time-Series Forecasting) model baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek, sadece "doÄŸru tahmini" bulmak deÄŸil, hatanÄ±n karakterini ve iÅŸ problemine etkisini anlamaktÄ±r. Tek bir metrik asla resmin tamamÄ±nÄ± gÃ¶stermez.

Bu dÃ¶kÃ¼man, tahmin modellerini deÄŸerlendirirken kullanÄ±lan **Performans Metriklerini**, **Hata Analizi YÃ¶ntemlerini** ve **Karar Destek TablolarÄ±nÄ±** teknik bir derinlikle ele alÄ±r.

---

## 1. Temel Hata Metrikleri (Scale-Dependent)
Bu metrikler verinin Ã¶lÃ§eÄŸine baÄŸlÄ±dÄ±r. Yani, elma satÄ±ÅŸlarÄ±nÄ± (binlerce) ve araba satÄ±ÅŸlarÄ±nÄ± (onlarca) aynÄ± metrik deÄŸeriyle kÄ±yaslayamazsÄ±nÄ±z.

### ğŸ“‰ MAE (Mean Absolute Error)
HatalarÄ±n mutlak deÄŸerlerinin ortalamasÄ±dÄ±r. 
* **Ã–zellik:** TÃ¼m hatalara eÅŸit aÄŸÄ±rlÄ±k verir.
* **KullanÄ±m:** Modelin "ortalama kaÃ§ birim saptÄ±ÄŸÄ±nÄ±" en saf haliyle anlatÄ±r.
$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

### âš¡ RMSE (Root Mean Squared Error)
HatalarÄ±n karesinin ortalamasÄ±nÄ±n karekÃ¶kÃ¼dÃ¼r.
* **Ã–zellik:** HatalarÄ±n karesini aldÄ±ÄŸÄ± iÃ§in **bÃ¼yÃ¼k hatalarÄ± (outliers)** kÃ¼Ã§Ã¼k hatalara gÃ¶re Ã§ok daha aÄŸÄ±r cezalandÄ±rÄ±r.
* **KullanÄ±m:** BÃ¼yÃ¼k bir hata yapmanÄ±n maliyetinin Ã§ok yÃ¼ksek olduÄŸu durumlarda (Ã¶rneÄŸin enerji ÅŸebekesi yÃ¼k tahmini) tercih edilir.
$$RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

> **Uzman Notu (MAE vs RMSE):** EÄŸer RMSE deÄŸeri MAE deÄŸerinden Ã§ok bÃ¼yÃ¼kse, modeliniz bazÄ± Ã¶rneklerde Ã§ok bÃ¼yÃ¼k hatalar yapÄ±yor (outlier Ã¼retiyor) demektir.

---

## 2. YÃ¼zdesel ve Ã–lÃ§ekten BaÄŸÄ±msÄ±z Metrikler (Scale-Independent)
FarklÄ± Ã¶lÃ§ekteki (yÃ¼ksek hacimli vs. dÃ¼ÅŸÃ¼k hacimli) serileri karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r.

### ğŸ“Š MAPE (Mean Absolute Percentage Error)
HatalarÄ± yÃ¼zdesel olarak ifade eder. Ä°ÅŸ birimlerinin (Business Stakeholders) en sevdiÄŸi metriktir.
* **Dezavantaj 1:** GerÃ§ek deÄŸer ($y_i$) 0 olduÄŸunda tanÄ±msÄ±zdÄ±r (sonsuza gider).
* **Dezavantaj 2 (Asimetri):** GereÄŸinden az tahmin etmeyi (under-forecast), fazla tahmin etmeye (over-forecast) gÃ¶re daha fazla cezalandÄ±rÄ±r.
$$MAPE = \frac{100\%}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|$$

### âš–ï¸ sMAPE (Symmetric MAPE)
MAPE'nin asimetrik yapÄ±sÄ±nÄ± ve 0'a bÃ¶lÃ¼nme sorununu (kÄ±smen) dÃ¼zeltmek iÃ§in geliÅŸtirilmiÅŸtir. DeÄŸerler %0 ile %200 arasÄ±nda deÄŸiÅŸir.
$$sMAPE = \frac{100\%}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2}$$

### ğŸŒŸ MASE (Mean Absolute Scaled Error) - AltÄ±n Standart
Modelin hatasÄ±nÄ±, "Naive Model"in (bir Ã¶nceki deÄŸeri tahmin olarak kabul eden saf model: $\hat{y}_t = y_{t-1}$) hatasÄ±na oranlar.
* **MASE < 1:** Modeliniz, "dÃ¼nÃ¼ bugÃ¼ne kopyalayan" saf modelden daha zeki.
* **MASE > 1:** Modeliniz baÅŸarÄ±sÄ±z, Naive yaklaÅŸÄ±m daha iyi sonuÃ§ veriyor.
* **AvantajÄ±:** Mevsimsellik iÃ§eren verilerde ve 0 deÄŸerlerinde oldukÃ§a stabildir.
$$MASE = \frac{MAE_{model}}{MAE_{naive}}$$

---

## 3. Ä°leri Seviye ve Ä°ÅŸ OdaklÄ± Metrikler

### âš–ï¸ WMAPE (Weighted MAPE)
Standart MAPE, hacmi 1 olan Ã¼rÃ¼nle hacmi 1.000.000 olan Ã¼rÃ¼nÃ¼n hatasÄ±na eÅŸit davranÄ±r. Perakende ve Tedarik Zinciri yÃ¶netiminde bu istenmez. WMAPE, hatayÄ± hacme gÃ¶re aÄŸÄ±rlÄ±klandÄ±rÄ±r.
$$WMAPE = \frac{\sum_{i=1}^{n} |y_i - \hat{y}_i|}{\sum_{i=1}^{n} |y_i|}$$

---

## 4. Residual (ArtÄ±k) Analizi: Modeliniz Bilgiyi TÃ¼ketti mi?

Ä°yi bir zaman serisi modelinde, hatalar (residuals) **White Noise (Beyaz GÃ¼rÃ¼ltÃ¼)** olmalÄ±dÄ±r. EÄŸer hatalarda bir "desen" kaldÄ±ysa, model verideki sinyali tam yakalayamamÄ±ÅŸ demektir.

### âœ… White Noise Kriterleri
1.  **SÄ±fÄ±r OrtalamalÄ±:** $E[e_t] = 0$. Hatalar 0 etrafÄ±nda rastgele daÄŸÄ±lmalÄ±. (Bias olmamalÄ±).
2.  **Ä°liÅŸkisiz (Uncorrelated):** Hatalar geÃ§miÅŸ hatalarla korele olmamalÄ±dÄ±r. (ACF grafiÄŸi temiz Ã§Ä±kmalÄ±).
3.  **Sabit Varyans (Homoscedasticity):** HatalarÄ±n boyutu zamanla artmamalÄ± veya azalmamalÄ±dÄ±r.
4.  **Normal DaÄŸÄ±lÄ±m:** Hatalar Ã‡an EÄŸrisi (Gaussian) ÅŸeklinde daÄŸÄ±lmalÄ±dÄ±r (GÃ¼ven aralÄ±klarÄ±nÄ±n doÄŸruluÄŸu iÃ§in ÅŸarttÄ±r).

### ğŸ§ª Ä°statistiksel Test: Ljung-Box Testi
Sadece grafiÄŸe bakmak yetmez. Otokorelasyonun olup olmadÄ±ÄŸÄ±nÄ± istatistiksel olarak test etmeliyiz.
* **H0 (Null Hypothesis):** Veri rastgele daÄŸÄ±lmÄ±ÅŸtÄ±r (White Noise'dur).
* **p-value < 0.05:** H0 reddedilir. Hatalarda otokorelasyon var -> **Model Yetersiz.**
* **p-value > 0.05:** H0 reddedilemez. Hatalar rastgele -> **Model BaÅŸarÄ±lÄ±.**

---

## 5. KarÅŸÄ±laÅŸtÄ±rmalÄ± Karar Tablosu: Hangi YÃ¶ntem Ne Zaman?

| Senaryo | Ã–nerilen Metrik | Neden? |
| :--- | :--- | :--- |
| **BÃ¼yÃ¼k hatalar felaketse** (Ã–rn: Enerji ÅŸebekesi Ã§Ã¶kmesi) | **RMSE** | Karesini aldÄ±ÄŸÄ± iÃ§in outlier'larÄ± Ã§ok sert cezalandÄ±rÄ±r. |
| **Yorumlanabilirlik Ã¶nemliyse** (YÃ¶netim sunumlarÄ±) | **MAE / MAPE** | "Ortalama X adet yanÄ±lÄ±yoruz" demek kolaydÄ±r. |
| **FarklÄ± hacimli binlerce Ã¼rÃ¼n varsa** (Perakende) | **WMAPE** | Ã‡ok satan Ã¼rÃ¼nlerin baÅŸarÄ±sÄ±, az satanlardan daha Ã¶nemlidir. |
| **Veride Ã§ok fazla 0 varsa** (Intermittent Demand) | **MASE** | MAPE sonsuza gider, MASE stabildir. |
| **Modelin ne kadar "zeki" olduÄŸunu Ã¶lÃ§mek iÃ§in** | **MASE** | Basit bir kurala (Naive) gÃ¶re ne kadar katma deÄŸer saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶sterir. |

---

> **Pro Tip:** Asla tek bir metriÄŸe gÃ¼venmeyin. Genellikle **RMSE** (model optimizasyonu iÃ§in) ve **MAPE/WMAPE** (iÅŸ birimlerine raporlama iÃ§in) birlikte kullanÄ±lÄ±r. Residual analizi ise modelin gÃ¼venilirliÄŸi ("CanlÄ±ya alÄ±nÄ±r mÄ±?") sorusunun cevabÄ±dÄ±r.


# ğŸ“‰ Time-Series Forecasting: Model Evaluation Quiz Solutions

Bu dokÃ¼man, **Time-Series Forecasting (Zaman Serisi Tahminleme)** modellerinin deÄŸerlendirilmesi, hata metrikleri ve validasyon stratejileri Ã¼zerine odaklanan **Quiz 5** sorularÄ±nÄ±n detaylÄ± Ã§Ã¶zÃ¼mlerini ve teknik aÃ§Ä±klamalarÄ±nÄ± iÃ§erir.

> **Ã–zet:** Bu quiz, Ã¶zellikle "Data Leakage", "RMSE vs MAPE karÅŸÄ±laÅŸtÄ±rmasÄ±" ve "Validasyon YÃ¶ntemleri" konularÄ±ndaki kavramsal anlayÄ±ÅŸÄ± test etmektedir.

---

## ğŸ§© Quiz SorularÄ± ve Teknik Ã‡Ã¶zÃ¼mler

### 1. Neden rastgele eÄŸitim-test bÃ¶lmesi (random train-test split) zaman serisi verileri iÃ§in uygun deÄŸildir?
**Soru:** Why is random train-test splitting not suitable for time-series data?
* A - it takes longer to compute
* **B - it can lead to data leakage by using future data for training** âœ…
* C - it requires specific algorithms to process time-series
* D - it reduces the size of the training dataset

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Zaman serilerinde veriler arasÄ±nda zamansal bir baÄŸÄ±mlÄ±lÄ±k (temporal dependency) vardÄ±r. Veriyi rastgele karÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda, gelecekteki bir veri noktasÄ±nÄ± eÄŸitim setine, geÃ§miÅŸteki bir noktayÄ± test setine koyabilirsiniz. Bu durum, modelin geleceÄŸi gÃ¶rerek geÃ§miÅŸi tahmin etmesine (**Data Leakage**) neden olur ve yanÄ±ltÄ±cÄ± derecede yÃ¼ksek baÅŸarÄ± oranlarÄ± verir.

---

### 2. Hangi bÃ¶lme yÃ¶ntemi, verinin Ã¶nceki bÃ¶lÃ¼mlerini eÄŸitim ve sonraki bÃ¶lÃ¼mlerini test iÃ§in kullanmayÄ± iÃ§erir?
**Soru:** Which splitting method involves using earlier portions of the data for training and later portions for testing?
* A - random train-test split
* **B - k-fold cross-validation** âœ…
* C - chronological split
* D - rolling window split

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Burada kastedilen standart k-fold deÄŸil, zaman serileri iÃ§in uyarlanmÄ±ÅŸ **Time Series Cross-Validation** (genellikle Nested Cross-Validation veya Blocked CV olarak da bilinir) yÃ¶ntemidir. Bu yÃ¶ntemde veri bloklarÄ± zaman sÄ±rasÄ±na gÃ¶re korunur; model geÃ§miÅŸ bloklarda eÄŸitilir ve gelecek bloklarda test edilir.

---

### 3. Zaman serisi deÄŸerlendirmesi iÃ§in "Rolling Window" (Kayan Pencere) kullanmanÄ±n temel avantajÄ± nedir?
**Soru:** What is the main advantage of using a rolling window split for time-series evaluation?
* A - it reduces computation time
* B - it avoids overfitting
* **C - it mimics real-world scenarios with models predicting future unseen data** âœ…
* D - it uses all data for both training and testing

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Rolling Window yÃ¶ntemi, modelin her adÄ±mda yeni gelen veriyi Ã¶ÄŸrenip bir sonraki adÄ±mÄ± tahmin ettiÄŸi canlÄ± (production) ortamÄ± simÃ¼le eder. Bu, modelin zaman iÃ§inde deÄŸiÅŸen trendlere karÅŸÄ± dayanÄ±klÄ±lÄ±ÄŸÄ±nÄ± Ã¶lÃ§menin en gerÃ§ekÃ§i yoludur.

---

### 4. Tahminlemede "Pozitif Bias" neyi gÃ¶sterir?
**Soru:** What does a positive bias in forecasting indicate?
* A - the model systematically under-predicts demand
* B - the model is unbiased and accurate
* C - the model performs better on larger datasets
* **D - the model systematically over-predicts demand** âœ…

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Bias formÃ¼lÃ¼ kaynaÄŸa gÃ¶re deÄŸiÅŸebilir ancak bu cevap anahtarÄ±na gÃ¶re Bias ÅŸu ÅŸekilde tanÄ±mlanmÄ±ÅŸtÄ±r: `Bias = Tahmin (Forecast) - GerÃ§ek (Actual)`.
> EÄŸer sonuÃ§ **Pozitif (+)** ise, Tahmin > GerÃ§ek demektir. Bu da modelin talebi olduÄŸundan fazla tahmin ettiÄŸini (**Over-prediction**) gÃ¶sterir.

---

### 5. MAD ve RMSE arasÄ±ndaki temel fark nedir?
**Soru:** What is the primary difference between MAD and RMSE?
* A - MAD penalizes larger errors more than RMSE
* **B - RMSE penalizes larger errors more than MAD** âœ…
* C - MAD measures relative errors, while RMSE measures absolute errors
* D - MAD focuses on predicting average values, while RMSE focuses on predicting medians

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> * **MAD (Mean Absolute Deviation):** HatalarÄ±n mutlak deÄŸerini alÄ±r ($|e|$). DoÄŸrusal bir ceza uygular.
> * **RMSE (Root Mean Squared Error):** HatalarÄ±n karesini alÄ±r ($e^2$). Karesi alÄ±nan bÃ¼yÃ¼k hatalar sonucu orantÄ±sÄ±z ÅŸekilde bÃ¼yÃ¼tÃ¼r. Bu nedenle RMSE, bÃ¼yÃ¼k hatalarÄ± (outlier) Ã§ok daha aÄŸÄ±r cezalandÄ±rÄ±r.

---

### 6. Hangi metrik, Ortalama Mutlak SapmayÄ± (MAD) gerÃ§ek deÄŸerlerin ortalamasÄ±na bÃ¶lerek normalleÅŸtirir?
**Soru:** Which metric normalizes the Mean Absolute Deviation (MAD) by the mean of the actual values?
* A - MAPE
* B - RMSE
* **C - rMAD** âœ…
* D - Bias

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> **rMAD (Relative MAD)**, hatanÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ verinin ortalamasÄ±na gÃ¶re oranlar. FormÃ¼lÃ¼: $rMAD = \frac{MAD}{Mean}$. Bu, MAPE'ye bir alternatiftir ancak MAPE kadar yaygÄ±n kullanÄ±lmaz.

---

### 7. Neden MAPE zaman serisi tahminlemesi iÃ§in her zaman gÃ¼venilir bir metrik deÄŸildir?
**Soru:** Why is MAPE not always a reliable metric for time-series forecasting?
* A - it is difficult to interpret
* B - it penalizes large errors less than RMSE
* **C - it is sensitive to small actual values and asymmetry in error treatment** âœ…
* D - it cannot be used with rolling window splits

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> **MAPE (Mean Absolute Percentage Error)** formÃ¼lÃ¼nde paydada "GerÃ§ek DeÄŸer" ($y_t$) bulunur.
> 1.  EÄŸer $y_t = 0$ ise sonuÃ§ tanÄ±msÄ±zdÄ±r (sonsuz).
> 2.  EÄŸer $y_t$ Ã§ok kÃ¼Ã§Ã¼kse, hata oranÄ± yapay olarak devasa Ã§Ä±kar (Ã–rn: GerÃ§ek 1, Tahmin 2 ise hata %100'dÃ¼r).

---

### 8. Bir tahminleme gÃ¶revinde, bir model en iyi RMSE'ye ama en kÃ¶tÃ¼ MAPE'ye sahiptir. Bu ne anlama gelir?
**Soru:** In a forecasting task, a model has the best RMSE but the worst MAPE. What does this imply?
* A - the model is inaccurate overall
* **B - the model handles small actual values poorly but minimizes large errors effectively** âœ…
* C - the model predicts median values better than averages
* D - the model overfits the training data

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> * **Ä°yi RMSE:** Model bÃ¼yÃ¼k hatalar (outlier) yapmÄ±yor demektir.
> * **KÃ¶tÃ¼ MAPE:** Model, gerÃ§ek deÄŸerin (hacmin) Ã§ok dÃ¼ÅŸÃ¼k olduÄŸu zamanlarda oransal olarak bÃ¼yÃ¼k hatalar yapÄ±yor demektir.
> * **Ã–rnek:** Model 10.000 adetlik satÄ±ÅŸta 100 hata yaparsa (KÃ¼Ã§Ã¼k % hata), ama 5 adetlik satÄ±ÅŸta 4 hata yaparsa (BÃ¼yÃ¼k % hata - %80), MAPE bozulur ama RMSE Ã§ok etkilenmez.

---

### 9. BÃ¼yÃ¼k hatalarÄ±n Ã¶zellikle maliyetli olduÄŸu durumlarda hangi metrik en uygundur?
**Soru:** Which metric is most appropriate when large errors are especially costly?
* A - Bias
* B - MAD
* C - MAPE
* **D - RMSE** âœ…

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Enerji santralleri veya hayati medikal cihazlar gibi "bÃ¼yÃ¼k bir hatanÄ±n felaket olduÄŸu" durumlarda, o tek bÃ¼yÃ¼k hatayÄ± matematiksel olarak parlatÄ±p modele "bunu dÃ¼zelt" diyen metrik **RMSE**'dir (karesini aldÄ±ÄŸÄ± iÃ§in).

---

### 10. Zaman serisi tahminlemesi iÃ§in hangi deÄŸerlendirme metriÄŸine Ã¶ncelik verileceÄŸine nasÄ±l karar vermelisiniz?
**Soru:** How should you decide which evaluation metric to prioritize for time-series forecasting?
* A - choose the metric with the smallest value
* **B - consider the specific business goals and consequences of forecasting errors** âœ…
* C - prioritize metrics that are easy to calculate
* D - use MAPE in all cases

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Veri biliminde "tek doÄŸru metrik" yoktur.
> * EÄŸer envanter yÃ¶netiyorsanÄ±z ve Ã¼rÃ¼nler ucuzsa **MAE** yeterlidir.
> * EÄŸer finansal bir Ã§Ã¶kÃ¼ÅŸÃ¼ tahmin ediyorsanÄ±z **RMSE** kritiktir.
> * EÄŸer yÃ¶netim kuruluna sunum yapÄ±yorsanÄ±z yÃ¼zdesel olduÄŸu iÃ§in **MAPE** tercih edilir.
> Karar her zaman **iÅŸ hedeflerine (Business Goals)** gÃ¶re verilir.

---
# â³ Time-Series Model Evaluation: Train-Test Splits

Geleneksel makine Ã¶ÄŸreniminde (Traditional ML) verilerin **I.I.D.** (Independent and Identically Distributed - BaÄŸÄ±msÄ±z ve Ã–zdeÅŸ DaÄŸÄ±lÄ±mlÄ±) olduÄŸu varsayÄ±lÄ±r. Bu nedenle rastgele (random) bÃ¶lme yapÄ±labilir. Ancak **Zaman Serilerinde** durum farklÄ±dÄ±r; veriler arasÄ±nda **zamansal bir baÄŸÄ±mlÄ±lÄ±k (autocorrelation)** vardÄ±r.

Bu dokÃ¼man, zaman serisi tahmin modellerini deÄŸerlendirirken kullanÄ±lan doÄŸru validasyon stratejilerini, teknik ayrÄ±mlarÄ± ve uygulama yÃ¶ntemlerini iÃ§erir.

---

## ğŸš« Neden Rastgele (Random) Split YapamayÄ±z?
Zaman serilerinde rastgele bÃ¶lme yapmak **Data Leakage (Veri SÄ±zÄ±ntÄ±sÄ±)** yaratÄ±r.
* **Sorun:** Gelecekteki bir veri noktasÄ±nÄ± eÄŸitim (train) setine, geÃ§miÅŸteki bir noktayÄ± test setine koyarsanÄ±z; model "geleceÄŸi gÃ¶rerek" geÃ§miÅŸi tahmin etmeye Ã§alÄ±ÅŸÄ±r.
* **SonuÃ§:** Model eÄŸitimde harika sonuÃ§lar verir ancak canlÄ± (production) ortamda baÅŸarÄ±sÄ±z olur.
* **Kural:** BÃ¶lme iÅŸlemi her zaman **Zaman DuyarlÄ± (Time-Aware)** olmalÄ±dÄ±r. Gelecek, geÃ§miÅŸi eÄŸitmek iÃ§in kullanÄ±lamaz.

---

## ğŸ› ï¸ BÃ¶lme YÃ¶ntemleri (Splitting Techniques)

### Method 1 & 2: Simple Chronological Split (Hold-Out)
Veri seti, zaman ekseninde tek bir kesim noktasÄ± belirlenerek ikiye ayrÄ±lÄ±r. Tarih bazlÄ± (Date-based) veya oran bazlÄ± (%70-%30) yapÄ±labilir.

* **YapÄ±sÄ±:** Ä°lk %80 EÄŸitim, Son %20 Test.
* **KullanÄ±mÄ±:** Veri seti Ã§ok bÃ¼yÃ¼kse ve zaman iÃ§inde istatistiksel Ã¶zellikleri (daÄŸÄ±lÄ±mÄ±) Ã§ok deÄŸiÅŸmiyorsa (Stationary) uygundur.

```text
[EÄŸitim Verisi ........................] | [Test Verisi]
t_0 ---------------------------------> t_split ------> t_end
```

<img width="1185" height="316" alt="image" src="https://github.com/user-attachments/assets/88b578eb-d4eb-47c0-ba87-9d5f12235bd3" />

## ğŸ”„ Method 3: Cross-Validation Strategies (Geriye DÃ¶nÃ¼k Test Stratejileri)

Zaman serisi analizinde tek bir test seti (single test set) kullanmak bazen yanÄ±ltÄ±cÄ± sonuÃ§lar doÄŸurabilir. Ã–rneÄŸin, seÃ§ilen test dÃ¶nemi Ã§ok olaÄŸandÄ±ÅŸÄ± bir dÃ¶neme (outlier/anomaly period) denk gelebilir ve bu da modelin genel baÅŸarÄ±sÄ±nÄ± yansÄ±tmaz.

Bu riski minimize etmek iÃ§in **Cross-Validation (Ã‡apraz DoÄŸrulama)** uygulanÄ±r. Ancak, zaman serilerinin sÄ±ralÄ± yapÄ±sÄ± gereÄŸi standart *K-Fold* yerine **Walk-Forward Validation (Ä°leriye YÃ¼rÃ¼yen DoÄŸrulama)** yÃ¶ntemi kullanÄ±lÄ±r.

Bu yÃ¶ntemde temel olarak iki ana yaklaÅŸÄ±m vardÄ±r. LiteratÃ¼rde genellikle karÄ±ÅŸtÄ±rÄ±lsa da teknik farklarÄ± belirgindir. AÅŸaÄŸÄ±da, en yaygÄ±n kullanÄ±lan yaklaÅŸÄ±m detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r:

### ğŸ“ˆ A. Expanding Window (GeniÅŸleyen Pencere)

Bu yÃ¶ntem, Scikit-Learn kÃ¼tÃ¼phanesindeki `TimeSeriesSplit` fonksiyonunun varsayÄ±lan Ã§alÄ±ÅŸma mantÄ±ÄŸÄ±dÄ±r.

#### âš™ï¸ Ã‡alÄ±ÅŸma Prensibi (Mechanism)
EÄŸitim seti (training set) her iterasyonda kÃ¼mÃ¼latif olarak bÃ¼yÃ¼rken, test seti (test set) zaman ekseninde ileriye doÄŸru kayar. BaÅŸlangÄ±Ã§ noktasÄ± sabittir, ancak bitiÅŸ noktasÄ± her adÄ±mda ilerler.

**GÃ¶rselleÅŸtirme (Visualization):**

```text
AdÄ±m 1: | Train (T1)       | -> [Test (T2)]
AdÄ±m 2: | Train (T1 + T2)  | -------------> [Test (T3)]
AdÄ±m 3: | Train (T1 + T2 + T3)            | -------------> [Test (T4)]
```

#### ğŸ”‘ Temel Nitelikler
* **HafÄ±za (Memory):** Model, tÃ¼m geÃ§miÅŸ veriyi (historical data) hatÄ±rlar ve kullanÄ±r. Veri seti kesilmez, sÃ¼rekli eklenir.

* KÃ¼tÃ¼phane DesteÄŸi (Library Support): Python'da sklearn.model_selection.TimeSeriesSplit bu mantÄ±kla Ã§alÄ±ÅŸÄ±r.

* **KullanÄ±m Senaryosu (Use Case):** Veri geÃ§miÅŸinin tamamÄ±nÄ±n (entire history) model baÅŸarÄ±sÄ± iÃ§in Ã¶nemli olduÄŸu ve eski verilerin hala geÃ§erliliÄŸini koruduÄŸu durumlarda tercih edilir.

* ğŸ’¡ Uzman Notu: Bu yÃ¶ntem, veri miktarÄ± arttÄ±kÃ§a eÄŸitim sÃ¼resini (training time) uzatabilir ancak uzun vadeli trendleri (long-term trends) yakalamak iÃ§in idealdir.

  ### ğŸ”„ B. Rolling Window (Kayan Pencere)

Bu yÃ¶ntemde eÄŸitim setinin boyutu sabittir (fixed size). Pencere zaman ekseninde ilerledikÃ§e, yeni veri eÄŸitim setine eklenir ve en eski veri eÄŸitim setinden Ã§Ä±karÄ±lÄ±r.

#### âš™ï¸ Ã‡alÄ±ÅŸma Prensibi (Mechanism)
Modelin hafÄ±zasÄ± sÄ±nÄ±rlÄ±dÄ±r; geÃ§miÅŸi bir "kuyruk" gibi takip eder.

**GÃ¶rselleÅŸtirme (Visualization):**
```text
AdÄ±m 1: | Train (T1-T2) | -> [Test (T3)]
AdÄ±m 2:       | Train (T2-T3) | -> [Test (T4)]
AdÄ±m 3:             | Train (T3-T4) | -> [Test (T5)]
```

### ğŸ”„ B. Rolling Window (Kayan Pencere)

Bu strateji, modelin hafÄ±zasÄ±nÄ± sÄ±nÄ±rlar ve sadece belirli bir yakÄ±n geÃ§miÅŸe odaklanmasÄ±nÄ± saÄŸlar.

#### ğŸ”‘ Temel Nitelikler ve KullanÄ±m

* **Ã–zellik (Feature):** Model sadece en yakÄ±n geÃ§miÅŸi (**recent history** / **sliding window**), Ã¶rneÄŸin son 1 yÄ±lÄ± hatÄ±rlar. Pencere kaydÄ±kÃ§a, en eski verilerin etkisi silinir (**impact is removed**).
* **KullanÄ±m (Usage):** Veri setinde **Concept Drift** (Kavram KaymasÄ± / Rejim DeÄŸiÅŸikliÄŸi) varsa tercih edilir.
    * *Ã–rnek:* 5 yÄ±l Ã¶nceki piyasa koÅŸullarÄ± veya tÃ¼ketici davranÄ±ÅŸlarÄ± bugÃ¼nÃ¼ temsil etmiyorsa (**obsolete data**), modelin o verileri "unutmasÄ±" (**forgetting mechanism**) performans iÃ§in daha iyidir.

---

### ğŸ Teknik Uygulama Notu (Technical Implementation Note: Python/Sklearn)

Scikit-learn kÃ¼tÃ¼phanesindeki `TimeSeriesSplit` sÄ±nÄ±fÄ±, varsayÄ±lan ayarlarÄ±yla **Expanding Window** (GeniÅŸleyen Pencere) mantÄ±ÄŸÄ±yla Ã§alÄ±ÅŸÄ±r.

> **ğŸ’¡ Uzman Ä°pucu (Expert Tip):** EÄŸer `TimeSeriesSplit`'i **Rolling Window** olarak kullanmak istiyorsanÄ±z, `max_train_size` parametresini ayarlamanÄ±z gerekir. Aksi takdirde eÄŸitim seti sÃ¼rekli bÃ¼yÃ¼r.

Hiperparametre optimizasyonu (**Hyperparameter Optimization**) sÃ¼reÃ§lerinde (Ã¶rneÄŸin `GridSearchCV` veya `RandomizedSearchCV`) `cv` parametresine bu objeyi vermemiz gerekir.

---

### âœ… DoÄŸru Ä°ÅŸ AkÄ±ÅŸÄ± (Correct Workflow)

BaÅŸarÄ±lÄ± bir zaman serisi modellemesi iÃ§in izlenmesi gereken standart sÃ¼reÃ§ ÅŸÃ¶yledir:

1.  **Veriyi AyÄ±r (Split):** Veriyi kronolojik olarak (**chronologically**) ikiye ayÄ±r:
    * `X_train_full`: %80 (EÄŸitim ve Validasyon dÃ¶ngÃ¼sÃ¼ iÃ§in)
    * `X_test`: %20 (Sadece Final Test iÃ§in)
2.  **Test Setini Kilitle (Hold-out):** `X_test` setini "kasaya kilitle" (**lock away**). Model canlÄ±ya (**production**) alÄ±nana kadar bu veriye asla dokunma (**No peeking / Avoid Look-ahead Bias**).
3.  **Ã‡apraz DoÄŸrulama (Cross-Validation):** `X_train_full` Ã¼zerinde `TimeSeriesSplit` kullanarak Hiperparametre TaramasÄ± (**Validation**) yap.
4.  **Final DeÄŸerlendirme (Evaluation):** En iyi parametrelerle (**best parameters**) eÄŸitilen modeli `X_test` Ã¼zerinde test et ve son performansÄ± Ã¶lÃ§.

#### ğŸ’» Python Uygulama Kodu

```python
from sklearn.model_selection import TimeSeriesSplit

# 5 parÃ§alÄ± Cross-Validation
# EÄŸer Rolling Window isteniyorsa 'max_train_size' belirtilmeli!
tscv = TimeSeriesSplit(n_splits=5, max_train_size=None) # None = Expanding, Int = Rolling

for train_index, val_index in tscv.split(X):
    # Ä°ndeksleri kullanarak veriyi bÃ¶lme
    X_train, X_val = X[train_index], X[val_index]
    y_train, y_val = y[train_index], y[val_index]
    
    # Buradan sonra model eÄŸitimi ve validasyonu yapÄ±lÄ±r
    # model.fit(X_train, y_train)
    # ...

```

# âš”ï¸ Zaman Serisi Validasyon Stratejileri: KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz

Zaman serisi modellerini doÄŸrularken (validation) kullanÄ±lacak yÃ¶ntem, veri setinin doÄŸasÄ±na ve iÅŸ probleminin gerekliliklerine gÃ¶re seÃ§ilmelidir. AÅŸaÄŸÄ±daki tablolar ve gÃ¶rseller, **Rolling** (Kayan) ve **Expanding** (GeniÅŸleyen) pencere yÃ¶ntemleri ile **Basit Kronolojik BÃ¶lme** arasÄ±ndaki teknik farklarÄ± Ã¶zetlemektedir.

---

## 1. ğŸ†š KarÅŸÄ±laÅŸtÄ±rma: Rolling vs. Expanding Window

Bu bÃ¶lÃ¼m, iki ana Ã§apraz doÄŸrulama (cross-validation) stratejisinin teknik Ã¶zelliklerini kÄ±yaslar.

### ğŸ¨ GÃ¶rsel AnlatÄ±m (Visual Concept)

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'fontSize': '13px'}}}%%
gantt
    title Expanding vs Rolling Window
    dateFormat X
    axisFormat %s
    
    section Expanding (GeniÅŸleyen)
    Train (T1)       :a1, 0, 10
    Test             :crit, 10, 12
    Train (T1+T2)    :a2, 0, 12
    Test             :crit, 12, 14
    Train (T1+T2+T3) :a3, 0, 14
    Test             :crit, 14, 16

    section Rolling (Kayan)
    Train (T1)       :b1, 0, 10
    Test             :crit, 10, 12
    Train (T2)       :b2, 2, 12
    Test             :crit, 12, 14
    Train (T3)       :b3, 4, 14
    Test             :crit, 14, 16
```

