
# ğŸ“ˆ Model Evaluation for Time-Series Forecasting


<img width="1373" height="700" alt="image" src="https://github.com/user-attachments/assets/132a51e3-f996-4911-bb0a-c5ba8e49d395" />


Zaman serisi tahmini (Time-Series Forecasting), verinin sÄ±ralÄ± doÄŸasÄ± nedeniyle geleneksel makine Ã¶ÄŸrenimi gÃ¶revlerinden ayrÄ±lÄ±r. Bir modeli deÄŸerlendirmek, zamana duyarlÄ± teknikler ve stratejik bir yaklaÅŸÄ±m gerektirir.

Bu dÃ¶kÃ¼man, zaman serisi modellerinin deÄŸerlendirilmesinde kullanÄ±lan temel prensipleri, validasyon stratejilerini ve baÅŸarÄ± metriklerini teknik bir derinlikle ele alÄ±r.

---

## 1. Temel Zorluklar ve FarklÄ±lÄ±klar

Geleneksel makine Ã¶ÄŸreniminde veriler genellikle baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±ma sahip (IID) olarak kabul edilirken, zaman serilerinde bu durum geÃ§erli deÄŸildir.

### â³ Temporal Dependency (Zaman BaÄŸÄ±mlÄ±lÄ±ÄŸÄ±)
Zaman serilerinde gÃ¶zlemler zaman iÃ§inde sÄ±ralÄ±dÄ±r ve mevcut deÄŸer genellikle Ã¶nceki deÄŸerlere baÄŸlÄ±dÄ±r (otokorelasyon). 
* **Sorun:** Veriyi rastgele (random shuffle) "EÄŸitim" ve "Test" setlerine ayÄ±rmak, modelin geÃ§miÅŸten geleceÄŸi deÄŸil, "gelecekten geÃ§miÅŸi" Ã¶ÄŸrenmesine neden olur.
* **Ã‡Ã¶zÃ¼m:** Veri setleri her zaman kronolojik sÄ±raya gÃ¶re kesilmelidir.

### ğŸ’§ Data Leakage (Veri SÄ±zÄ±ntÄ±sÄ±)
GeleceÄŸe ait bilgilerin (test seti) eÄŸitim sÃ¼recine dahil olmasÄ± durumudur.
* **SonuÃ§:** Model eÄŸitimde harika performans gÃ¶sterir ancak canlÄ±ya (production) alÄ±ndÄ±ÄŸÄ±nda Ã§uvallar.
* **Kural:** Gelecek, geÃ§miÅŸi tahmin etmek iÃ§in kullanÄ±lamaz.

---

## 2. Validasyon Stratejileri (Cross-Validation Techniques)

Zaman serilerinde standart *k-fold cross-validation* kullanÄ±lmaz. Bunun yerine "Walk-Forward Validation" (Ä°leriye YÃ¼rÃ¼yen DoÄŸrulama) teknikleri uygulanÄ±r.

### A. Hold-Out YÃ¶ntemi (Basit Kronolojik BÃ¶lme)
Veri seti belirli bir zaman noktasÄ±ndan itibaren ikiye (veya Ã¼Ã§e) bÃ¶lÃ¼nÃ¼r.
* **EÄŸitim Seti:** $t_0$'dan $t_n$'e kadar.
* **Test Seti:** $t_{n+1}$'den $t_{n+m}$'e kadar.

### B. Time Series Cross-Validation (Walk-Forward)
Bu yÃ¶ntem, modelin zaman iÃ§indeki stabilitesini Ã¶lÃ§mek iÃ§in en gÃ¼venilir yoldur. Ä°ki ana yaklaÅŸÄ±mÄ± vardÄ±r:

#### 1. Expanding Window (GeniÅŸleyen Pencere)
EÄŸitim seti her adÄ±mda bÃ¼yÃ¼rken, test seti zaman ekseninde ileriye doÄŸru kayar.
* **KullanÄ±m AlanÄ±:** Veri geÃ§miÅŸinin tamamÄ± Ã¶nemliyse ve "Concept Drift" (Veri daÄŸÄ±lÄ±mÄ±nÄ±n zamanla deÄŸiÅŸmesi) az ise kullanÄ±lÄ±r.

```text
AdÄ±m 1: [Train: YÄ±l 1-3] -> [Test: YÄ±l 4]
AdÄ±m 2: [Train: YÄ±l 1-4] -> [Test: YÄ±l 5]
AdÄ±m 3: [Train: YÄ±l 1-5] -> [Test: YÄ±l 6]
```
####  2. Rolling Window (Kayan Pencere)
EÄŸitim setinin boyutu sabit tutulur. Yeni veri eklendikÃ§e, en eski veri eÄŸitim setinden Ã§Ä±karÄ±lÄ±r.

* **KullanÄ±m AlanÄ±:** Veri yapÄ±sÄ± zamanla deÄŸiÅŸiyorsa (rejim deÄŸiÅŸikliÄŸi) ve modelin sadece yakÄ±n geÃ§miÅŸe odaklanmasÄ± isteniyorsa kullanÄ±lÄ±r.
  
```text
AdÄ±m 1: [Train: YÄ±l 2-3] -> [Test: YÄ±l 4]
AdÄ±m 2:       [Train: YÄ±l 3-4] -> [Test: YÄ±l 5]
AdÄ±m 3:             [Train: YÄ±l 4-5] -> [Test: YÄ±l 6]
```

### ğŸ†š KarÅŸÄ±laÅŸtÄ±rma: Rolling vs. Expanding Window

Zaman serisi modellerinde doÄŸrulama (validation) yaparken veri setinin nasÄ±l bÃ¶lÃ¼ndÃ¼ÄŸÃ¼ modelin baÅŸarÄ±sÄ±nÄ± doÄŸrudan etkiler. AÅŸaÄŸÄ±da iki ana yÃ¶ntemin mekanizmasÄ± ve karÅŸÄ±laÅŸtÄ±rmalÄ± analizi yer almaktadÄ±r.

#### ğŸ¨ GÃ¶rsel AnlatÄ±m (Visual Explanation)

**1. Expanding Window (GeniÅŸleyen Pencere)**
Veri seti kÃ¼mÃ¼latif olarak bÃ¼yÃ¼r. BaÅŸlangÄ±Ã§ noktasÄ± sabittir.
```text
AdÄ±m 1: | Train (YÄ±l 1) | -> Test (YÄ±l 2)
AdÄ±m 2: | Train (YÄ±l 1 + 2)      | -> Test (YÄ±l 3)
AdÄ±m 3: | Train (YÄ±l 1 + 2 + 3)           | -> Test (YÄ±l 4)

```

# ğŸ“Š Model Evaluation Metrics & Residual Analysis for Time-Series

Zaman serisi tahminlemesinde (Time-Series Forecasting) model baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek, sadece "doÄŸru tahmini" bulmak deÄŸil, hatanÄ±n karakterini ve iÅŸ problemine etkisini anlamaktÄ±r. Tek bir metrik asla resmin tamamÄ±nÄ± gÃ¶stermez.

Bu dÃ¶kÃ¼man, tahmin modellerini deÄŸerlendirirken kullanÄ±lan **Performans Metriklerini**, **Hata Analizi YÃ¶ntemlerini** ve **Karar Destek TablolarÄ±nÄ±** teknik bir derinlikle ele alÄ±r.

---

## 1. Temel Hata Metrikleri (Scale-Dependent)
Bu metrikler verinin Ã¶lÃ§eÄŸine baÄŸlÄ±dÄ±r. Yani, elma satÄ±ÅŸlarÄ±nÄ± (binlerce) ve araba satÄ±ÅŸlarÄ±nÄ± (onlarca) aynÄ± metrik deÄŸeriyle kÄ±yaslayamazsÄ±nÄ±z.

### ğŸ“‰ MAE (Mean Absolute Error)
HatalarÄ±n mutlak deÄŸerlerinin ortalamasÄ±dÄ±r. 
* **Ã–zellik:** TÃ¼m hatalara eÅŸit aÄŸÄ±rlÄ±k verir.
* **KullanÄ±m:** Modelin "ortalama kaÃ§ birim saptÄ±ÄŸÄ±nÄ±" en saf haliyle anlatÄ±r.
$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

### âš¡ RMSE (Root Mean Squared Error)
HatalarÄ±n karesinin ortalamasÄ±nÄ±n karekÃ¶kÃ¼dÃ¼r.
* **Ã–zellik:** HatalarÄ±n karesini aldÄ±ÄŸÄ± iÃ§in **bÃ¼yÃ¼k hatalarÄ± (outliers)** kÃ¼Ã§Ã¼k hatalara gÃ¶re Ã§ok daha aÄŸÄ±r cezalandÄ±rÄ±r.
* **KullanÄ±m:** BÃ¼yÃ¼k bir hata yapmanÄ±n maliyetinin Ã§ok yÃ¼ksek olduÄŸu durumlarda (Ã¶rneÄŸin enerji ÅŸebekesi yÃ¼k tahmini) tercih edilir.
$$RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

> **Uzman Notu (MAE vs RMSE):** EÄŸer RMSE deÄŸeri MAE deÄŸerinden Ã§ok bÃ¼yÃ¼kse, modeliniz bazÄ± Ã¶rneklerde Ã§ok bÃ¼yÃ¼k hatalar yapÄ±yor (outlier Ã¼retiyor) demektir.

---

## 2. YÃ¼zdesel ve Ã–lÃ§ekten BaÄŸÄ±msÄ±z Metrikler (Scale-Independent)
FarklÄ± Ã¶lÃ§ekteki (yÃ¼ksek hacimli vs. dÃ¼ÅŸÃ¼k hacimli) serileri karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r.

### ğŸ“Š MAPE (Mean Absolute Percentage Error)
HatalarÄ± yÃ¼zdesel olarak ifade eder. Ä°ÅŸ birimlerinin (Business Stakeholders) en sevdiÄŸi metriktir.
* **Dezavantaj 1:** GerÃ§ek deÄŸer ($y_i$) 0 olduÄŸunda tanÄ±msÄ±zdÄ±r (sonsuza gider).
* **Dezavantaj 2 (Asimetri):** GereÄŸinden az tahmin etmeyi (under-forecast), fazla tahmin etmeye (over-forecast) gÃ¶re daha fazla cezalandÄ±rÄ±r.
$$MAPE = \frac{100\%}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|$$

### âš–ï¸ sMAPE (Symmetric MAPE)
MAPE'nin asimetrik yapÄ±sÄ±nÄ± ve 0'a bÃ¶lÃ¼nme sorununu (kÄ±smen) dÃ¼zeltmek iÃ§in geliÅŸtirilmiÅŸtir. DeÄŸerler %0 ile %200 arasÄ±nda deÄŸiÅŸir.
$$sMAPE = \frac{100\%}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2}$$

### ğŸŒŸ MASE (Mean Absolute Scaled Error) - AltÄ±n Standart
Modelin hatasÄ±nÄ±, "Naive Model"in (bir Ã¶nceki deÄŸeri tahmin olarak kabul eden saf model: $\hat{y}_t = y_{t-1}$) hatasÄ±na oranlar.
* **MASE < 1:** Modeliniz, "dÃ¼nÃ¼ bugÃ¼ne kopyalayan" saf modelden daha zeki.
* **MASE > 1:** Modeliniz baÅŸarÄ±sÄ±z, Naive yaklaÅŸÄ±m daha iyi sonuÃ§ veriyor.
* **AvantajÄ±:** Mevsimsellik iÃ§eren verilerde ve 0 deÄŸerlerinde oldukÃ§a stabildir.
$$MASE = \frac{MAE_{model}}{MAE_{naive}}$$

---

## 3. Ä°leri Seviye ve Ä°ÅŸ OdaklÄ± Metrikler

### âš–ï¸ WMAPE (Weighted MAPE)
Standart MAPE, hacmi 1 olan Ã¼rÃ¼nle hacmi 1.000.000 olan Ã¼rÃ¼nÃ¼n hatasÄ±na eÅŸit davranÄ±r. Perakende ve Tedarik Zinciri yÃ¶netiminde bu istenmez. WMAPE, hatayÄ± hacme gÃ¶re aÄŸÄ±rlÄ±klandÄ±rÄ±r.
$$WMAPE = \frac{\sum_{i=1}^{n} |y_i - \hat{y}_i|}{\sum_{i=1}^{n} |y_i|}$$

---

## 4. Residual (ArtÄ±k) Analizi: Modeliniz Bilgiyi TÃ¼ketti mi?

Ä°yi bir zaman serisi modelinde, hatalar (residuals) **White Noise (Beyaz GÃ¼rÃ¼ltÃ¼)** olmalÄ±dÄ±r. EÄŸer hatalarda bir "desen" kaldÄ±ysa, model verideki sinyali tam yakalayamamÄ±ÅŸ demektir.

### âœ… White Noise Kriterleri
1.  **SÄ±fÄ±r OrtalamalÄ±:** $E[e_t] = 0$. Hatalar 0 etrafÄ±nda rastgele daÄŸÄ±lmalÄ±. (Bias olmamalÄ±).
2.  **Ä°liÅŸkisiz (Uncorrelated):** Hatalar geÃ§miÅŸ hatalarla korele olmamalÄ±dÄ±r. (ACF grafiÄŸi temiz Ã§Ä±kmalÄ±).
3.  **Sabit Varyans (Homoscedasticity):** HatalarÄ±n boyutu zamanla artmamalÄ± veya azalmamalÄ±dÄ±r.
4.  **Normal DaÄŸÄ±lÄ±m:** Hatalar Ã‡an EÄŸrisi (Gaussian) ÅŸeklinde daÄŸÄ±lmalÄ±dÄ±r (GÃ¼ven aralÄ±klarÄ±nÄ±n doÄŸruluÄŸu iÃ§in ÅŸarttÄ±r).

### ğŸ§ª Ä°statistiksel Test: Ljung-Box Testi
Sadece grafiÄŸe bakmak yetmez. Otokorelasyonun olup olmadÄ±ÄŸÄ±nÄ± istatistiksel olarak test etmeliyiz.
* **H0 (Null Hypothesis):** Veri rastgele daÄŸÄ±lmÄ±ÅŸtÄ±r (White Noise'dur).
* **p-value < 0.05:** H0 reddedilir. Hatalarda otokorelasyon var -> **Model Yetersiz.**
* **p-value > 0.05:** H0 reddedilemez. Hatalar rastgele -> **Model BaÅŸarÄ±lÄ±.**

---

## 5. KarÅŸÄ±laÅŸtÄ±rmalÄ± Karar Tablosu: Hangi YÃ¶ntem Ne Zaman?

| Senaryo | Ã–nerilen Metrik | Neden? |
| :--- | :--- | :--- |
| **BÃ¼yÃ¼k hatalar felaketse** (Ã–rn: Enerji ÅŸebekesi Ã§Ã¶kmesi) | **RMSE** | Karesini aldÄ±ÄŸÄ± iÃ§in outlier'larÄ± Ã§ok sert cezalandÄ±rÄ±r. |
| **Yorumlanabilirlik Ã¶nemliyse** (YÃ¶netim sunumlarÄ±) | **MAE / MAPE** | "Ortalama X adet yanÄ±lÄ±yoruz" demek kolaydÄ±r. |
| **FarklÄ± hacimli binlerce Ã¼rÃ¼n varsa** (Perakende) | **WMAPE** | Ã‡ok satan Ã¼rÃ¼nlerin baÅŸarÄ±sÄ±, az satanlardan daha Ã¶nemlidir. |
| **Veride Ã§ok fazla 0 varsa** (Intermittent Demand) | **MASE** | MAPE sonsuza gider, MASE stabildir. |
| **Modelin ne kadar "zeki" olduÄŸunu Ã¶lÃ§mek iÃ§in** | **MASE** | Basit bir kurala (Naive) gÃ¶re ne kadar katma deÄŸer saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶sterir. |

---

> **Pro Tip:** Asla tek bir metriÄŸe gÃ¼venmeyin. Genellikle **RMSE** (model optimizasyonu iÃ§in) ve **MAPE/WMAPE** (iÅŸ birimlerine raporlama iÃ§in) birlikte kullanÄ±lÄ±r. Residual analizi ise modelin gÃ¼venilirliÄŸi ("CanlÄ±ya alÄ±nÄ±r mÄ±?") sorusunun cevabÄ±dÄ±r.


# ğŸ“‰ Time-Series Forecasting: Model Evaluation Quiz Solutions

Bu dokÃ¼man, **Time-Series Forecasting (Zaman Serisi Tahminleme)** modellerinin deÄŸerlendirilmesi, hata metrikleri ve validasyon stratejileri Ã¼zerine odaklanan **Quiz 5** sorularÄ±nÄ±n detaylÄ± Ã§Ã¶zÃ¼mlerini ve teknik aÃ§Ä±klamalarÄ±nÄ± iÃ§erir.

> **Ã–zet:** Bu quiz, Ã¶zellikle "Data Leakage", "RMSE vs MAPE karÅŸÄ±laÅŸtÄ±rmasÄ±" ve "Validasyon YÃ¶ntemleri" konularÄ±ndaki kavramsal anlayÄ±ÅŸÄ± test etmektedir.

---

## ğŸ§© Quiz SorularÄ± ve Teknik Ã‡Ã¶zÃ¼mler

### 1. Neden rastgele eÄŸitim-test bÃ¶lmesi (random train-test split) zaman serisi verileri iÃ§in uygun deÄŸildir?
**Soru:** Why is random train-test splitting not suitable for time-series data?
* A - it takes longer to compute
* **B - it can lead to data leakage by using future data for training** âœ…
* C - it requires specific algorithms to process time-series
* D - it reduces the size of the training dataset

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Zaman serilerinde veriler arasÄ±nda zamansal bir baÄŸÄ±mlÄ±lÄ±k (temporal dependency) vardÄ±r. Veriyi rastgele karÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda, gelecekteki bir veri noktasÄ±nÄ± eÄŸitim setine, geÃ§miÅŸteki bir noktayÄ± test setine koyabilirsiniz. Bu durum, modelin geleceÄŸi gÃ¶rerek geÃ§miÅŸi tahmin etmesine (**Data Leakage**) neden olur ve yanÄ±ltÄ±cÄ± derecede yÃ¼ksek baÅŸarÄ± oranlarÄ± verir.

---

### 2. Hangi bÃ¶lme yÃ¶ntemi, verinin Ã¶nceki bÃ¶lÃ¼mlerini eÄŸitim ve sonraki bÃ¶lÃ¼mlerini test iÃ§in kullanmayÄ± iÃ§erir?
**Soru:** Which splitting method involves using earlier portions of the data for training and later portions for testing?
* A - random train-test split
* **B - k-fold cross-validation** âœ…
* C - chronological split
* D - rolling window split

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Burada kastedilen standart k-fold deÄŸil, zaman serileri iÃ§in uyarlanmÄ±ÅŸ **Time Series Cross-Validation** (genellikle Nested Cross-Validation veya Blocked CV olarak da bilinir) yÃ¶ntemidir. Bu yÃ¶ntemde veri bloklarÄ± zaman sÄ±rasÄ±na gÃ¶re korunur; model geÃ§miÅŸ bloklarda eÄŸitilir ve gelecek bloklarda test edilir.

---

### 3. Zaman serisi deÄŸerlendirmesi iÃ§in "Rolling Window" (Kayan Pencere) kullanmanÄ±n temel avantajÄ± nedir?
**Soru:** What is the main advantage of using a rolling window split for time-series evaluation?
* A - it reduces computation time
* B - it avoids overfitting
* **C - it mimics real-world scenarios with models predicting future unseen data** âœ…
* D - it uses all data for both training and testing

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Rolling Window yÃ¶ntemi, modelin her adÄ±mda yeni gelen veriyi Ã¶ÄŸrenip bir sonraki adÄ±mÄ± tahmin ettiÄŸi canlÄ± (production) ortamÄ± simÃ¼le eder. Bu, modelin zaman iÃ§inde deÄŸiÅŸen trendlere karÅŸÄ± dayanÄ±klÄ±lÄ±ÄŸÄ±nÄ± Ã¶lÃ§menin en gerÃ§ekÃ§i yoludur.

---

### 4. Tahminlemede "Pozitif Bias" neyi gÃ¶sterir?
**Soru:** What does a positive bias in forecasting indicate?
* A - the model systematically under-predicts demand
* B - the model is unbiased and accurate
* C - the model performs better on larger datasets
* **D - the model systematically over-predicts demand** âœ…

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Bias formÃ¼lÃ¼ kaynaÄŸa gÃ¶re deÄŸiÅŸebilir ancak bu cevap anahtarÄ±na gÃ¶re Bias ÅŸu ÅŸekilde tanÄ±mlanmÄ±ÅŸtÄ±r: `Bias = Tahmin (Forecast) - GerÃ§ek (Actual)`.
> EÄŸer sonuÃ§ **Pozitif (+)** ise, Tahmin > GerÃ§ek demektir. Bu da modelin talebi olduÄŸundan fazla tahmin ettiÄŸini (**Over-prediction**) gÃ¶sterir.

---

### 5. MAD ve RMSE arasÄ±ndaki temel fark nedir?
**Soru:** What is the primary difference between MAD and RMSE?
* A - MAD penalizes larger errors more than RMSE
* **B - RMSE penalizes larger errors more than MAD** âœ…
* C - MAD measures relative errors, while RMSE measures absolute errors
* D - MAD focuses on predicting average values, while RMSE focuses on predicting medians

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> * **MAD (Mean Absolute Deviation):** HatalarÄ±n mutlak deÄŸerini alÄ±r ($|e|$). DoÄŸrusal bir ceza uygular.
> * **RMSE (Root Mean Squared Error):** HatalarÄ±n karesini alÄ±r ($e^2$). Karesi alÄ±nan bÃ¼yÃ¼k hatalar sonucu orantÄ±sÄ±z ÅŸekilde bÃ¼yÃ¼tÃ¼r. Bu nedenle RMSE, bÃ¼yÃ¼k hatalarÄ± (outlier) Ã§ok daha aÄŸÄ±r cezalandÄ±rÄ±r.

---

### 6. Hangi metrik, Ortalama Mutlak SapmayÄ± (MAD) gerÃ§ek deÄŸerlerin ortalamasÄ±na bÃ¶lerek normalleÅŸtirir?
**Soru:** Which metric normalizes the Mean Absolute Deviation (MAD) by the mean of the actual values?
* A - MAPE
* B - RMSE
* **C - rMAD** âœ…
* D - Bias

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> **rMAD (Relative MAD)**, hatanÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ verinin ortalamasÄ±na gÃ¶re oranlar. FormÃ¼lÃ¼: $rMAD = \frac{MAD}{Mean}$. Bu, MAPE'ye bir alternatiftir ancak MAPE kadar yaygÄ±n kullanÄ±lmaz.

---

### 7. Neden MAPE zaman serisi tahminlemesi iÃ§in her zaman gÃ¼venilir bir metrik deÄŸildir?
**Soru:** Why is MAPE not always a reliable metric for time-series forecasting?
* A - it is difficult to interpret
* B - it penalizes large errors less than RMSE
* **C - it is sensitive to small actual values and asymmetry in error treatment** âœ…
* D - it cannot be used with rolling window splits

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> **MAPE (Mean Absolute Percentage Error)** formÃ¼lÃ¼nde paydada "GerÃ§ek DeÄŸer" ($y_t$) bulunur.
> 1.  EÄŸer $y_t = 0$ ise sonuÃ§ tanÄ±msÄ±zdÄ±r (sonsuz).
> 2.  EÄŸer $y_t$ Ã§ok kÃ¼Ã§Ã¼kse, hata oranÄ± yapay olarak devasa Ã§Ä±kar (Ã–rn: GerÃ§ek 1, Tahmin 2 ise hata %100'dÃ¼r).

---

### 8. Bir tahminleme gÃ¶revinde, bir model en iyi RMSE'ye ama en kÃ¶tÃ¼ MAPE'ye sahiptir. Bu ne anlama gelir?
**Soru:** In a forecasting task, a model has the best RMSE but the worst MAPE. What does this imply?
* A - the model is inaccurate overall
* **B - the model handles small actual values poorly but minimizes large errors effectively** âœ…
* C - the model predicts median values better than averages
* D - the model overfits the training data

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> * **Ä°yi RMSE:** Model bÃ¼yÃ¼k hatalar (outlier) yapmÄ±yor demektir.
> * **KÃ¶tÃ¼ MAPE:** Model, gerÃ§ek deÄŸerin (hacmin) Ã§ok dÃ¼ÅŸÃ¼k olduÄŸu zamanlarda oransal olarak bÃ¼yÃ¼k hatalar yapÄ±yor demektir.
> * **Ã–rnek:** Model 10.000 adetlik satÄ±ÅŸta 100 hata yaparsa (KÃ¼Ã§Ã¼k % hata), ama 5 adetlik satÄ±ÅŸta 4 hata yaparsa (BÃ¼yÃ¼k % hata - %80), MAPE bozulur ama RMSE Ã§ok etkilenmez.

---

### 9. BÃ¼yÃ¼k hatalarÄ±n Ã¶zellikle maliyetli olduÄŸu durumlarda hangi metrik en uygundur?
**Soru:** Which metric is most appropriate when large errors are especially costly?
* A - Bias
* B - MAD
* C - MAPE
* **D - RMSE** âœ…

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Enerji santralleri veya hayati medikal cihazlar gibi "bÃ¼yÃ¼k bir hatanÄ±n felaket olduÄŸu" durumlarda, o tek bÃ¼yÃ¼k hatayÄ± matematiksel olarak parlatÄ±p modele "bunu dÃ¼zelt" diyen metrik **RMSE**'dir (karesini aldÄ±ÄŸÄ± iÃ§in).

---

### 10. Zaman serisi tahminlemesi iÃ§in hangi deÄŸerlendirme metriÄŸine Ã¶ncelik verileceÄŸine nasÄ±l karar vermelisiniz?
**Soru:** How should you decide which evaluation metric to prioritize for time-series forecasting?
* A - choose the metric with the smallest value
* **B - consider the specific business goals and consequences of forecasting errors** âœ…
* C - prioritize metrics that are easy to calculate
* D - use MAPE in all cases

> **ğŸ’¡ Teknik AÃ§Ä±klama:**
> Veri biliminde "tek doÄŸru metrik" yoktur.
> * EÄŸer envanter yÃ¶netiyorsanÄ±z ve Ã¼rÃ¼nler ucuzsa **MAE** yeterlidir.
> * EÄŸer finansal bir Ã§Ã¶kÃ¼ÅŸÃ¼ tahmin ediyorsanÄ±z **RMSE** kritiktir.
> * EÄŸer yÃ¶netim kuruluna sunum yapÄ±yorsanÄ±z yÃ¼zdesel olduÄŸu iÃ§in **MAPE** tercih edilir.
> Karar her zaman **iÅŸ hedeflerine (Business Goals)** gÃ¶re verilir.

---
# â³ Time-Series Model Evaluation: Train-Test Splits

Geleneksel makine Ã¶ÄŸreniminde (Traditional ML) verilerin **I.I.D.** (Independent and Identically Distributed - BaÄŸÄ±msÄ±z ve Ã–zdeÅŸ DaÄŸÄ±lÄ±mlÄ±) olduÄŸu varsayÄ±lÄ±r. Bu nedenle rastgele (random) bÃ¶lme yapÄ±labilir. Ancak **Zaman Serilerinde** durum farklÄ±dÄ±r; veriler arasÄ±nda **zamansal bir baÄŸÄ±mlÄ±lÄ±k (autocorrelation)** vardÄ±r.

Bu dokÃ¼man, zaman serisi tahmin modellerini deÄŸerlendirirken kullanÄ±lan doÄŸru validasyon stratejilerini, teknik ayrÄ±mlarÄ± ve uygulama yÃ¶ntemlerini iÃ§erir.

---

## ğŸš« Neden Rastgele (Random) Split YapamayÄ±z?
Zaman serilerinde rastgele bÃ¶lme yapmak **Data Leakage (Veri SÄ±zÄ±ntÄ±sÄ±)** yaratÄ±r.
* **Sorun:** Gelecekteki bir veri noktasÄ±nÄ± eÄŸitim (train) setine, geÃ§miÅŸteki bir noktayÄ± test setine koyarsanÄ±z; model "geleceÄŸi gÃ¶rerek" geÃ§miÅŸi tahmin etmeye Ã§alÄ±ÅŸÄ±r.
* **SonuÃ§:** Model eÄŸitimde harika sonuÃ§lar verir ancak canlÄ± (production) ortamda baÅŸarÄ±sÄ±z olur.
* **Kural:** BÃ¶lme iÅŸlemi her zaman **Zaman DuyarlÄ± (Time-Aware)** olmalÄ±dÄ±r. Gelecek, geÃ§miÅŸi eÄŸitmek iÃ§in kullanÄ±lamaz.

---

## ğŸ› ï¸ BÃ¶lme YÃ¶ntemleri (Splitting Techniques)

### Method 1 & 2: Simple Chronological Split (Hold-Out)
Veri seti, zaman ekseninde tek bir kesim noktasÄ± belirlenerek ikiye ayrÄ±lÄ±r. Tarih bazlÄ± (Date-based) veya oran bazlÄ± (%70-%30) yapÄ±labilir.

* **YapÄ±sÄ±:** Ä°lk %80 EÄŸitim, Son %20 Test.
* **KullanÄ±mÄ±:** Veri seti Ã§ok bÃ¼yÃ¼kse ve zaman iÃ§inde istatistiksel Ã¶zellikleri (daÄŸÄ±lÄ±mÄ±) Ã§ok deÄŸiÅŸmiyorsa (Stationary) uygundur.

```text
[EÄŸitim Verisi ........................] | [Test Verisi]
t_0 ---------------------------------> t_split ------> t_end
```

<img width="1185" height="316" alt="image" src="https://github.com/user-attachments/assets/88b578eb-d4eb-47c0-ba87-9d5f12235bd3" />

## ğŸ”„ Method 3: Cross-Validation Strategies (Geriye DÃ¶nÃ¼k Test Stratejileri)

Zaman serisi analizinde tek bir test seti (single test set) kullanmak bazen yanÄ±ltÄ±cÄ± sonuÃ§lar doÄŸurabilir. Ã–rneÄŸin, seÃ§ilen test dÃ¶nemi Ã§ok olaÄŸandÄ±ÅŸÄ± bir dÃ¶neme (outlier/anomaly period) denk gelebilir ve bu da modelin genel baÅŸarÄ±sÄ±nÄ± yansÄ±tmaz.

Bu riski minimize etmek iÃ§in **Cross-Validation (Ã‡apraz DoÄŸrulama)** uygulanÄ±r. Ancak, zaman serilerinin sÄ±ralÄ± yapÄ±sÄ± gereÄŸi standart *K-Fold* yerine **Walk-Forward Validation (Ä°leriye YÃ¼rÃ¼yen DoÄŸrulama)** yÃ¶ntemi kullanÄ±lÄ±r.

Bu yÃ¶ntemde temel olarak iki ana yaklaÅŸÄ±m vardÄ±r. LiteratÃ¼rde genellikle karÄ±ÅŸtÄ±rÄ±lsa da teknik farklarÄ± belirgindir. AÅŸaÄŸÄ±da, en yaygÄ±n kullanÄ±lan yaklaÅŸÄ±m detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r:

### ğŸ“ˆ A. Expanding Window (GeniÅŸleyen Pencere)

Bu yÃ¶ntem, Scikit-Learn kÃ¼tÃ¼phanesindeki `TimeSeriesSplit` fonksiyonunun varsayÄ±lan Ã§alÄ±ÅŸma mantÄ±ÄŸÄ±dÄ±r.

#### âš™ï¸ Ã‡alÄ±ÅŸma Prensibi (Mechanism)
EÄŸitim seti (training set) her iterasyonda kÃ¼mÃ¼latif olarak bÃ¼yÃ¼rken, test seti (test set) zaman ekseninde ileriye doÄŸru kayar. BaÅŸlangÄ±Ã§ noktasÄ± sabittir, ancak bitiÅŸ noktasÄ± her adÄ±mda ilerler.

**GÃ¶rselleÅŸtirme (Visualization):**

```text
AdÄ±m 1: | Train (T1)       | -> [Test (T2)]
AdÄ±m 2: | Train (T1 + T2)  | -------------> [Test (T3)]
AdÄ±m 3: | Train (T1 + T2 + T3)            | -------------> [Test (T4)]
```

#### ğŸ”‘ Temel Nitelikler
* **HafÄ±za (Memory):** Model, tÃ¼m geÃ§miÅŸ veriyi (historical data) hatÄ±rlar ve kullanÄ±r. Veri seti kesilmez, sÃ¼rekli eklenir.

* KÃ¼tÃ¼phane DesteÄŸi (Library Support): Python'da sklearn.model_selection.TimeSeriesSplit bu mantÄ±kla Ã§alÄ±ÅŸÄ±r.

* **KullanÄ±m Senaryosu (Use Case):** Veri geÃ§miÅŸinin tamamÄ±nÄ±n (entire history) model baÅŸarÄ±sÄ± iÃ§in Ã¶nemli olduÄŸu ve eski verilerin hala geÃ§erliliÄŸini koruduÄŸu durumlarda tercih edilir.

* ğŸ’¡ Uzman Notu: Bu yÃ¶ntem, veri miktarÄ± arttÄ±kÃ§a eÄŸitim sÃ¼resini (training time) uzatabilir ancak uzun vadeli trendleri (long-term trends) yakalamak iÃ§in idealdir.

  ### ğŸ”„ B. Rolling Window (Kayan Pencere)

Bu yÃ¶ntemde eÄŸitim setinin boyutu sabittir (fixed size). Pencere zaman ekseninde ilerledikÃ§e, yeni veri eÄŸitim setine eklenir ve en eski veri eÄŸitim setinden Ã§Ä±karÄ±lÄ±r.

#### âš™ï¸ Ã‡alÄ±ÅŸma Prensibi (Mechanism)
Modelin hafÄ±zasÄ± sÄ±nÄ±rlÄ±dÄ±r; geÃ§miÅŸi bir "kuyruk" gibi takip eder.

**GÃ¶rselleÅŸtirme (Visualization):**
```text
AdÄ±m 1: | Train (T1-T2) | -> [Test (T3)]
AdÄ±m 2:       | Train (T2-T3) | -> [Test (T4)]
AdÄ±m 3:             | Train (T3-T4) | -> [Test (T5)]
```

### ğŸ”„ B. Rolling Window (Kayan Pencere)

Bu strateji, modelin hafÄ±zasÄ±nÄ± sÄ±nÄ±rlar ve sadece belirli bir yakÄ±n geÃ§miÅŸe odaklanmasÄ±nÄ± saÄŸlar.

#### ğŸ”‘ Temel Nitelikler ve KullanÄ±m

* **Ã–zellik (Feature):** Model sadece en yakÄ±n geÃ§miÅŸi (**recent history** / **sliding window**), Ã¶rneÄŸin son 1 yÄ±lÄ± hatÄ±rlar. Pencere kaydÄ±kÃ§a, en eski verilerin etkisi silinir (**impact is removed**).
* **KullanÄ±m (Usage):** Veri setinde **Concept Drift** (Kavram KaymasÄ± / Rejim DeÄŸiÅŸikliÄŸi) varsa tercih edilir.
    * *Ã–rnek:* 5 yÄ±l Ã¶nceki piyasa koÅŸullarÄ± veya tÃ¼ketici davranÄ±ÅŸlarÄ± bugÃ¼nÃ¼ temsil etmiyorsa (**obsolete data**), modelin o verileri "unutmasÄ±" (**forgetting mechanism**) performans iÃ§in daha iyidir.

---

### ğŸ Teknik Uygulama Notu (Technical Implementation Note: Python/Sklearn)

Scikit-learn kÃ¼tÃ¼phanesindeki `TimeSeriesSplit` sÄ±nÄ±fÄ±, varsayÄ±lan ayarlarÄ±yla **Expanding Window** (GeniÅŸleyen Pencere) mantÄ±ÄŸÄ±yla Ã§alÄ±ÅŸÄ±r.

> **ğŸ’¡ Uzman Ä°pucu (Expert Tip):** EÄŸer `TimeSeriesSplit`'i **Rolling Window** olarak kullanmak istiyorsanÄ±z, `max_train_size` parametresini ayarlamanÄ±z gerekir. Aksi takdirde eÄŸitim seti sÃ¼rekli bÃ¼yÃ¼r.

Hiperparametre optimizasyonu (**Hyperparameter Optimization**) sÃ¼reÃ§lerinde (Ã¶rneÄŸin `GridSearchCV` veya `RandomizedSearchCV`) `cv` parametresine bu objeyi vermemiz gerekir.

---

### âœ… DoÄŸru Ä°ÅŸ AkÄ±ÅŸÄ± (Correct Workflow)

BaÅŸarÄ±lÄ± bir zaman serisi modellemesi iÃ§in izlenmesi gereken standart sÃ¼reÃ§ ÅŸÃ¶yledir:

1.  **Veriyi AyÄ±r (Split):** Veriyi kronolojik olarak (**chronologically**) ikiye ayÄ±r:
    * `X_train_full`: %80 (EÄŸitim ve Validasyon dÃ¶ngÃ¼sÃ¼ iÃ§in)
    * `X_test`: %20 (Sadece Final Test iÃ§in)
2.  **Test Setini Kilitle (Hold-out):** `X_test` setini "kasaya kilitle" (**lock away**). Model canlÄ±ya (**production**) alÄ±nana kadar bu veriye asla dokunma (**No peeking / Avoid Look-ahead Bias**).
3.  **Ã‡apraz DoÄŸrulama (Cross-Validation):** `X_train_full` Ã¼zerinde `TimeSeriesSplit` kullanarak Hiperparametre TaramasÄ± (**Validation**) yap.
4.  **Final DeÄŸerlendirme (Evaluation):** En iyi parametrelerle (**best parameters**) eÄŸitilen modeli `X_test` Ã¼zerinde test et ve son performansÄ± Ã¶lÃ§.

#### ğŸ’» Python Uygulama Kodu

```python
from sklearn.model_selection import TimeSeriesSplit

# 5 parÃ§alÄ± Cross-Validation
# EÄŸer Rolling Window isteniyorsa 'max_train_size' belirtilmeli!
tscv = TimeSeriesSplit(n_splits=5, max_train_size=None) # None = Expanding, Int = Rolling

for train_index, val_index in tscv.split(X):
    # Ä°ndeksleri kullanarak veriyi bÃ¶lme
    X_train, X_val = X[train_index], X[val_index]
    y_train, y_val = y[train_index], y[val_index]
    
    # Buradan sonra model eÄŸitimi ve validasyonu yapÄ±lÄ±r
    # model.fit(X_train, y_train)
    # ...

```

# âš”ï¸ Zaman Serisi Validasyon Stratejileri: KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz

Zaman serisi modellerini doÄŸrularken (validation) kullanÄ±lacak yÃ¶ntem, veri setinin doÄŸasÄ±na ve iÅŸ probleminin gerekliliklerine gÃ¶re seÃ§ilmelidir. AÅŸaÄŸÄ±daki tablolar ve gÃ¶rseller, **Rolling** (Kayan) ve **Expanding** (GeniÅŸleyen) pencere yÃ¶ntemleri ile **Basit Kronolojik BÃ¶lme** arasÄ±ndaki teknik farklarÄ± Ã¶zetlemektedir.

---

## 1. ğŸ†š KarÅŸÄ±laÅŸtÄ±rma: Rolling vs. Expanding Window

Bu bÃ¶lÃ¼m, iki ana Ã§apraz doÄŸrulama (cross-validation) stratejisinin teknik Ã¶zelliklerini kÄ±yaslar.

### ğŸ¨ Visual Concept

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'fontSize': '13px'}}}%%
gantt
    title Expanding vs Rolling Window
    dateFormat X
    axisFormat %s
    
    section Expanding (GeniÅŸleyen)
    Train (T1)       :a1, 0, 10
    Test             :crit, 10, 12
    Train (T1+T2)    :a2, 0, 12
    Test             :crit, 12, 14
    Train (T1+T2+T3) :a3, 0, 14
    Test             :crit, 14, 16

    section Rolling (Kayan)
    Train (T1)       :b1, 0, 10
    Test             :crit, 10, 12
    Train (T2)       :b2, 2, 12
    Test             :crit, 12, 14
    Train (T3)       :b3, 4, 14
    Test             :crit, 14, 16
```
# ğŸ“‰ Evaluation Metrics for Retail Demand Forecasting

Perakende sektÃ¶rÃ¼nde talep tahmini (Retail Demand Forecasting), envanter yÃ¶netimi, fiyatlandÄ±rma stratejileri ve tedarik zinciri optimizasyonu iÃ§in kritik Ã¶neme sahiptir. Veriyi doÄŸru bÃ¶lmek ve modeli eÄŸitmek sadece baÅŸlangÄ±Ã§tÄ±r; asÄ±l mesele modelin baÅŸarÄ±sÄ±nÄ± **doÄŸru metriklerle** Ã¶lÃ§mektir.

FarklÄ± metrikler, hatanÄ±n farklÄ± yÃ¶nlerini (bÃ¼yÃ¼klÃ¼k, yÃ¶n, aÄŸÄ±rlÄ±k) yakalar. AÅŸaÄŸÄ±da, perakende talep tahminlemesinde kullanÄ±lan en kritik metrikler, teknik detaylarÄ± ve kullanÄ±m senaryolarÄ± yer almaktadÄ±r.

---

## 1. Bias (YanlÄ±lÄ±k / Sapma)
Bias, tahmin edilen deÄŸerler ($\hat{y}$) ile gerÃ§ek deÄŸerler ($y$) arasÄ±ndaki sistematik sapmayÄ± Ã¶lÃ§er. HatalarÄ±n ortalamasÄ±dÄ±r.

$$Bias = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)$$

*Burada:*
* $y$: GerÃ§ek satÄ±ÅŸ/talep deÄŸeri
* $\hat{y}$: Modelin tahmin ettiÄŸi deÄŸer
* $n$: GÃ¶zlem sayÄ±sÄ±

### ğŸ¯ Neden Ã–nemlidir?
Bias, modelinizin "yÃ¶nsel" bir hatasÄ± olup olmadÄ±ÄŸÄ±nÄ± gÃ¶sterir.
* **Pozitif Bias (Over-prediction):** Model sÃ¼rekli gerekenden fazlasÄ±nÄ± tahmin ediyordur.
    * *Perakende Riski:* Gereksiz stok maliyeti (Overstocking), imha maliyetleri, nakit akÄ±ÅŸÄ±nÄ±n stoÄŸa baÄŸlanmasÄ±.
* **Negatif Bias (Under-prediction):** Model sÃ¼rekli gerekenden azÄ±nÄ± tahmin ediyordur.
    * *Perakende Riski:* Stok tÃ¼kenmesi (Stockouts), satÄ±ÅŸ kaybÄ± (Lost Sales), mÃ¼ÅŸteri memnuniyetsizliÄŸi.

> **Uzman Notu:** Sadece Bias'a bakarak modelin baÅŸarÄ±sÄ± Ã¶lÃ§Ã¼lmez. Pozitif ve negatif hatalar birbirini gÃ¶tÃ¼rebilir (Ã¶rn: bir gÃ¼n +100, ertesi gÃ¼n -100 hata yaparsanÄ±z Bias 0 Ã§Ä±kar ama model kÃ¶tÃ¼dÃ¼r). Bu yÃ¼zden Bias, her zaman MAE veya RMSE ile birlikte yorumlanmalÄ±dÄ±r.

---

## 2. Mean Absolute Deviation (MAD / MAE)
Tahmin edilen ve gerÃ§ek deÄŸerler arasÄ±ndaki mutlak farklarÄ±n ortalamasÄ±dÄ±r. HatanÄ±n yÃ¶nÃ¼ne (pozitif/negatif) bakmaksÄ±zÄ±n, hatanÄ±n **bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne** odaklanÄ±r.

$$MAD = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

### ğŸ¯ Neden Ã–nemlidir?
* **Yorumlanabilirlik:** Veri ile aynÄ± birimdedir. "GÃ¼nde ortalama 20 adet hata yapÄ±yoruz" demek yÃ¶neticiler iÃ§in anlaÅŸÄ±lÄ±rdÄ±r.
* **GÃ¼venlik StoÄŸu (Safety Stock):** Lojistik planlamasÄ±nda gÃ¼venlik stoÄŸu belirlenirken genellikle MAD kullanÄ±lÄ±r.
* **Ä°statistiksel Ã–zellik:** MAD, medyan tahmini optimize eder. EÄŸer veri setinizde Ã§ok fazla aykÄ±rÄ± deÄŸer (outlier) varsa, MAD, RMSE'ye gÃ¶re daha direnÃ§li (robust) bir metriktir.

---

## 3. Relative Mean Absolute Deviation (rMAD)
MAD deÄŸerinin, gerÃ§ek deÄŸerlerin ortalamasÄ±na bÃ¶lÃ¼nmesiyle elde edilir. Bu iÅŸlem MAD'yi normalize eder ve Ã¶lÃ§ekten baÄŸÄ±msÄ±z hale getirir.

$$rMAD = \frac{MAD}{\bar{y}} = \frac{\sum |y_i - \hat{y}_i|}{\sum y_i}$$

### ğŸ¯ Neden Ã–nemlidir?
* **KarÅŸÄ±laÅŸtÄ±rÄ±labilirlik:** FarklÄ± satÄ±ÅŸ hacmine sahip Ã¼rÃ¼nleri (Ã§ok satan "Fast-mover" vs. az satan "Slow-mover") kÄ±yaslamak iÃ§in kullanÄ±lÄ±r.
* **Ã–rnek:** rMAD %10 ise, hata payÄ±nÄ±z ortalama talebin %10'u kadardÄ±r.
* **Dikkat:** DÃ¼ÅŸÃ¼k hacimli (low-demand) Ã¼rÃ¼nlerde rMAD ve diÄŸer oransal hatalar genellikle yÃ¼ksek Ã§Ä±kar. Bu istatistiksel bir beklentidir; az satan Ã¼rÃ¼nlerin volatilitesi daha yÃ¼ksektir.

---

## 4. Mean Absolute Percentage Error (MAPE)
Tahmin hatasÄ±nÄ±n mutlak yÃ¼zdesel ortalamasÄ±dÄ±r. LiteratÃ¼rde en yaygÄ±n gÃ¶rÃ¼len metriklerden biridir ancak perakendede ciddi dezavantajlarÄ± vardÄ±r.

$$MAPE = \frac{100\%}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|$$

### âš ï¸ Kritik Dezavantajlar
1.  **SÄ±fÄ±ra BÃ¶lme HatasÄ± (Sensitivity to Small Values):** GerÃ§ek satÄ±ÅŸ ($y_i$) 0 olduÄŸunda (ki perakendede bazÄ± gÃ¼nler satÄ±ÅŸ olmaz), MAPE tanÄ±msÄ±zdÄ±r (sonsuz). GerÃ§ek deÄŸer Ã§ok kÃ¼Ã§Ã¼kse (Ã¶rn: 1), hata oranÄ± yapay olarak devasa Ã§Ä±kar.
2.  **Asimetri (Asymmetry in Error Treatment):** MAPE, gereÄŸinden az tahmin etmeyi (under-forecast), fazla tahmin etmeye (over-forecast) gÃ¶re daha aÄŸÄ±r cezalandÄ±rÄ±r.
    * *Ã–rnek:* GerÃ§ek=100, Tahmin=150 (Over) -> Hata %50
    * *Ã–rnek:* GerÃ§ek=100, Tahmin=50 (Under) -> Hata %50
    * *Ancak:* Payda deÄŸiÅŸtiÄŸinde iÅŸler karÄ±ÅŸÄ±r. Modelin finansal tahminlerdeki cezalandÄ±rma yapÄ±sÄ± dengesizleÅŸebilir.

> **Uzman Tavsiyesi:** Perakendede "Intermittent Demand" (Kesikli Talep) sÄ±k gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ iÃ§in MAPE yerine genellikle **WMAPE (Weighted MAPE)** veya **MASE** tercih edilmelidir.

---

## 5. Root Mean Square Error (RMSE)
HatalarÄ±n karesinin ortalamasÄ±nÄ±n karekÃ¶kÃ¼dÃ¼r. MAD'den farklÄ± olarak, hatalarÄ±n karesini aldÄ±ÄŸÄ± iÃ§in **bÃ¼yÃ¼k hatalarÄ±** Ã§ok daha aÄŸÄ±r cezalandÄ±rÄ±r.

$$RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

### ğŸ¯ Neden Ã–nemlidir?
* **BÃ¼yÃ¼k HatalarÄ±n Maliyeti:** EÄŸer iÅŸletmeniz iÃ§in "bÃ¼yÃ¼k bir hata yapmak", "birÃ§ok kÃ¼Ã§Ã¼k hata yapmaktan" Ã§ok daha kÃ¶tÃ¼yse (Ã¶rneÄŸin: tÃ¼m stoÄŸun bitmesi veya fabrikanÄ±n durmasÄ±), RMSE kullanmalÄ±sÄ±nÄ±z.
* **Ortalama Tahmini:** RMSE, istatistiksel olarak ortalamayÄ± (mean) tahmin etmeye Ã§alÄ±ÅŸÄ±r.

---

## ğŸ“Š KarÅŸÄ±laÅŸtÄ±rmalÄ± Ã–zet Tablosu

| Metrik | Odak NoktasÄ± | Avantaj | Dezavantaj | En Ä°yi KullanÄ±m AlanÄ± |
| :--- | :--- | :--- | :--- | :--- |
| **Bias** | YÃ¶n (Alt/Ãœst Tahmin) | Sistematik hatalarÄ± (sÃ¼rekli fazla/eksik tahmin) gÃ¶sterir. | Tek baÅŸÄ±na baÅŸarÄ±yÄ± Ã¶lÃ§emez (Hatalar birbirini gÃ¶tÃ¼rÃ¼r). | Stok politikasÄ± belirleme (Overstock vs Stockout riski). |
| **MAD (MAE)** | Hata BÃ¼yÃ¼klÃ¼ÄŸÃ¼ (Lineer) | YorumlamasÄ± kolaydÄ±r, outlier'lara karÅŸÄ± direnÃ§lidir. | BÃ¼yÃ¼k hatalarÄ± RMSE kadar cezalandÄ±rmaz. | Genel envanter yÃ¶netimi, GÃ¼venlik stoÄŸu hesabÄ±. |
| **RMSE** | Hata BÃ¼yÃ¼klÃ¼ÄŸÃ¼ (Karesel) | BÃ¼yÃ¼k hatalarÄ± aÄŸÄ±r cezalandÄ±rÄ±r. | Outlier'lardan Ã§ok etkilenir. YorumlamasÄ± MAE kadar doÄŸrudan deÄŸildir. | BÃ¼yÃ¼k hatalarÄ±n maliyetinin Ã§ok yÃ¼ksek olduÄŸu durumlar (Finans, Enerji). |
| **MAPE** | YÃ¼zdesel Hata | FarklÄ± Ã¶lÃ§ekteki Ã¼rÃ¼nleri kÄ±yaslamayÄ± saÄŸlar. YÃ¶neticiler sever. | 0 satÄ±ÅŸ olduÄŸunda patlar (TanÄ±msÄ±z). Asimetriktir. | YÃ¼ksek hacimli ve dÃ¼zenli satÄ±ÅŸa sahip Ã¼rÃ¼nler. |
| **rMAD / WMAPE** | Normalize Hata | Hacim aÄŸÄ±rlÄ±klÄ± hatayÄ± gÃ¶sterir. 0 deÄŸerlerinde MAPE gibi patlamaz. | HesaplanmasÄ± MAPE'den bir tÄ±k daha karmaÅŸÄ±ktÄ±r. | **Perakende StandardÄ±.** Az ve Ã§ok satan Ã¼rÃ¼nlerin olduÄŸu karma portfÃ¶yler. |

---

### ğŸ’¡ SonuÃ§ ve Strateji
Perakende talep tahminlemesinde "tek bir doÄŸru metrik" yoktur. Genellikle hibrit bir yaklaÅŸÄ±m izlenir:
1.  **Model Optimizasyonu iÃ§in:** **RMSE** veya **MAE** kullanÄ±lÄ±r (Matematiksel tÃ¼revlenebilirlik ve ceza mekanizmasÄ± iÃ§in).
2.  **Ä°ÅŸ RaporlamasÄ± (Business Reporting) iÃ§in:** **WMAPE (veya rMAD)** kullanÄ±lÄ±r (YÃ¶neticilere "Hata oranÄ±mÄ±z %15" diyebilmek iÃ§in).
3.  **Stok Riski Analizi iÃ§in:** **Bias** kontrol edilir (SÃ¼rekli eksik mi tahmin ediyoruz?).

*Bu dÃ¶kÃ¼man, veri bilimi projelerinizde model deÄŸerlendirme aÅŸamasÄ± iÃ§in bir rehber niteliÄŸindedir.*

# ğŸ“Š Evaluation Metrics for Retail Demand Forecasting II: Holistic Diagnosis

Perakende talep tahminlemesinde (Retail Demand Forecasting) modelleri deÄŸerlendirirken tek bir metriÄŸe gÃ¼venmek, uÃ§aÄŸÄ± sadece "yÃ¼kseklik gÃ¶stergesi" ile uÃ§urmaya benzer; hÄ±zÄ± veya yÃ¶nÃ¼ gÃ¶remezsiniz. 

Bu dÃ¶kÃ¼man, bir XGBoost modelinin performans Ã§Ä±ktÄ±larÄ±nÄ± (MAE, Bias, RMSE, rMAD, MAPE) yan yana koyarak nasÄ±l **detaylÄ± bir model teÅŸhisi** yapÄ±lacaÄŸÄ±nÄ± analiz eder.

---

## 1. Metriklerin Toplu Analizi (The Line-up)

Modelin saÄŸlÄ±ÄŸÄ±nÄ± Ã¶lÃ§mek iÃ§in aÅŸaÄŸÄ±daki metrikleri bir arada raporluyoruz. Bu yaklaÅŸÄ±m, sorunun kaynaÄŸÄ±nÄ± tespit etmemizi saÄŸlar:
* **Hata BÃ¼yÃ¼klÃ¼ÄŸÃ¼ (Magnitude):** MAE ve RMSE.
* **Sistematik Sapma (Direction):** Bias.
* **GÃ¶receli Performans (Relativity):** rMAD ve MAPE.

### ğŸ§ª Vaka Analizi: XGBoost Baseline SonuÃ§larÄ±

AÅŸaÄŸÄ±daki deÄŸerler, standart bir XGBoost modelinin test seti Ã¼zerindeki performansÄ±nÄ± temsil etmektedir. Gelin bu sayÄ±larÄ±n "Veri Bilimi" ve "Perakende Operasyonu" aÃ§Ä±sÄ±ndan ne anlama geldiÄŸini inceleyelim.

#### ğŸ“‰ 1. MAE (Mean Absolute Error) â‰ˆ 117 Units
> **Durum:** GÃ¼nlÃ¼k satÄ±ÅŸlarÄ±n genellikle **300-800 birim** arasÄ±nda deÄŸiÅŸtiÄŸi bir seride, model ortalama **117 birim** hata yapÄ±yor.
>
> **Uzman Yorumu:** Model, ortalama bir gÃ¼nde sipariÅŸ toplama sÃ¼recinde (order pick-bin) yaklaÅŸÄ±k 100-120 birimlik bir sapma yaratÄ±yor. SatÄ±ÅŸ hacmi (800) gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda bu kabul edilebilir bir baÅŸlangÄ±Ã§tÄ±r, ancak mÃ¼kemmel deÄŸildir.

#### âš–ï¸ 2. Bias â‰ˆ -18 Units
> **Durum:** SonuÃ§ negatiftir.
>
> **Uzman Yorumu (Under-prediction Risk):** Model, sistematik olarak gerÃ§eÄŸin altÄ±nda tahmin yapÄ±yor (**Negative Bias**). 
> * **Ä°ÅŸ Riski:** Perakendede bu durum, **"Stok Yok" (Stockout)** riskine ve potansiyel ciro kaybÄ±na (Lost Sales) iÅŸaret eder. Model talebi yakalayamÄ±yor, gerisinde kalÄ±yor.
> * **Teknik Aksiyon:** KayÄ±p fonksiyonuna (Loss Function) asimetrik bir ceza ekleyerek veya "Safety Stock" (GÃ¼venlik StoÄŸu) Ã§arpanÄ±nÄ± artÄ±rarak bu bias dÃ¼zeltilmelidir.

#### âš¡ 3. RMSE (Root Mean Square Error) â‰ˆ 171 Units
> **Durum:** $RMSE (171) > MAE (117)$. Aradaki fark belirgindir.
>
> **Uzman Yorumu (Variance & Outliers):** RMSE'nin MAE'den bu kadar yÃ¼ksek olmasÄ±, modelin **bÃ¼yÃ¼k hatalar** (large spikes) yaptÄ±ÄŸÄ±nÄ± gÃ¶sterir.
> * Model, "sÄ±radan gÃ¼nleri" iyi tahmin ediyor olabilir, ancak promosyon veya Ã¶zel gÃ¼nlerdeki (tallest peaks) ani talep artÄ±ÅŸlarÄ±nÄ± yakalayamÄ±yor ve karesel ceza (squared error) nedeniyle RMSE yÃ¼kseliyor.

#### ğŸ“Š 4. MAD & rMAD (Relative MAD) â‰ˆ 0.83 (%83)
> **Durum:** $MAD \approx 140$ ve $rMAD \approx 0.83$.
>
> **Uzman Yorumu (Variability Check):** Burada rMAD, modelin hatasÄ±nÄ±n, serinin kendi doÄŸal deÄŸiÅŸkenliÄŸine (variability) oranÄ± olarak yorumlanmÄ±ÅŸtÄ±r. 
> * Hata, verinin kendi dalgalanmasÄ±nÄ±n %83'Ã¼ kadar. Bu, modelin serideki varyansÄ±n (bilginin) bir kÄ±smÄ±nÄ± aÃ§Ä±kladÄ±ÄŸÄ±nÄ± ancak hala Ã¶nemli bir kÄ±smÄ±nÄ± "gÃ¼rÃ¼ltÃ¼" veya "aÃ§Ä±klanamayan varyans" olarak bÄ±raktÄ±ÄŸÄ±nÄ± gÃ¶sterir. Model doÄŸal yayÄ±lÄ±mÄ± (spread) tam olarak kavrayamamÄ±ÅŸ.

#### ğŸ·ï¸ 5. MAPE (Mean Absolute Percentage Error) â‰ˆ 28%
> **Durum:** Ortalama mutlak yÃ¼zdesel hata %28.
>
> **Uzman Yorumu:** Model, gerÃ§ek talebi ortalama olarak dÃ¶rtte bir veya Ã¼Ã§te bir oranÄ±nda Ä±skalÄ±yor.
> * **Perakende BaÄŸlamÄ±:** HÄ±zlÄ± tÃ¼ketim (FMCG) iÃ§in %28 iyileÅŸtirilmesi gereken bir orandÄ±r. Ancak moda veya lÃ¼ks tÃ¼ketim gibi yÃ¼ksek volatiliteli alanlarda "iÅŸletilebilir" (serviceable) bir oran kabul edilebilir.

---

## 2. KarÅŸÄ±laÅŸtÄ±rmalÄ± TeÅŸhis Tablosu (Diagnostic Matrix)

Hangi metriÄŸin neyi iÅŸaret ettiÄŸini ve bu XGBoost Ã¶rneÄŸindeki karÅŸÄ±lÄ±ÄŸÄ±nÄ± Ã¶zetleyen teknik tablo:

| Metrik | Ne Ã–lÃ§Ã¼yor? | XGBoost Sonucu | TeÅŸhis & Ä°ÅŸ AnlamÄ± |
| :--- | :--- | :--- | :--- |
| **MAE** | Ortalama Hata (Lineer) | **117 birim** | "GÃ¼nde ortalama 117 Ã¼rÃ¼n yanÄ±lÄ±yoruz." |
| **Bias** | HatanÄ±n YÃ¶nÃ¼ | **-18 birim** | **Tehlike:** Talebi azÄ±msÄ±yoruz. MÃ¼ÅŸteri Ã¼rÃ¼nÃ¼ bulamayabilir (Under-forecasting). |
| **RMSE** | BÃ¼yÃ¼k Hatalar (Karesel) | **171 birim** | MAE ile fark bÃ¼yÃ¼k. Kampanya dÃ¶nemleri veya ani piklerde model Ã§uvallÄ±yor. |
| **rMAD** | DeÄŸiÅŸkenliÄŸe GÃ¶re Hata | **0.83** | Model verinin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± tam Ã§Ã¶zemedi, varyansÄ±n bÃ¼yÃ¼k kÄ±smÄ± hala hatada. |
| **MAPE** | YÃ¼zdesel Hata | **%28** | YÃ¶netim raporu iÃ§in makul, ancak tedarik zinciri optimizasyonu iÃ§in %20 altÄ±na inilmeli. |

---

## 3. Uzman SonuÃ§ Bildirgesi (Executive Summary)

Bu XGBoost modeli **"Tutucu" (Conservative)** bir modeldir:
1.  **Negatif Bias:** Risk almaktan kaÃ§Ä±nÄ±yor ve talebi olduÄŸundan az tahmin ediyor.
2.  **YÃ¼ksek RMSE:** Beklenmedik talep patlamalarÄ±nÄ± (Outliers) tahmin etmekte zorlanÄ±yor.
3.  **SonuÃ§:** Model ÅŸu haliyle "Otomatik SipariÅŸ" sistemine baÄŸlanÄ±rsa **stoksuz kalma (stock-out)** sorunlarÄ± yaÅŸanÄ±r. Modelin hiperparametreleri, ani yÃ¼kseliÅŸleri (spikes) daha iyi yakalayacak ÅŸekilde optimize edilmelidir.

# ğŸ“‰ Model Evaluation Case Study: The Metric Paradox

Zaman serisi tahminlemesinde sÄ±kÃ§a karÅŸÄ±laÅŸÄ±lan bir yanÄ±lgÄ± ÅŸudur: "En dÃ¼ÅŸÃ¼k hataya sahip model en iyisidir." Ancak bu vaka analizi, farklÄ± metriklerin (MAPE, RMSE, MAD) birbirleriyle nasÄ±l Ã§eliÅŸebileceÄŸini ve her birinin aslÄ±nda verinin farklÄ± bir istatistiksel Ã¶zelliÄŸini (Mean, Median, Mode) optimize ettiÄŸini kanÄ±tlamaktadÄ±r.

Bu Ã§alÄ±ÅŸma, Nicolas Vandeput'un *Data Science for Supply Chain Forecasting* kitabÄ±ndaki Ã¼nlÃ¼ Ã¶rneÄŸe dayanmaktadÄ±r.

---

## 1. Veri Seti ve Senaryo

Elimizde 5 haftalÄ±k, oldukÃ§a dalgalÄ± (volatile) gÃ¼nlÃ¼k satÄ±ÅŸ verileri var. Veri seti 1 ile 20 arasÄ±nda deÄŸiÅŸen, ani yÃ¼kseliÅŸler (spikes) iÃ§eren bir yapÄ±ya sahip.

### ğŸ“… GÃ¼nlÃ¼k SatÄ±ÅŸ Verileri (Actual Demand)

| GÃ¼n | W1 | W2 | W3 | W4 | W5 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Pzt** | 3 | 3 | 4 | 1 | 5 |
| **Sal** | 1 | 4 | 1 | 2 | 2 |
| **Ã‡ar** | 5 | 5 | 1 | 1 | 12 |
| **Per** | 20 | 4 | 3 | 2 | 1 |
| **Cum** | 13 | 16 | 14 | 5 | 20 |


### ğŸ”® Tahmin SenaryolarÄ± (Forecast Scenarios)
KarmaÅŸÄ±k algoritmalar yerine, Ã¼Ã§ farklÄ± "sabit" tahmin (naive constant forecasts) stratejisini test ediyoruz:

1.  **Forecast #1 (Low):** GÃ¼nde sabit **2 adet**.
2.  **Forecast #2 (Medium):** GÃ¼nde sabit **4 adet**.
3.  **Forecast #3 (High):** GÃ¼nde sabit **6 adet**.

---

## 2. Metrik KarÅŸÄ±laÅŸtÄ±rmasÄ± ve SonuÃ§lar

Her bir tahmin senaryosu iÃ§in **Bias**, **MAPE**, **MAD (MAE)** ve **RMSE** hesaplandÄ±ÄŸÄ±nda ortaya ÅŸaÅŸÄ±rtÄ±cÄ± bir tablo Ã§Ä±kÄ±yor. HiÃ§bir tahmin, tÃ¼m metriklerde "kazanan" deÄŸildir.

| Metrik | Forecast #1 (Tahmin: 2) | Forecast #2 (Tahmin: 4) | Forecast #3 (Tahmin: 6) |
| :--- | :--- | :--- | :--- |
| **Bias** | -3.9 (Ã‡ok Eksik) | -1.9 (Eksik) | **0.1 (Unbiased - En Ä°yi) ğŸ†** |
| **MAPE** | **64% (En Ä°yi) ğŸ†** | 109% | 180% (En KÃ¶tÃ¼) |
| **MAD** | 4.4 | **4.1 (En Ä°yi) ğŸ†** | 4.8 |
| **RMSE** | 7.1 (En KÃ¶tÃ¼) | 6.2 | **5.9 (En Ä°yi) ğŸ†** |

---

## 3. ğŸ§  Teknik Derinlemesine Analiz: Neden BÃ¶yle Oldu?

Bu tablo, veri bilimindeki temel optimizasyon kurallarÄ±nÄ±n canlÄ± kanÄ±tÄ±dÄ±r. Ä°ÅŸte her metriÄŸin neden farklÄ± bir kazanan seÃ§tiÄŸinin teknik aÃ§Ä±klamasÄ±:

### A. Neden RMSE, Forecast #3'Ã¼ (6 adet) SeÃ§ti?
* **Matematiksel Ä°lke:** RMSE (Root Mean Squared Error), hatalarÄ±n karesini alÄ±r. Bu iÅŸlem, bÃ¼yÃ¼k hatalarÄ± (outliers) aÅŸÄ±rÄ± cezalandÄ±rÄ±r. HatayÄ± minimize etmek iÃ§in RMSE, istatistiksel olarak **Ortalama'ya (Mean)** yakÄ±nsamaya Ã§alÄ±ÅŸÄ±r.
* **Vaka:** Veri setinin aritmetik ortalamasÄ± yaklaÅŸÄ±k **5.92**'dir. Bu deÄŸere en yakÄ±n tahmin **Forecast #3 (6)** olduÄŸu iÃ§in RMSE burada en dÃ¼ÅŸÃ¼k Ã§Ä±kar.
* **Mesaj:** "EÄŸer bÃ¼yÃ¼k hatalardan (stok tÃ¼kenmesi, krizler) korkuyorsan, ortalamaya oyna."

### B. Neden MAD, Forecast #2'yi (4 adet) SeÃ§ti?
* **Matematiksel Ä°lke:** MAD (veya MAE), hatalarÄ±n mutlak deÄŸerini alÄ±r. Bu metrik, istatistiksel olarak **Medyan'a (Median)** yakÄ±nsamaya Ã§alÄ±ÅŸÄ±r.
* **Vaka:** Veri setindeki deÄŸerleri sÄ±raladÄ±ÄŸÄ±mÄ±zda medyan deÄŸerin **4** olduÄŸunu gÃ¶rÃ¼rÃ¼z. Bu yÃ¼zden **Forecast #2 (4)**, MAD aÃ§Ä±sÄ±ndan rakipsizdir.
* **Mesaj:** "EÄŸer istikrarlÄ± ve dengeli bir tahmin istiyorsan, medyana oyna."

### C. Neden MAPE, Forecast #1'i (2 adet) SeÃ§ti?
* **Matematiksel Ä°lke:** MAPE (Mean Absolute Percentage Error), asimetrik bir cezalandÄ±rma yapÄ±sÄ±na sahiptir.
    * GerÃ§ek satÄ±ÅŸ dÃ¼ÅŸÃ¼k (Ã¶rn: 1) iken yÃ¼ksek tahmin yaparsanÄ±z (Ã¶rn: 6), hata %500 olur.
    * GerÃ§ek satÄ±ÅŸ yÃ¼ksek (Ã¶rn: 20) iken dÃ¼ÅŸÃ¼k tahmin yaparsanÄ±z (Ã¶rn: 2), hata en fazla %100'e yaklaÅŸabilir (Asla %100'Ã¼ geÃ§emez).
* **SonuÃ§:** MAPE, devasa yÃ¼zdesel hatalardan kaÃ§Ä±nmak iÃ§in **dÃ¼ÅŸÃ¼k tahmin yapmayÄ± (under-forecasting)** Ã¶dÃ¼llendirir.
* **Vaka:** Veride Ã§ok fazla "1" ve "2" gibi kÃ¼Ã§Ã¼k deÄŸerler var. Forecast #3 (6) buralarda %500 hata yaparken, Forecast #1 (2) Ã§ok az hata yapar.
* **Mesaj:** "MAPE kullanÄ±rsan modelin risk almaz, korkak davranÄ±r ve eksik tahmin yapar."

---

## 4. ğŸš€ Karar Matrisi: Hangi Senaryoda Hangi Tahmin?

Ä°ÅŸ hedefine (Business KPI) gÃ¶re hangi modeli seÃ§melisiniz?

| Ä°ÅŸ Hedefi (Goal) | Ã–nerilen Model | Neden? |
| :--- | :--- | :--- |
| **Maliyet Minimizasyonu** (Stoksuz kalmak Ã§ok pahalÄ±ysa) | **Forecast #3** (RMSE Winner) | Bias neredeyse 0'dÄ±r. Toplam talebi tam karÅŸÄ±lar. BÃ¼yÃ¼k talep gÃ¼nlerini Ä±skalamaz. |
| **Denge / Stabilite** (Lojistik planlama) | **Forecast #2** (MAD Winner) | "SÄ±radan bir gÃ¼nde" en az hatayÄ± bu model yapar. |
| **KPI Raporlama / DÃ¼ÅŸÃ¼k Stok Maliyeti** | **Forecast #1** (MAPE Winner) | EÄŸer yÃ¶netim sadece yÃ¼zdesel hataya bakÄ±yorsa bu model "baÅŸarÄ±lÄ±" gÃ¶rÃ¼nÃ¼r ama iÅŸ aÃ§Ä±sÄ±ndan sÃ¼rekli satÄ±ÅŸ kaybÄ± (lost sales) yaratÄ±r. |

> **ğŸ’¡ Uzman Notu:** Bu Ã¶rnek, perakende talep tahminlemesinde neden sadece **MAPE** kullanÄ±lmamasÄ± gerektiÄŸinin en gÃ¼Ã§lÃ¼ kanÄ±tÄ±dÄ±r. MAPE'ye gÃ¶re "en iyi" olan model, aslÄ±nda bias'Ä± en yÃ¼ksek ve ÅŸirkete en Ã§ok ciro kaybettiren modeldir.

```mermaid
xychart-beta
    title "5 HaftalÄ±k SatÄ±ÅŸ Talebi ve Tahmin SenaryolarÄ±"
    x-axis [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
    y-axis "Hacim" 0 --> 20
    line [3, 1, 5, 20, 13, 3, 4, 5, 4, 16, 4, 1, 1, 3, 14, 1, 2, 1, 2, 5, 5, 2, 12, 1, 20]
    line [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
    line [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
    line [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]
```

# ğŸ›ï¸ Hyperparameter Tuning for Time-Series Forecasting with XGBoost


<img width="610" height="341" alt="image" src="https://github.com/user-attachments/assets/3b74d547-f6e4-461d-a276-01660532376e" />

Makine Ã¶ÄŸrenimi modellerinde baÅŸarÄ±, sadece doÄŸru algoritmayÄ± seÃ§mekle deÄŸil, o algoritmanÄ±n "ayarlarÄ±nÄ±" doÄŸru yapmakla ilgilidir. Bu dokÃ¼man, Zaman Serisi tahminlemesinde Hiperparametre Optimizasyonunun (Hyperparameter Tuning) temellerini, XGBoost Ã¶zelindeki kritik ayarlarÄ± ve uygulama stratejilerini detaylandÄ±rÄ±r.

---

## 1. Hiperparametre Nedir? (The Concept)

Hiperparametreler, eÄŸitim sÃ¼reci (training process) baÅŸlamadan Ã¶nce tanÄ±mlanan ayarlardÄ±r. Modelin parametrelerinden (Ã¶rneÄŸin regresyon katsayÄ±larÄ± veya aÄŸ aÄŸÄ±rlÄ±klarÄ±) farklÄ±dÄ±rlar; Ã§Ã¼nkÃ¼ model parametreleri veri Ã¼zerinden Ã¶ÄŸrenilirken, hiperparametreler mÃ¼hendis tarafÄ±ndan **manuel olarak** veya **deneysel yollarla** belirlenir.

### ğŸ“Œ Neden Ã–nemlidir?
Hiperparametre optimizasyonu, bu ayarlarÄ±n en iyi kombinasyonunu arama sÃ¼recidir. DoÄŸru yapÄ±ldÄ±ÄŸÄ±nda:
* Modelin doÄŸruluÄŸunu (accuracy) artÄ±rÄ±r.
* Modelin genelleme yeteneÄŸini (generalization) iyileÅŸtirir (yeni verilerde daha iyi performans).
* Overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme) veya Underfitting (eksik Ã¶ÄŸrenme) riskini dengeler.

---

## 2. XGBoost Hiperparametreleri (Deep Dive)

XGBoost (Extreme Gradient Boosting), yapÄ±landÄ±rÄ±lmÄ±ÅŸ/tablo verileri iÃ§in endÃ¼stri standardÄ± haline gelmiÅŸ gÃ¼Ã§lÃ¼ bir algoritmadÄ±r. Zaman serisi tahminlemesini bir **regresyon problemi** olarak kurguladÄ±ÄŸÄ±mÄ±zda, aÅŸaÄŸÄ±daki hiperparametreler kritik rol oynar.

### A. Temel YapÄ±landÄ±rÄ±cÄ±lar

#### ğŸ¢ Learning Rate (`eta`)
Her iterasyonda modelin parametrelerini ne kadar gÃ¼ncelleyeceÄŸini kontrol eder. HatalarÄ± minimize etme yolunda atÄ±lan adÄ±mÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼dÃ¼r.
* **DÃ¼ÅŸÃ¼k DeÄŸer (Ã¶rn: 0.01):** Model yavaÅŸ ama emin adÄ±mlarla Ã¶ÄŸrenir. Daha gÃ¼venlidir ancak converge olmasÄ± (yakÄ±nsamasÄ±) uzun sÃ¼rer.
* **YÃ¼ksek DeÄŸer (Ã¶rn: 0.3):** Ã–ÄŸrenmeyi hÄ±zlandÄ±rÄ±r ancak optimum noktayÄ± Ä±skalama (overshoot) riski taÅŸÄ±r.
> **âœ… Uzman Ä°pucu:** Genellikle dÃ¼ÅŸÃ¼k bir Ã¶ÄŸrenme oranÄ± (`eta`) ile yÃ¼ksek sayÄ±da aÄŸaÃ§ (`n_estimators`) kullanmak, genelleme yeteneÄŸini artÄ±rÄ±r.

#### ğŸŒ³ Number of Estimators (`n_estimators`)
Kurulacak olan aÄŸaÃ§ sayÄ±sÄ±dÄ±r (boosting rounds).
* **Ã‡ok Az:** Underfitting riski.
* **Ã‡ok Fazla:** Overfitting riski (eÄŸer early stopping kullanÄ±lmazsa).

#### ğŸŒ² Max Depth (`max_depth`)
Her bir aÄŸacÄ±n ne kadar derinleÅŸebileceÄŸini (karmaÅŸÄ±klaÅŸabileceÄŸini) sÄ±nÄ±rlar.
* **DÃ¼ÅŸÃ¼k Derinlik:** Daha basit modeller (Bias yÃ¼ksek, Varyans dÃ¼ÅŸÃ¼k).
* **YÃ¼ksek Derinlik:** Model veriyi ezberleyebilir (Overfitting riski). Zaman serilerinde genelde 3-10 arasÄ± deÄŸerler denenir.

### B. Stokastik (Rastgelelik) Parametreleri

Bu parametreler, her aÄŸaÃ§ta verinin veya Ã¶zelliklerin sadece bir kÄ±smÄ±nÄ± kullanarak modelin gÃ¼rÃ¼ltÃ¼ye (noise) karÅŸÄ± direncini artÄ±rÄ±r.

#### ğŸ² Subsample
Her boosting turunda eÄŸitim verisinin ne kadarÄ±nÄ±n (% olarak) kullanÄ±lacaÄŸÄ±nÄ± belirler.
* Ã–rn: `0.8` -> Her aÄŸaÃ§ verinin %80'i ile eÄŸitilir.

#### ğŸ“Š Colsample_bytree
Her aÄŸaÃ§ oluÅŸturulurken Ã¶zelliklerin (sÃ¼tunlarÄ±n) ne kadarÄ±nÄ±n kullanÄ±lacaÄŸÄ±nÄ± belirler.
* Ã–zellikle Ã§ok fazla feature (lag, rolling window vb.) Ã¼rettiÄŸinizde kritiktir.

### C. Ä°leri Seviye Regularization (Uzman BÃ¶lÃ¼mÃ¼) ğŸš€

Metinde yer almayan ancak profesyonel modellemede hayati olan parametreler:

#### âš–ï¸ Min Child Weight (`min_child_weight`)
Bir yaprak dÃ¼ÄŸÃ¼mde (leaf node) olmasÄ± gereken minimum Ã¶rneklem aÄŸÄ±rlÄ±ÄŸÄ± toplamÄ±dÄ±r.
* **AmaÃ§:** GÃ¼rÃ¼ltÃ¼lÃ¼ verilerde overfitting'i engellemek. YÃ¼ksek deÄŸerler modeli daha muhafazakar yapar.

#### ğŸ›¡ï¸ Gamma (`min_split_loss`)
Bir dalÄ±n daha fazla bÃ¶lÃ¼nmesi iÃ§in gereken minimum kayÄ±p dÃ¼ÅŸÃ¼ÅŸÃ¼dÃ¼r (loss reduction). Modelin gereksiz karmaÅŸÄ±klÄ±ÄŸa girmesini engeller.

#### ğŸ§² Reg Alpha (`alpha`) & Reg Lambda (`lambda`)
* **Alpha (L1 Regularization):** Ã–zellik seÃ§iminde etkilidir, gereksiz katsayÄ±larÄ± sÄ±fÄ±ra Ã§eker.
* **Lambda (L2 Regularization):** BÃ¼yÃ¼k katsayÄ±larÄ± cezalandÄ±rarak modelin istikrarÄ±nÄ± saÄŸlar.

---

## 3. Optimizasyon Stratejisi (Workflow)

Zaman serisi verilerinde hiperparametre aramasÄ± yaparken standart yÃ¶ntemler (Shuffle Split) kullanÄ±lamaz. SÃ¼reÃ§ ÅŸÃ¶yle iÅŸler:

### 1ï¸âƒ£ Grid (Arama UzayÄ±) Belirleme
Hangi hiperparametreleri ve hangi deÄŸer aralÄ±klarÄ±nÄ± deneyeceÄŸimizi tanÄ±mlarÄ±z.

### 2ï¸âƒ£ Cross-Validation (Zaman DuyarlÄ±)
Standart K-Fold yerine **`TimeSeriesSplit`** kullanÄ±lÄ±r.
* Gelecek verisi geÃ§miÅŸi eÄŸitmek iÃ§in kullanÄ±lamaz (Data Leakage Ã¶nlenir).
* EÄŸitim seti geniÅŸleyen pencere (expanding window) mantÄ±ÄŸÄ±yla bÃ¼yÃ¼r.

### 3ï¸âƒ£ Arama YÃ¶ntemi (Search Method)
Grid Ã¼zerinde en iyi kombinasyonu bulmak iÃ§in kullanÄ±lan algoritmadÄ±r.

---

## ğŸ†š KarÅŸÄ±laÅŸtÄ±rma: Arama YÃ¶ntemleri

Hangi durumda hangi optimizasyon tekniÄŸini kullanmalÄ±sÄ±nÄ±z?

| YÃ¶ntem | AÃ§Ä±klama | Avantaj | Dezavantaj | KullanÄ±m Yeri |
| :--- | :--- | :--- | :--- | :--- |
| **Grid Search** | Belirlenen tÃ¼m kombinasyonlarÄ± tek tek dener. | En iyi sonucu bulmayÄ± garanti eder (grid iÃ§inde). | Ã‡ok yavaÅŸtÄ±r. Kombinasyon sayÄ±sÄ± arttÄ±kÃ§a sÃ¼re Ã¼ssel artar. | Az sayÄ±da parametre ve kÃ¼Ã§Ã¼k veri setleri. |
| **Random Search** | Kombinasyonlar arasÄ±ndan rastgele seÃ§imler yapar. | Ã‡ok daha hÄ±zlÄ±dÄ±r. Grid Search kadar iyi sonuÃ§larÄ± Ã§ok daha kÄ±sa sÃ¼rede bulabilir. | En iyi kombinasyonu ÅŸans eseri Ä±skalayabilir. | **XGBoost gibi Ã§ok parametreli modellerde baÅŸlangÄ±Ã§ iÃ§in.** |
| **Bayesian Optimization** (Optuna/Hyperopt) | Ã–nceki denemelerden Ã¶ÄŸrenerek (probabilistic) bir sonraki denemeyi akÄ±llÄ±ca seÃ§er. | En verimli yÃ¶ntemdir. Daha az denemeyle daha iyi sonuca ulaÅŸÄ±r. | Kurulumu ve mantÄ±ÄŸÄ± biraz daha karmaÅŸÄ±ktÄ±r. | Kaggle yarÄ±ÅŸmalarÄ± ve ProdÃ¼ksiyon seviyesi modeller. |

---

## ğŸ Ã–rnek Kod Åablonu (Python)

AÅŸaÄŸÄ±da `RandomizedSearchCV` ve `TimeSeriesSplit` kullanÄ±larak yapÄ±lan bir optimizasyon Ã¶rneÄŸi verilmiÅŸtir:

```python
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit
import xgboost as xgb

# 1. Model
model = xgb.XGBRegressor(objective='reg:squarederror')

# 2. Hiperparametre UzayÄ± (Grid)
param_grid = {
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'max_depth': [3, 5, 7, 10],
    'min_child_weight': [1, 3, 5],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'n_estimators': [100, 500, 1000]
}

# 3. Zaman Serisi CV
tscv = TimeSeriesSplit(n_splits=5)

# 4. Arama
random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_grid,
    n_iter=50, # 50 farklÄ± kombinasyon dene
    scoring='neg_mean_squared_error', # RMSE hedefli
    cv=tscv,
    verbose=1,
    n_jobs=-1
)

# random_search.fit(X_train, y_train)
```

# ğŸ§  (Advanced) Hyperparameter Tuning for LSTM Time-Series Forecasting

LSTM (Long Short-Term Memory) aÄŸlarÄ±, sÄ±ralÄ± veriler (sequential data) ve zaman serisi tahminlemeleri iÃ§in tasarlanmÄ±ÅŸ Ã¶zel bir Tekrarlayan Sinir AÄŸÄ± (RNN) tÃ¼rÃ¼dÃ¼r. Modelin "hafÄ±zasÄ±" sayesinde geÃ§miÅŸteki kalÄ±plarÄ± (patterns) uzun sÃ¼re saklayabilir. Ancak, LSTM'ler hesaplama aÃ§Ä±sÄ±ndan maliyetlidir ve doÄŸru hiperparametreleri bulmak, modelin baÅŸarÄ±sÄ± iÃ§in kritiktir.

Bu dokÃ¼man, LSTM modellerini optimize ederken kullanÄ±lan ileri seviye teknikleri, veri hazÄ±rlÄ±k sÃ¼reÃ§lerini ve Grid Search stratejilerini adÄ±m adÄ±m aÃ§Ä±klar.

---

## ğŸ›ï¸ 1. Kritik LSTM Hiperparametreleri

LSTM'in performansÄ±nÄ± doÄŸrudan etkileyen "ayar dÃ¼ÄŸmeleri" ÅŸunlardÄ±r:

| Hiperparametre | AÃ§Ä±klama ve Etkisi |
| :--- | :--- |
| **Number of Layers** (Katman SayÄ±sÄ±) | Modelin derinliÄŸini belirler. Genellikle 1 veya 2 katman yeterlidir. Daha fazlasÄ± karmaÅŸÄ±k desenleri Ã¶ÄŸrenebilir ancak overfitting riski artar. |
| **Units per Layer** (NÃ¶ron SayÄ±sÄ±) | Her katmandaki LSTM hÃ¼cresi sayÄ±sÄ±dÄ±r (Ã¶rn: 64, 128). Modelin "kapasitesini" (Ã¶ÄŸrenme gÃ¼cÃ¼nÃ¼) belirler. |
| **Batch Size** (YÄ±ÄŸÄ±n Boyutu) | Modelin aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncellemeden Ã¶nce gÃ¶rdÃ¼ÄŸÃ¼ Ã¶rnek sayÄ±sÄ±dÄ±r. KÃ¼Ã§Ã¼k batch (Ã¶rn: 32) gÃ¼rÃ¼ltÃ¼lÃ¼ ama genelleÅŸtirici, bÃ¼yÃ¼k batch (Ã¶rn: 256) hÄ±zlÄ± ama ezberci olabilir. |
| **Learning Rate** (Ã–ÄŸrenme OranÄ±) | Gradyan iniÅŸi (gradient descent) sÄ±rasÄ±nda atÄ±lan adÄ±mÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼. Ã‡ok bÃ¼yÃ¼kse model yakÄ±nsamaz, Ã§ok kÃ¼Ã§Ã¼kse eÄŸitim bitmez. |
| **Dropout Rate** | Her eÄŸitim adÄ±mÄ±nda nÃ¶ronlarÄ±n rastgele %X kadarÄ±nÄ± kapatÄ±r. **Overfitting'i engellemek iÃ§in en kritik parametredir.** |
| **Sequence Length** (Pencere Boyutu) | Modelin geÃ§miÅŸe ne kadar bakacaÄŸÄ± (Look-back window). Ã–rn: Son 30 gÃ¼n. |

---

## ğŸ› ï¸ 2. Veri HazÄ±rlÄ±ÄŸÄ±: LSTM Ä°Ã§in "3D" DÃ¶nÃ¼ÅŸÃ¼m

LSTM modelleri, klasik makine Ã¶ÄŸrenimi modellerinden (XGBoost vb.) farklÄ± olarak veriyi **3 Boyutlu TensÃ¶rler** halinde bekler.

### ğŸ“ Veri Åekli (Input Shape): `(Samples, Time Steps, Features)`
* **Samples:** Veri setindeki toplam pencere sayÄ±sÄ±.
* **Time Steps (Sequence Length):** GeÃ§miÅŸe bakÄ±lan adÄ±m sayÄ±sÄ± (Ã¶rn: 30 gÃ¼n).
* **Features:** Her adÄ±mda kullanÄ±lan deÄŸiÅŸken sayÄ±sÄ±. (Ã–nceki derste 1'di, ÅŸimdi 9 Ã¶zellik kullanÄ±yoruz: `sales`, `lags`, `rolling_stats` vb.)

### ğŸ”„ AdÄ±m AdÄ±m Ä°ÅŸ AkÄ±ÅŸÄ± (Workflow)

#### AdÄ±m 1: Ã–lÃ§eklendirme (Scaling) - âš ï¸ Kritik UyarÄ±!
LSTM'ler aktivasyon fonksiyonlarÄ± (Tanh/Sigmoid) kullandÄ±ÄŸÄ± iÃ§in verinin **[0, 1]** veya **[-1, 1]** aralÄ±ÄŸÄ±nda olmasÄ± ÅŸarttÄ±r.
* **Kural:** Scaler (`MinMaxScaler`) sadece **EÄŸitim Seti (Train Set)** Ã¼zerinde `fit` edilmelidir. Test setine sadece `transform` uygulanÄ±r.
* **Neden?** Test setindeki (gelecekteki) minimum/maksimum deÄŸerleri bilmek **Data Leakage** (Veri SÄ±zÄ±ntÄ±sÄ±) yaratÄ±r.

#### AdÄ±m 2: Pencereleme (Windowing / Sequencing)
Zaman serisini, modelin yiyebileceÄŸi kÃ¼Ã§Ã¼k kliplere bÃ¶lme iÅŸlemidir.
* **Girdi (X):** [t-30 ... t-1] aralÄ±ÄŸÄ±ndaki veriler (Ã–zelliklerle birlikte).
* **Hedef (y):** [t] anÄ±ndaki satÄ±ÅŸ deÄŸeri.

```mermaid
graph LR
    A[Ham Veri] --> B[Train/Test Split (Kronolojik)]
    B --> C{Scaler Fit (Sadece Train)}
    C --> D[Transform Train & Test]
    D --> E[Pencereleme (Sliding Window)]
    E --> F[3D Reshape (Samples, TimeSteps, Features)]
    F --> G[LSTM Modeli]

```

# ğŸ§  (Advanced) Hyperparameter Tuning for LSTM: Implementation

LSTM modellemesinde teoriden pratiÄŸe geÃ§iÅŸ, titiz bir kod yapÄ±sÄ± gerektirir. Veriyi 3 boyutlu tensÃ¶rlere Ã§evirdikten sonraki adÄ±m, farklÄ± mimarileri sistematik olarak test etmektir.

Bu dokÃ¼man, dinamik model oluÅŸturma (Model Factory), manuel Grid Search dÃ¶ngÃ¼sÃ¼ ve sonuÃ§larÄ±n doÄŸru raporlanmasÄ± sÃ¼reÃ§lerini teknik detaylarla ele alÄ±r.

---

## ğŸ­ 3. Model FabrikasÄ± (Model Factory)

Grid Search yapabilmek iÃ§in, her iterasyonda farklÄ± parametrelerle (Ã¶rn: 1 katman vs 2 katman) modeli sÄ±fÄ±rdan inÅŸa eden bir fonksiyona ihtiyacÄ±mÄ±z vardÄ±r.

### ğŸ”‘ Kritik Teknik Detay: `return_sequences`
LSTM katmanlarÄ± arasÄ±ndaki bilgi akÄ±ÅŸÄ±nÄ± yÃ¶neten en Ã¶nemli parametredir.
* **`True` (RÃ¶le YarÄ±ÅŸÄ±):** EÄŸer LSTM katmanlarÄ±nÄ± Ã¼st Ã¼ste diziyorsanÄ±z (Stacked LSTM), alttaki katman sadece sonucu deÄŸil, tÃ¼m sÃ¼recin Ã¶zetini (sequence) bir Ã¼st katmana iletmelidir.
* **`False` (BitiÅŸ Ã‡izgisi):** Son LSTM katmanÄ±, artÄ±k zaman boyutunu Ã§Ã¶kertmeli ve `Dense` katmanÄ±na tek bir Ã¶zet vektÃ¶r vermelidir.

### ğŸ Python UygulamasÄ±

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam

def build_lstm(seq_len, n_features, n_units, n_layers, dropout_rate):
    """
    Verilen hiperparametrelerle dinamik bir LSTM modeli oluÅŸturur.
    """
    model = Sequential()
    
    # --- Ä°lk LSTM KatmanÄ± ---
    # input_shape=(zaman_adÄ±mÄ±, Ã¶zellik_sayÄ±sÄ±) sadece ilk katmanda belirtilir.
    # EÄŸer n_layers > 1 ise, bir sonraki katmana sequence aktarmalÄ±yÄ±z (True).
    model.add(LSTM(n_units, 
                   input_shape=(seq_len, n_features), 
                   return_sequences=(n_layers > 1)))
    model.add(Dropout(dropout_rate))
    
    # --- Ara Katmanlar (Varsa) ---
    for i in range(1, n_layers):
        # EÄŸer bu son katmansa False, deÄŸilse True dÃ¶ndÃ¼r
        is_last_layer = (i == n_layers - 1)
        model.add(LSTM(n_units, return_sequences=not is_last_layer))
        model.add(Dropout(dropout_rate))
        
    # --- Ã‡Ä±kÄ±ÅŸ KatmanÄ± ---
    # Regresyon problemi olduÄŸu iÃ§in tek bir nÃ¶ron (Linear activation)
    model.add(Dense(1))
    
    # Modeli derle
    model.compile(optimizer='adam', loss='mse')
    return model
```

# ğŸ” 4. Grid Search Stratejisi (The Tiny Grid-Search)

Derin Ã¶ÄŸrenme modellerinde (Deep Learning) her kombinasyonu denemek ("Brute Force") maliyetli ve zaman alÄ±cÄ±dÄ±r. Bu nedenle, `sklearn` kÃ¼tÃ¼phanesindeki standart `GridSearchCV` yerine, **manuel ve kontrollÃ¼ dÃ¶ngÃ¼ler** tercih edilir.

Bu yaklaÅŸÄ±mÄ±n en bÃ¼yÃ¼k avantajÄ±, **farklÄ± pencere boyutlarÄ±nÄ± (`seq_len`)** test edebilme esnekliÄŸidir. Standart yÃ¶ntemler genellikle sabit bir giriÅŸ boyutu ($X$) beklerken, biz burada her iterasyonda veriyi yeniden ÅŸekillendireceÄŸiz.

---

## ğŸ¯ Arama UzayÄ± (Search Space)

AÅŸaÄŸÄ±daki hiperparametreler, modelin kapasitesini ve hafÄ±za derinliÄŸini belirleyen en kritik oyunculardÄ±r:

| Hiperparametre | DeÄŸerler | AmaÃ§ |
| :--- | :--- | :--- |
| **`seq_len`** (Window) | `[30, 60]` | GeÃ§miÅŸe ne kadar bakacaÄŸÄ±z? (KÄ±sa vade vs Uzun vade) |
| **`n_units`** | `[64, 128]` | Modelin Ã¶ÄŸrenme kapasitesi ne olacak? |
| **`n_layers`** | `[1, 2]` | Model ne kadar derin (soyutlama yeteneÄŸi) olacak? |

**Toplam:** $2 \times 2 \times 2 = 8$ farklÄ± model eÄŸitimi gerÃ§ekleÅŸtirilecek.

---

## ğŸš€ GeliÅŸmiÅŸ EÄŸitim DÃ¶ngÃ¼sÃ¼ (Python Implementation)

AÅŸaÄŸÄ±daki kod bloÄŸu, `itertools` kullanarak temiz bir dÃ¶ngÃ¼ oluÅŸturur, her adÄ±mda veriyi yeniden hazÄ±rlar, `EarlyStopping` ile zaman tasarrufu saÄŸlar ve en iyi modeli hafÄ±zada tutar.

> **ğŸ’¡ Uzman Ä°pucu:** `seq_len` deÄŸiÅŸtiÄŸinde `X` ve `y` matrislerinin boyutu deÄŸiÅŸir. Bu yÃ¼zden `make_sequences` fonksiyonu dÃ¶ngÃ¼nÃ¼n *iÃ§inde* Ã§aÄŸrÄ±lmalÄ±dÄ±r.

```python
import itertools
import numpy as np
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_absolute_error

# 1. Parametre Grid'i
param_grid = {
    'seq_len': [30, 60],
    'n_units': [64, 128],
    'n_layers': [1, 2]
}

# 2. En iyi skoru takip etmek iÃ§in deÄŸiÅŸkenler
best_mae = float('inf')
best_params = {}
best_model = None

# 3. KombinasyonlarÄ± oluÅŸtur (itertools ile temiz kod)
keys, values = zip(*param_grid.items())
combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]

print(f"Toplam {len(combinations)} farklÄ± model test edilecek.\n")

# --- GRID SEARCH DÃ–NGÃœSÃœ ---
for params in combinations:
    print(f"Testing: {params} ...", end=" ")
    
    # A. Veriyi Dinamik HazÄ±rla (KRÄ°TÄ°K ADIM)
    # seq_len deÄŸiÅŸtiÄŸi iÃ§in X ve y her turda yeniden oluÅŸturulmalÄ±.
    # make_sequences fonksiyonu Ã¶nceki adÄ±mlardan gelmektedir.
    X_train_seq, y_train_seq = make_sequences(train_scaled, params['seq_len'])
    X_test_seq, y_test_seq = make_sequences(test_scaled, params['seq_len'])
    
    # B. Model FabrikasÄ±nÄ± Ã‡aÄŸÄ±r
    model = build_lstm(
        seq_len=params['seq_len'], 
        n_features=X_train_seq.shape[2], # Genellikle 9 feature
        n_units=params['n_units'],
        n_layers=params['n_layers'],
        dropout_rate=0.2
    )
    
    # C. Callback (Erken Durdurma)
    # restore_best_weights=True: Model overfitting'e baÅŸladÄ±ÄŸÄ± anÄ± deÄŸil, en iyi anÄ± hatÄ±rlar.
    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    
    # D. Modeli EÄŸit
    # verbose=0 yaparak konsolu kirletmiyoruz, sadece sonuÃ§larÄ± basacaÄŸÄ±z.
    history = model.fit(
        X_train_seq, y_train_seq, 
        validation_split=0.1, # EÄŸitim verisinin %10'u validasyon iÃ§in
        epochs=40, 
        batch_size=32, 
        callbacks=[es], 
        verbose=0
    )
    
    # E. DeÄŸerlendir (Evaluation)
    # 1. Tahmin yap (SonuÃ§lar [0,1] arasÄ±ndadÄ±r)
    preds_scaled = model.predict(X_test_seq, verbose=0)
    
    # 2. Ters DÃ¶nÃ¼ÅŸÃ¼m (Inverse Transform)
    # Scaler, Ã§ok deÄŸiÅŸkenli (multivariate) olduÄŸu iÃ§in dummy (boÅŸ) sÃ¼tun hilesi gerekebilir.
    # Burada basitleÅŸtirilmiÅŸ bir inverse iÅŸlemi varsayÄ±yoruz:
    # (GerÃ§ek projede 'inverse_transform_helper' gibi bir fonksiyona ihtiyaÃ§ vardÄ±r)
    preds_real = scaler_target.inverse_transform(preds_scaled) 
    y_test_real = scaler_target.inverse_transform(y_test_seq)
    
    # 3. Skoru Hesapla
    current_mae = mean_absolute_error(y_test_real, preds_real)
    print(f"MAE: {current_mae:.2f}")
    
    # F. En Ä°yiyi Kaydet (Winner Takes All)
    if current_mae < best_mae:
        best_mae = current_mae
        best_params = params
        best_model = model # En iyi modelin aÄŸÄ±rlÄ±klarÄ±nÄ± sakla

print("-" * 30)
print(f"ğŸ† EN Ä°YÄ° SONUÃ‡: MAE = {best_mae:.2f}")
print(f"âš™ï¸ EN Ä°YÄ° PARAMETRELER: {best_params}")
```

## ğŸ› ï¸ Teknik Derinlemesine Analiz: Kod Neden Ã‡alÄ±ÅŸÄ±yor?

YazdÄ±ÄŸÄ±mÄ±z Grid Search dÃ¶ngÃ¼sÃ¼ basit gÃ¶rÃ¼nse de, arka planda zaman serisi modellemesinin en temel matematiksel ve lojistik problemlerini Ã§Ã¶zer. Ä°ÅŸte bu kodun baÅŸarÄ±sÄ±nÄ±n altÄ±ndaki 3 temel mekanizma:

### 1. ğŸ”„ Dinamik Veri Ãœretimi (`make_sequences`)
LSTM modellerinde veri sabit bir matris deÄŸildir; seÃ§ilen pencere boyutuna (`seq_len`) gÃ¶re ÅŸekil alan "akÄ±ÅŸkan" bir yapÄ±dÄ±r.

* **Matematiksel GerÃ§ek:** Bir zaman serisinde Ã¶rneklem sayÄ±sÄ± ($N$) ile pencere boyutu ($w$) arasÄ±nda ters orantÄ± vardÄ±r:
  $$\text{Sample Count} = N - w$$
* **Senaryo:**
    * 1000 gÃ¼nlÃ¼k veride **30 gÃ¼n** pencere kullanÄ±rsanÄ±z: $1000 - 30 = 970$ satÄ±r veri oluÅŸur.
    * 1000 gÃ¼nlÃ¼k veride **60 gÃ¼n** pencere kullanÄ±rsanÄ±z: $1000 - 60 = 940$ satÄ±r veri oluÅŸur.
* **Ã‡Ã¶zÃ¼m:** Bu yÃ¼zden `X` ve `y` matrislerini dÃ¶ngÃ¼nÃ¼n dÄ±ÅŸÄ±nda sabit tutamayÄ±z. Her iterasyonda, yeni `seq_len` deÄŸerine gÃ¶re veriyi yeniden "dilimlememiz" (slicing) gerekir.

### 2. ğŸ›‘ EarlyStopping'in Gizli GÃ¼cÃ¼ (`restore_best_weights=True`)
Derin Ã¶ÄŸrenme eÄŸitimlerinde model genellikle bir noktadan sonra ezberlemeye (overfitting) baÅŸlar.
* **VarsayÄ±lan DavranÄ±ÅŸ (`False`):** EÄŸitim bittiÄŸinde (veya durdurulduÄŸunda), model hafÄ±zasÄ±nda **en son epoch'un** aÄŸÄ±rlÄ±klarÄ± kalÄ±r. Ancak son epoch, genellikle modelin overfitting yapmaya baÅŸladÄ±ÄŸÄ± "kÃ¶tÃ¼" bir andÄ±r.
* **Bizim AyarÄ±mÄ±z (`True`):** Bu parametre modele bir "Zaman Makinesi" Ã¶zelliÄŸi kazandÄ±rÄ±r. EÄŸitim dursa bile, model geÃ§miÅŸe dÃ¶ner ve doÄŸrulama hatasÄ±nÄ±n (validation loss) en dÃ¼ÅŸÃ¼k olduÄŸu **"AltÄ±n Ã‡aÄŸ"**daki (Golden Epoch) aÄŸÄ±rlÄ±klarÄ± geri yÃ¼kler. Bu, genelleme baÅŸarÄ±sÄ±nÄ± garanti eder.

### 3. ğŸ“‰ Ters DÃ¶nÃ¼ÅŸÃ¼m (Inverse Transform) ZorunluluÄŸu
LSTM'ler, gradyanlarÄ±n patlamamasÄ± iÃ§in `[0, 1]` aralÄ±ÄŸÄ±na sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ verilerle Ã§alÄ±ÅŸÄ±r. Ancak iÅŸ birimi (business) "0.45" deÄŸerinden bir ÅŸey anlamaz.

* **Sorun:** Model Ã§Ä±ktÄ±sÄ± normalize edilmiÅŸtir (Ã–rn: 0.45).
* **GerÃ§ek:** Bu 0.45 deÄŸeri, gerÃ§ek dÃ¼nyada **1500 adet satÄ±ÅŸa** denk geliyor olabilir.
* **Ã‡Ã¶zÃ¼m:** BaÅŸarÄ±yÄ± (MAE/RMSE) Ã¶lÃ§meden Ã¶nce, tahminleri mutlaka `scaler.inverse_transform()` ile orijinal birimine (satÄ±ÅŸ adedine) Ã§evirmeliyiz. Aksi takdirde 1500 birimlik hatayÄ± 0.45 gibi gÃ¶rÃ¼p "Model harika Ã§alÄ±ÅŸÄ±yor" yanÄ±lgÄ±sÄ±na dÃ¼ÅŸeriz.

# ğŸ“Š 5. SonuÃ§larÄ±n RaporlanmasÄ± ve "Tuzaklar"

En iyi modeli bulduktan sonra yapÄ±lan en bÃ¼yÃ¼k hata, Ã¶lÃ§eklenmiÅŸ (scaled) sonuÃ§larÄ± yorumlamaya Ã§alÄ±ÅŸmaktÄ±r. Model Ã§Ä±ktÄ±sÄ± `0.45` olabilir, ancak iÅŸ dÃ¼nyasÄ±nda bu **450 adet satÄ±ÅŸ** anlamÄ±na geliyor olabilir.

---

## ğŸ”„ Inverse Transform (Ters DÃ¶nÃ¼ÅŸÃ¼m)

Model Ã§Ä±ktÄ±sÄ± genellikle `[0, 1]` arasÄ±ndadÄ±r (MinMaxScaler kullanÄ±ldÄ±ÄŸÄ± varsayÄ±lÄ±rsa). Bunu gerÃ§ek dÃ¼nyaya (satÄ±ÅŸ adetlerine) dÃ¶ndÃ¼rmek iÃ§in `scaler.inverse_transform()` metodu kullanÄ±lÄ±r.

### âš ï¸ Uzman UyarÄ±sÄ±: Shape Mismatch Trap (Boyut UyuÅŸmazlÄ±ÄŸÄ± TuzaÄŸÄ±)

EÄŸer modeliniz **"Multivariate" (Ã‡ok deÄŸiÅŸkenli)** ise, Scaler'Ä±nÄ±z eÄŸitim sÄ±rasÄ±nda Ã¶rneÄŸin **9 sÃ¼tun (feature)** gÃ¶rmÃ¼ÅŸtÃ¼r. Ancak modelinizin tahmini (`y_pred`) genellikle **tek sÃ¼tundur** (sadece hedef deÄŸiÅŸken).

EÄŸer doÄŸrudan `scaler.inverse_transform(y_pred)` yaparsanÄ±z, **boyut hatasÄ± (ValueError)** alÄ±rsÄ±nÄ±z. Scaler, 9 sÃ¼tun beklerken siz ona 1 sÃ¼tun veriyorsunuzdur.

#### âœ… Ã‡Ã¶zÃ¼m: Dummy Features ile Tamamlama
`y_pred` vektÃ¶rÃ¼nÃ¼n yanÄ±na 8 tane boÅŸ (veya sÄ±fÄ±r) sÃ¼tun ekleyip transform iÅŸlemini yapÄ±n, ardÄ±ndan sadece ilgilendiÄŸiniz ilk sÃ¼tunu geri alÄ±n.

```python
import numpy as np

# Ã–rnek: y_pred (Model Tahmini) -> (100, 1) boyutunda
# Scaler eÄŸitimde 9 feature kullandÄ±ysa:

# 1. 9 sÃ¼tunlu boÅŸ bir matris oluÅŸtur
# (Shape: [tahmin_sayisi, feature_sayisi])
dummy_features = np.zeros((len(y_pred), 9))

# 2. Ä°lk sÃ¼tuna tahminleri yerleÅŸtir (Target deÄŸiÅŸkeniniz ilk sÄ±radaysa)
dummy_features[:, 0] = y_pred.flatten()

# 3. Inverse Transform uygula
rescaled_matrix = scaler.inverse_transform(dummy_features)

# 4. Sadece gerÃ§ek tahmin sÃ¼tununu Ã§ek
final_predictions = rescaled_matrix[:, 0]

```

# ğŸ©º SaÄŸlÄ±k KontrolÃ¼ (Diagnostics) & Model Validasyonu

Model eÄŸitimi bittikten sonra alÄ±nan sayÄ±sal skor (MAE/RMSE) tek baÅŸÄ±na yeterli deÄŸildir. Modelin davranÄ±ÅŸsal olarak saÄŸlÄ±klÄ± olup olmadÄ±ÄŸÄ±nÄ± anlamak iÃ§in "TeÅŸhis" (Diagnostics) aÅŸamasÄ± uygulanmalÄ±dÄ±r.

Bu aÅŸamada aÅŸaÄŸÄ±daki kontrolleri adÄ±m adÄ±m uygulayÄ±n:

---

## 1. ğŸ“ˆ GÃ¶rsel Kontrol (Visual Inspection)

SayÄ±lar yalan sÃ¶yleyebilir ama grafikler (genellikle) sÃ¶ylemez. Tahmin edilen (`y_pred`) ve gerÃ§ek (`y_test`) deÄŸerleri aynÄ± eksende Ã§izdirin.

### ğŸ” Neye BakmalÄ±yÄ±z?
1.  **Pik NoktalarÄ± (Peak Capture):**
    * *Soru:* GerÃ§ek verideki ani sÄ±Ã§ramalarÄ± (Ã¶rneÄŸin kampanya gÃ¼nleri) model yakalayabiliyor mu? Yoksa ortalamadan gÃ¼venli bir dÃ¼z Ã§izgi mi Ã§ekiyor?
2.  **Faz KaymasÄ± (Phase Shift / Lagging):** âš ï¸ *Kritik Kontrol*
    * *Soru:* Tahmin Ã§izgisi, gerÃ§ek Ã§izgiyi "takip mi ediyor"?
    * *Tehlike:* LSTM bazen tembellik yapar ve $t$ anÄ±nÄ± tahmin etmek iÃ§in sadece $t-1$ deÄŸerini kopyalar. Grafikte Ã§izgiler uyumlu gÃ¶rÃ¼nÃ¼r ama aslÄ±nda model sadece **1 adÄ±m geriden geliyordur.** Bunu anlamak iÃ§in grafiÄŸe "zoom" yapÄ±n.

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(15, 6))
plt.plot(y_test_real, label='GerÃ§ek (Actual)', color='black', alpha=0.7)
plt.plot(preds_real, label='Tahmin (Prediction)', color='red', linestyle='--')
plt.title('LSTM Model: GerÃ§ek vs Tahmin')
plt.legend()
plt.show()
```

## 2. ğŸ“‰ Hata Metrikleri Analizi (Error Metrics Analysis)

Sadece genel ortalamaya bakmak yanÄ±ltÄ±cÄ±dÄ±r. HatayÄ± parÃ§alara ayÄ±rÄ±n (decompose the error):

* **MAE (Mean Absolute Error):** "Ortalama kaÃ§ adet Ã¼rÃ¼n yanÄ±lÄ±yoruz?" (YÃ¶neticilerin anlayacaÄŸÄ± dildir / Business friendly language).
* **Bias (YanlÄ±lÄ±k):**
    * $\text{Bias} > 0$: Model sÃ¼rekli fazla tahmin ediyor (Stok ÅŸiÅŸkinliÄŸi riski / **Overstock risk**).
    * $\text{Bias} < 0$: Model sÃ¼rekli eksik tahmin ediyor (Stoksuz kalma / **Stockout** - MÃ¼ÅŸteri kaybÄ± riski / **Lost sales risk**).
    * **Hedef (Goal):** Bias'Ä±n 0'a yakÄ±n olmasÄ±dÄ±r.

---

## 3. ğŸï¸ Benchmark (KÄ±yaslama) Testi

"KarmaÅŸÄ±klÄ±ÄŸÄ±n Maliyeti" (**Cost of Complexity**) ilkesi gereÄŸi, oluÅŸturduÄŸunuz Derin Ã–ÄŸrenme (Deep Learning) modeli kendinden daha basit modellerden belirgin ÅŸekilde iyi olmalÄ±dÄ±r.

AÅŸaÄŸÄ±daki modellerle kÄ±yaslayÄ±n:

1.  **Naive Model:** "YarÄ±nki satÄ±ÅŸ, bugÃ¼nkÃ¼ satÄ±ÅŸla aynÄ±dÄ±r" diyen model. LSTM bunu bile geÃ§emiyorsa model Ã§Ã¶p demektir.
2.  **Moving Average (Hareketli Ortalama):** Son 7 gÃ¼nÃ¼n ortalamasÄ±.
3.  **XGBoost / LightGBM:** EÄŸitimi Ã§ok daha hÄ±zlÄ± olan aÄŸaÃ§ tabanlÄ± modeller (**Tree-based models**).

> **Karar KuralÄ± (Decision Rule):** EÄŸer LSTM, XGBoost'tan sadece %1 daha iyiyse ama eÄŸitimi 10 kat uzun sÃ¼rÃ¼yorsa; **XGBoost'u seÃ§in.**

---

### ğŸ’¡ Uzman Notu: Hibrit Modeller (Hybrid / Ensemble Models)

Zaman serisi yarÄ±ÅŸmalarÄ±nda (Kaggle, M5 Forecasting vb.) tek bir modelin kazandÄ±ÄŸÄ± nadir gÃ¶rÃ¼lÃ¼r. Genellikle **Ensemble (Topluluk)** yÃ¶ntemleri kullanÄ±lÄ±r.

* **LSTM:** Trendleri (yÃ¶nÃ¼) ve uzun vadeli dÃ¶ngÃ¼sel hareketleri Ã¶ÄŸrenmekte Ã§ok baÅŸarÄ±lÄ±dÄ±r (**Smooth predictions** - PÃ¼rÃ¼zsÃ¼z tahminler).
* **XGBoost:** Ani ÅŸoklarÄ±, Ã¶zel gÃ¼nleri ve aykÄ±rÄ± deÄŸerleri (**Outliers**) yakalamakta daha keskindir (**Sharp predictions** - Keskin tahminler).

#### ğŸš€ Ã‡Ã¶zÃ¼m: AÄŸÄ±rlÄ±klÄ± Ortalama TopluluÄŸu (Weighted Average Ensemble)

Ä°ki dÃ¼nyanÄ±n en iyisini birleÅŸtirmek iÃ§in tahminlerin aÄŸÄ±rlÄ±klÄ± ortalamasÄ±nÄ± alÄ±n:

```python
# Basit bir Ensemble Ã¶rneÄŸi (Simple Ensemble Example)
lstm_preds = model_lstm.predict(X_test)
xgb_preds = model_xgb.predict(X_test)

# AÄŸÄ±rlÄ±klar Deneme-YanÄ±lma (Trial & Error) veya Optimizasyonla bulunur
final_preds = (0.5 * lstm_preds) + (0.5 * xgb_preds)

```
### ğŸ¨ GÃ¶rsel MantÄ±k (Ensemble Logic)

AÅŸaÄŸÄ±daki diyagram, LSTM ve XGBoost modellerinin gÃ¼Ã§lÃ¼ yanlarÄ±nÄ± birleÅŸtiren hibrit yapÄ±yÄ± gÃ¶stermektedir.

```mermaid
graph TD
    Data["Veri Seti / Dataset"] --> LSTM["LSTM Modeli"]
    Data --> XGB["XGBoost Modeli"]
    
    LSTM -- "Trendi Yakalar (Captures Trend)" --> P1["Tahmin A"]
    XGB -- "Pikleri Yakalar (Captures Peaks)" --> P2["Tahmin B"]
    
    %% TÄ±rnak iÅŸaretleri hatayÄ± engeller
    P1 --> Mix{"Ensemble<br/>(Ortalama / Average)"}
    P2 --> Mix
    
    Mix --> Final["ğŸš€ Daha KararlÄ± & GÃ¼Ã§lÃ¼ Tahmin<br/>(Robust Prediction)"]


# ğŸ§ª Experiment Tracking with MLflow

Makine Ã¶ÄŸrenimi deneylerini (ARIMA, XGBoost, LSTM vb.) yÃ¶netmek karmaÅŸÄ±klaÅŸabilir. MLflow, Excel tablolarÄ± ve ekran gÃ¶rÃ¼ntÃ¼leri arasÄ±nda kaybolmadan; parametreleri, metrikleri ve modelleri dÃ¼zenli bir ÅŸekilde takip etmenizi saÄŸlar.

AÅŸaÄŸÄ±daki diyagramlar, MLflow'un neden gerekli olduÄŸunu, neleri kaydettiÄŸini ve nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶zetlemektedir.

---

### ğŸ§  1. Why MLflow & What We Log (Neden ve Ne Kaydediyoruz?)

Bu diyagram, MLflow'un "DaÄŸÄ±nÄ±k Deneyler" sorununu nasÄ±l Ã§Ã¶zdÃ¼ÄŸÃ¼nÃ¼ ve veri bilimci iÃ§in hangi kritik bilgileri sakladÄ±ÄŸÄ±nÄ± gÃ¶sterir.

```mermaid
graph TD
    %% Sorun TanÄ±mÄ±
    Chaos[("ğŸ”¥ The Problem<br/>(Spreadsheets & Screenshots)")]
    
    %% Ã‡Ã¶zÃ¼m
    MLflow{{"ğŸ§ª MLflow Tracking"}}
    
    %% BaÄŸlantÄ±
    Chaos -->|Solution| MLflow
    
    %% Neler LoglanÄ±yor? (What we log)
    MLflow --> Params[âš™ï¸ Hyperparameters]
    MLflow --> Metrics[ğŸ“Š Metrics]
    MLflow --> Artifacts[ğŸ“¦ Artifacts]
    
    %% Detaylar
    Params --- P1("p, d, q<br/>Learning Rate<br/>Window Size")
    Metrics --- M1("MAE, RMSE<br/>MAD, MAPE")
    Artifacts --- A1("Plots (Prediction Graphs)<br/>Models (.pkl / .h5)<br/>Confusion Matrices")
    
    %% Stil TanÄ±mlamalarÄ±
    classDef chaos fill:#ffcccc,stroke:#ff0000,stroke-width:2px;
    classDef main fill:#e1f5fe,stroke:#01579b,stroke-width:2px;
    classDef nodes fill:#ffffff,stroke:#333,stroke-width:1px;
    
    class Chaos chaos;
    class MLflow main;
    class Params,Metrics,Artifacts,P1,M1,A1 nodes;
```


### ğŸ—ï¸ 2. How We'll Run It (Ã‡alÄ±ÅŸma Mimarisi)
MLflow'u Ã§alÄ±ÅŸtÄ±rmanÄ±n iki yolu vardÄ±r. AÅŸaÄŸÄ±daki akÄ±ÅŸ ÅŸemasÄ±, Local (Yerel) ve Google Colab ortamlarÄ± arasÄ±ndaki kurulum farkÄ±nÄ± gÃ¶sterir.

flowchart LR
    subgraph Local_Env ["ğŸ’» Local Environment"]
        direction TB
        L_NB[Local Notebook] -->|Logs to| L_Disk[("ğŸ’¾ Local Disk<br/>(./mlruns)")]
        L_Disk -->|Reads| L_UI["ğŸ–¥ï¸ MLflow UI Server<br/>(localhost:5000)"]
    end

    subgraph Cloud_Env ["â˜ï¸ Google Colab Setup"]
        direction TB
        C_NB[Colab Notebook] -->|Mounts & Logs| GDrive[("ğŸ“ Google Drive<br/>(Storage)")]
        GDrive -->|Reads| C_UI["ğŸ–¥ï¸ MLflow UI (Background)"]
        C_UI -.->|Tunneling| Ngrok["ğŸ”— ngrok Service"]
        Ngrok -->|Public URL| User((User/Data Scientist))
    end

    %% Stil
    style Local_Env fill:#f9fbe7,stroke:#827717
    style Cloud_Env fill:#e3f2fd,stroke:#1565c0
    style Ngrok fill:#fff3e0,stroke:#ef6c00,stroke-dasharray: 5 5

### ğŸ—ºï¸ 3. Roadmap for Using MLflow (Uygulama Yol HaritasÄ±)
Projede MLflow'u entegre ederken izleyeceÄŸimiz 5 adÄ±mlÄ± sÃ¼reÃ§:

graph TD
    Step1("1ï¸âƒ£ Install & Setup<br/>(pip install mlflow)") 
    --> Step2("2ï¸âƒ£ Start Experiment<br/>Log a Simple Baseline Model")
    --> Step3("3ï¸âƒ£ Iterate & Scale<br/>Add ARIMA, SARIMA, XGBoost, LSTM")
    --> Step4("4ï¸âƒ£ Compare Runs<br/>Open UI & Analyze Side-by-Side")
    --> Step5("5ï¸âƒ£ Artifact Management<br/>Save Best Plots & Models")

    %% Stil
    style Step1 fill:#f3e5f5,stroke:#4a148c
    style Step2 fill:#e1bee7,stroke:#4a148c
    style Step3 fill:#ce93d8,stroke:#4a148c
    style Step4 fill:#ba68c8,stroke:#4a148c
    style Step5 fill:#ab47bc,stroke:#4a148c,color:#fff
